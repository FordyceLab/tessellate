{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nXUYGCpNbSla"
   },
   "source": [
    "# Benchmark position-aware graph neural network/2D CNN architecture\n",
    "\n",
    "This notebook contains all of the code to overfit a GAT to four contact channels of a single structure (6E6O).\n",
    "\n",
    "## Setup\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRzY2E5pbYm6"
   },
   "source": [
    "### Dataloader code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jf5S3ZSabSlc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import periodictable as pt\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import itertools as it\n",
    "\n",
    "\n",
    "def read_files(acc, model, graph_dir, contacts_dir):\n",
    "    \"\"\"\n",
    "    Read graph and contacts files.\n",
    "\n",
    "    Args:\n",
    "    - acc (str) - String of the PDB ID (lowercese).\n",
    "    - model (int) - Model number of the desired bioassembly.\n",
    "    - graph_dir (str) - Directory containing the nodes, edges,\n",
    "        and mask files.\n",
    "    - contacts_dir (str) - Directory containing the .contacts\n",
    "        files from get_contacts.py.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary of DataFrames and lists corresponding to\n",
    "        graph nodes, edges, mask, and contacts.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the file names for the graph files\n",
    "    node_file = os.path.join(graph_dir, '{}-{}_nodes.csv'.format(acc, model))\n",
    "    edge_file = os.path.join(graph_dir, '{}-{}_edges.csv'.format(acc, model))\n",
    "    mask_file = os.path.join(graph_dir, '{}-{}_mask.csv'.format(acc, model))\n",
    "\n",
    "    # Get the contacts file\n",
    "    contacts_file = os.path.join(contacts_dir, '{}-{}.contacts'.format(acc, model))\n",
    "\n",
    "    # Read the nodes and edges\n",
    "    nodes = pd.read_csv(node_file)\n",
    "    edges = pd.read_csv(edge_file)\n",
    "\n",
    "    # Check if the mask is empty\n",
    "    if os.path.getsize(mask_file) > 0:\n",
    "        with open(mask_file) as f:\n",
    "            mask = f.read().split('\\n')\n",
    "    else:\n",
    "        mask = []\n",
    "\n",
    "    # Read the contacts\n",
    "    contacts = pd.read_table(contacts_file, sep='\\t',\n",
    "                             header=None, names=['type', 'start', 'end'])\n",
    "\n",
    "    # Return the data\n",
    "    data = {\n",
    "        'nodes': nodes,\n",
    "        'edges': edges,\n",
    "        'mask': mask,\n",
    "        'contacts': contacts\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def process_res_data(data):\n",
    "    \"\"\"\n",
    "    Process residue-level data from atom-level data.\n",
    "\n",
    "    Args:\n",
    "    - data (dict) - Dictionary of graph data output from `read_files`.\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary of atom and residue graph and contact data.\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract data form dict\n",
    "    nodes = data['nodes']\n",
    "    edges = data['edges']\n",
    "    mask = data['mask']\n",
    "    contacts = data['contacts']\n",
    "\n",
    "    # Get residue nodes\n",
    "    res_nodes = pd.DataFrame()\n",
    "    res_nodes['res'] = [':'.join(atom.split(':')[:3]) for atom in nodes['atom']]\n",
    "    res_nodes = res_nodes.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Get residue edges\n",
    "    res_edges = edges.copy()\n",
    "    res_edges['start'] = [':'.join(atom.split(':')[:3]) for atom in res_edges['start']]\n",
    "    res_edges['end'] = [':'.join(atom.split(':')[:3]) for atom in res_edges['end']]\n",
    "    res_edges = res_edges[res_edges['start'] != res_edges['end']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Get residue contacts\n",
    "    res_contacts = contacts.copy()\n",
    "    res_contacts['start'] = [':'.join(atom.split(':')[:3]) for atom in res_contacts['start']]\n",
    "    res_contacts['end'] = [':'.join(atom.split(':')[:3]) for atom in res_contacts['end']]\n",
    "    res_contacts = res_contacts[res_contacts['start'] != res_contacts['end']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Get residue mask\n",
    "    res_mask = list(set([':'.join(atom.split(':')[:3]) for atom in mask]))\n",
    "\n",
    "    # Return data dict\n",
    "    data = {\n",
    "        'atom_nodes': nodes,\n",
    "        'atom_edges': edges,\n",
    "        'atom_contact': contacts,\n",
    "        'atom_mask': mask,\n",
    "        'res_nodes': res_nodes,\n",
    "        'res_edges': res_edges,\n",
    "        'res_contact': res_contacts,\n",
    "        'res_mask': res_mask\n",
    "    }\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_map_dicts(entity_list):\n",
    "    \"\"\"\n",
    "    Map identifiers to indices and vice versa.\n",
    "\n",
    "    Args:\n",
    "    - entity_list (list) - List of entities (atoms, residues, etc.)\n",
    "        to index.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple of the entity to index and index to entity dicts, respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create the entity:index dictionary\n",
    "    ent2idx_dict = {entity: idx for idx, entity in enumerate(entity_list)}\n",
    "\n",
    "    # Create the index:entity dictionary\n",
    "    idx2ent_dict = {idx: entity for entity, idx in ent2idx_dict.items()}\n",
    "\n",
    "    return (ent2idx_dict, idx2ent_dict)\n",
    "\n",
    "\n",
    "def create_adj_mat(data, dict_map, mat_type):\n",
    "    \"\"\"\n",
    "    Creates an adjacency matrix.\n",
    "\n",
    "    Args:\n",
    "    - data (DataFrame) - Dataframe with 'start' and 'end' column\n",
    "        for each interaction. For atom-level adjacency, 'order'\n",
    "        column is also required. For atom or residue conatcts,\n",
    "        'type' column is also required.\n",
    "\n",
    "    Returns:\n",
    "    - Coordinate format matrix (numpy). For atom adjacency, third column\n",
    "        corresponds to bond order. For contacts, third column\n",
    "        corresponds to channel.\n",
    "\n",
    "    Channel mappings (shorthand from get_contacts.py source):\n",
    "\n",
    "        0:\n",
    "            hp             hydrophobic interactions\n",
    "        1:\n",
    "            hb             hydrogen bonds\n",
    "            lhb            ligand hydrogen bonds\n",
    "            hbbb           backbone-backbone hydrogen bonds\n",
    "            hbsb           backbone-sidechain hydrogen bonds\n",
    "            hbss           sidechain-sidechain hydrogen bonds\n",
    "            hbls           ligand-sidechain residue hydrogen bonds\n",
    "            hblb           ligand-backbone residue hydrogen bonds\n",
    "        2:\n",
    "            vdw            van der Waals\n",
    "        3:\n",
    "            wb             water bridges\n",
    "            wb2            extended water bridges\n",
    "            lwb            ligand water bridges\n",
    "            lwb2           extended ligand water bridges\n",
    "        4:\n",
    "            sb             salt bridges\n",
    "        5:\n",
    "            ps             pi-stacking\n",
    "        6:\n",
    "            pc             pi-cation\n",
    "        7:\n",
    "            ts             t-stacking\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the coordinate list\n",
    "    coord_mat = []\n",
    "\n",
    "    # Map channel names to numeric channels\n",
    "    channel = {\n",
    "        # Hydrophobic interactions in first channel\n",
    "        'hp': 0,\n",
    "        'hplp': 0,\n",
    "        'hpll': 0,\n",
    "\n",
    "        # Hydrogen bonds in second channel\n",
    "        'hb': 1,\n",
    "        'lhb': 1,\n",
    "        'hbbb': 1,\n",
    "        'hbsb': 1,\n",
    "        'hbss': 1,\n",
    "        'hbls': 1,\n",
    "        'hblb': 1,\n",
    "\n",
    "        # VdW in third channel\n",
    "        'vdw': 2,\n",
    "\n",
    "        # Water bridges\n",
    "        'wb': 3,\n",
    "        'wb2': 3,\n",
    "        'lwb': 3,\n",
    "        'lwb2': 3,\n",
    "\n",
    "        # Salt bridges\n",
    "        'sb': 4,\n",
    "        'sbpl': 4,\n",
    "        'sbll': 4,\n",
    "\n",
    "        # Other interactions\n",
    "        'ps': 5,\n",
    "        'pc': 6,\n",
    "        'ts': 7,\n",
    "    }\n",
    "\n",
    "    # Assemble the contacts\n",
    "    for idx, row in data.iterrows():\n",
    "\n",
    "        if row['start'] in dict_map and row['end'] in dict_map:\n",
    "\n",
    "            entry = [dict_map[row['start']], dict_map[row['end']]]\n",
    "\n",
    "            # Add order or type if necessary\n",
    "            if mat_type == 'atom_graph':\n",
    "                entry.append(row['order'])\n",
    "            elif mat_type == 'atom_contact':\n",
    "                entry.append(channel[row['type']])\n",
    "            elif mat_type == 'res_contact':\n",
    "                entry.append(channel[row['type']])\n",
    "\n",
    "            coord_mat.append(entry)\n",
    "\n",
    "    return np.array(coord_mat)\n",
    "\n",
    "\n",
    "def create_conn_adj_mat(adj):\n",
    "    \"\"\"\n",
    "    Create connection adjacency matrix\n",
    "    \"\"\"\n",
    "\n",
    "    conn_map = {(a, b): idx for idx, (a, b) in enumerate(zip(*np.triu_indices_from(adj)))}\n",
    "\n",
    "    one_hop_neighbors = {idx: np.argwhere(row > 0).squeeze().tolist() for idx, row in enumerate(adj)}\n",
    "\n",
    "    conns = []\n",
    "\n",
    "    for i, j in it.combinations_with_replacement(one_hop_neighbors, 2):\n",
    "        row = conn_map[(i, j)]\n",
    "        adj_conn_coords = set([(m, n) if m <= n else (n, m)\n",
    "                               for m, n in it.product(one_hop_neighbors[i],\n",
    "                                                      one_hop_neighbors[j])])\n",
    "        adj_conns = [conn_map[x] for x in adj_conn_coords]\n",
    "\n",
    "        conns.append(np.array(list(it.product([row], adj_conns))))\n",
    "\n",
    "    conn_adj = np.concatenate(conns, axis=0).T\n",
    "\n",
    "    return conn_adj\n",
    "\n",
    "\n",
    "def create_mem_mat(atom_dict, res_dict):\n",
    "    \"\"\"\n",
    "    Create a membership matrix mapping atoms to residues.\n",
    "\n",
    "    Args:\n",
    "    - atom_dict (dict) - Dictionary mapping atoms to indices.\n",
    "    - res_dict (dict) - Dictionary mapping residues to indices.\n",
    "\n",
    "    Returns:\n",
    "    - Coordinate format membership matrix (numpy) with first\n",
    "        row being residue number and the second column being\n",
    "        atom number.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize the coordinate list\n",
    "    mem_coord = []\n",
    "\n",
    "    # Map atoms to residues\n",
    "    for atom, atom_idx in atom_dict.items():\n",
    "        res_idx = res_dict[':'.join(atom.split(':')[:3])]\n",
    "\n",
    "        mem_coord.append([res_idx, atom_idx])\n",
    "\n",
    "    mem_coord = np.array(mem_coord)\n",
    "\n",
    "    return mem_coord\n",
    "\n",
    "\n",
    "def create_idx_list(id_list, dict_map):\n",
    "    \"\"\"\n",
    "    Create list of indices.\n",
    "\n",
    "    Args:\n",
    "    - id_list (list) - List of masked atom or residue identifiers.\n",
    "    - dict_map (dict) - Dictionary mapping entities to indices.\n",
    "\n",
    "    Returns:\n",
    "    - A numpy array of the masked indices.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate the numpy index array\n",
    "    idx_array = np.array([dict_map[iden] for iden in id_list])\n",
    "\n",
    "    return idx_array\n",
    "\n",
    "\n",
    "class TesselateDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset class for structural data.\n",
    "\n",
    "    Args:\n",
    "    - accession_list (str) - File path from which to read PDB IDs for dataset.\n",
    "    - graph_dir (str) - Directory containing the nodes, edges, and mask files.\n",
    "    - contacts_dir (str) - Directory containing the .contacts files from\n",
    "        get_contacts.py.\n",
    "    - return_data (list) - List of datasets to return. Value must be 'all' or\n",
    "        a subset of the following list:\n",
    "            - pdb_id\n",
    "            - model\n",
    "            - atom_nodes\n",
    "            - atom_adj\n",
    "            - atom_contact\n",
    "            - atom_mask\n",
    "            - res_adj\n",
    "            - res_dist\n",
    "            - res_contact\n",
    "            - res_mask\n",
    "            - mem_mat\n",
    "            - idx2atom_dict\n",
    "            - idx2res_dict\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, accession_list, graph_dir, contacts_dir, add_covalent=False, return_data='all', in_memory=False):\n",
    "\n",
    "        if return_data == 'all':\n",
    "            self.return_data = [\n",
    "                'pdb_id',\n",
    "                'model',\n",
    "                'atom_nodes',\n",
    "                'atom_adj',\n",
    "                'atom_contact',\n",
    "                'atom_mask',\n",
    "                'res_adj',\n",
    "                'res_dist',\n",
    "                'conn_adj',\n",
    "                'res_contact',\n",
    "                'res_mask',\n",
    "                'mem_mat',\n",
    "                'idx2atom_dict',\n",
    "                'idx2res_dict'\n",
    "            ]\n",
    "\n",
    "        else:\n",
    "            self.return_data = return_data\n",
    "\n",
    "        # Store reference to accession list file\n",
    "        self.accession_list = accession_list\n",
    "\n",
    "        # Store references to the necessary directories\n",
    "        self.graph_dir = graph_dir\n",
    "        self.contacts_dir = contacts_dir\n",
    "\n",
    "        # Whether to add covalent bonds to prediction task and\n",
    "        # remove sequence non-deterministic covalent bonds from the adjacency matrix\n",
    "        self.add_covalent=add_covalent\n",
    "\n",
    "        # Read in and store a list of accession IDs\n",
    "        with open(accession_list, 'r') as handle:\n",
    "            self.accessions = np.array([acc.strip().lower().split() for acc in handle.readlines()])\n",
    "\n",
    "        self.data = {}\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the length of the dataset.\n",
    "\n",
    "        Returns:\n",
    "        - Integer count of number of examples.\n",
    "        \"\"\"\n",
    "        return len(self.accessions)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get an item with a particular index value.\n",
    "\n",
    "        Args:\n",
    "        - idx (int) - Index of desired sample.\n",
    "\n",
    "        Returns:\n",
    "        - Dictionary of dataset example. All tensors are sparse when possible.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            if idx in self.data:\n",
    "                return self.data[idx]\n",
    "\n",
    "            # initialize the return dictionary\n",
    "            return_dict = {}\n",
    "\n",
    "            acc_entry = self.accessions[idx]\n",
    "\n",
    "            # Get the PDB ID\n",
    "            acc = acc_entry[0]\n",
    "\n",
    "            # Get the model number if one exists\n",
    "            if len(acc_entry) == 1:\n",
    "                model = 1\n",
    "            else:\n",
    "                model = acc_entry[1]\n",
    "\n",
    "            # Read and process the files\n",
    "            data = read_files(acc, model, self.graph_dir, self.contacts_dir)\n",
    "            data = process_res_data(data)\n",
    "\n",
    "            # Generate the mapping dictionaries\n",
    "            atom2idx_dict, idx2atom_dict = get_map_dicts(data['atom_nodes']['atom'].unique())\n",
    "            res2idx_dict, idx2res_dict = get_map_dicts(data['res_nodes']['res'].unique())\n",
    "\n",
    "            # Get numbers of atoms and residues per sample\n",
    "            n_atoms = len(atom2idx_dict)\n",
    "            n_res = len(res2idx_dict)\n",
    "\n",
    "            # Handle all of the possible returned datasets\n",
    "            if 'pdb_id' in self.return_data:\n",
    "                return_dict['pdb_id'] = acc\n",
    "\n",
    "            if 'model' in self.return_data:\n",
    "                return_dict['model'] = model\n",
    "\n",
    "            if 'atom_nodes' in self.return_data:\n",
    "                ele_nums = [pt.elements.symbol(element).number for element in data['atom_nodes']['element']]\n",
    "                return_dict['atom_nodes'] = torch.LongTensor(ele_nums)\n",
    "                assert not torch.isnan(return_dict['atom_nodes']).any()\n",
    "\n",
    "            if 'atom_adj' in self.return_data:\n",
    "\n",
    "                adj = create_adj_mat(data['atom_edges'], atom2idx_dict, mat_type='atom_graph').T\n",
    "\n",
    "                x = torch.LongTensor(adj[0, :]).squeeze()\n",
    "                y = torch.LongTensor(adj[1, :]).squeeze()\n",
    "                val = torch.FloatTensor(adj[2, :]).squeeze()\n",
    "\n",
    "                atom_adj = torch.zeros([n_atoms, n_atoms]).index_put_((x, y), val, accumulate=False)\n",
    "\n",
    "                atom_adj = atom_adj.index_put_((y, x), val, accumulate=False)\n",
    "\n",
    "                atom_adj[range(n_atoms), range(n_atoms)] = 1\n",
    "\n",
    "                atom_adj = (atom_adj > 0).float()\n",
    "\n",
    "                return_dict['atom_adj'] = atom_adj\n",
    "\n",
    "                assert not torch.isnan(return_dict['atom_adj']).any()\n",
    "\n",
    "            if 'atom_contact' in self.return_data:\n",
    "                atom_contact = create_adj_mat(data['atom_contact'], atom2idx_dict, mat_type='atom_contact').T\n",
    "\n",
    "                x = torch.LongTensor(atom_contact[0, :]).squeeze()\n",
    "                y = torch.LongTensor(atom_contact[1, :]).squeeze()\n",
    "                z = torch.LongTensor(atom_contact[2, :]).squeeze()\n",
    "\n",
    "                atom_contact = torch.zeros([n_atoms, n_atoms, 8]).index_put_((x, y, z),\n",
    "                                                                        torch.ones(len(x)))\n",
    "                atom_contact = atom_contact.index_put_((y, x, z),\n",
    "                                                       torch.ones(len(x)))\n",
    "\n",
    "                return_dict['atom_contact'] = atom_contact\n",
    "\n",
    "                assert not torch.isnan(return_dict['atom_contact']).any()\n",
    "\n",
    "            if 'atom_mask' in self.return_data:\n",
    "                atom_mask = create_idx_list(data['atom_mask'], atom2idx_dict)\n",
    "\n",
    "                masked_pos = torch.from_numpy(atom_mask)\n",
    "\n",
    "                if self.add_covalent:\n",
    "                    channels = 9\n",
    "                else:\n",
    "                    channels = 8\n",
    "\n",
    "                mask = torch.ones([n_atoms, n_atoms, channels])\n",
    "\n",
    "                if len(masked_pos) > 0:\n",
    "                    mask[masked_pos, :, :] = 0\n",
    "                    mask[:, masked_pos, :] = 0\n",
    "\n",
    "                return_dict['atom_mask'] = mask\n",
    "\n",
    "                assert not torch.isnan(return_dict['atom_mask']).any()\n",
    "\n",
    "            if 'res_adj' in self.return_data:\n",
    "                adj = create_adj_mat(data['res_edges'], res2idx_dict, mat_type='res_graph').T\n",
    "\n",
    "                x = torch.LongTensor(adj[0, :]).squeeze()\n",
    "                y = torch.LongTensor(adj[1, :]).squeeze()\n",
    "\n",
    "                res_adj = torch.zeros([n_res, n_res]).index_put_((x, y), torch.ones(len(x)))\n",
    "\n",
    "                res_adj = res_adj.index_put_((y, x), torch.ones(len(x)))\n",
    "\n",
    "                res_adj[range(n_res), range(n_res)] = 1\n",
    "\n",
    "                return_dict['res_adj'] = res_adj\n",
    "\n",
    "                assert not torch.isnan(return_dict['res_adj']).any()\n",
    "\n",
    "                if 'res_dist' in self.return_data:\n",
    "                    G = nx.from_numpy_matrix(return_dict['res_adj'].numpy())\n",
    "                    res_dist = torch.from_numpy(nx.floyd_warshall_numpy(G)).float()\n",
    "\n",
    "                    res_dist[torch.isinf(res_dist)] = -1\n",
    "\n",
    "                    return_dict['res_dist'] = res_dist\n",
    "\n",
    "                    chain_mem = torch.zeros(res_dist.shape)\n",
    "                    chain_mem[~torch.isinf(return_dict['res_dist'])] = 1\n",
    "\n",
    "                    return_dict['chain_mem'] = chain_mem\n",
    "\n",
    "                    assert not torch.isnan(return_dict['res_dist']).any()\n",
    "                    assert not torch.isinf(return_dict['res_dist']).any()\n",
    "                    assert not torch.isnan(return_dict['chain_mem']).any()\n",
    "                    assert not torch.isinf(return_dict['chain_mem']).any()\n",
    "\n",
    "                if 'conn_adj' in self.return_data:\n",
    "\n",
    "                    conn_adj = create_conn_adj_mat(return_dict['res_adj'].numpy())\n",
    "\n",
    "                    return_dict['conn_adj'] = torch.from_numpy(conn_adj)\n",
    "\n",
    "            if 'res_contact' in self.return_data:\n",
    "                res_contact = create_adj_mat(data['res_contact'], res2idx_dict, mat_type='res_contact').T\n",
    "\n",
    "                x = torch.LongTensor(res_contact[0, :]).squeeze()\n",
    "                y = torch.LongTensor(res_contact[1, :]).squeeze()\n",
    "                z = torch.LongTensor(res_contact[2, :]).squeeze()\n",
    "\n",
    "                res_contact = torch.zeros([n_res, n_res, 8]).index_put_((x, y, z),\n",
    "                                                                        torch.ones(len(x)))\n",
    "\n",
    "                res_contact = res_contact.index_put_((y, x, z),\n",
    "                                                     torch.ones(len(x)))\n",
    "\n",
    "                return_dict['res_contact'] = res_contact\n",
    "\n",
    "                assert not torch.isnan(return_dict['res_contact']).any()\n",
    "\n",
    "            if 'res_mask' in self.return_data:\n",
    "                res_mask = create_idx_list(data['res_mask'], res2idx_dict)\n",
    "\n",
    "                masked_pos = torch.from_numpy(res_mask)\n",
    "\n",
    "                if self.add_covalent:\n",
    "                    channels = 9\n",
    "                else:\n",
    "                    channels = 8\n",
    "\n",
    "                mask = torch.ones([n_res, n_res, channels])\n",
    "\n",
    "                if len(masked_pos) > 0:\n",
    "                    mask[masked_pos, :, :] = 0\n",
    "                    mask[:, masked_pos, :] = 0\n",
    "\n",
    "                return_dict['res_mask'] = mask\n",
    "\n",
    "                assert not torch.isnan(return_dict['res_mask']).any()\n",
    "\n",
    "            if 'mem_mat' in self.return_data:\n",
    "                mem_mat = create_mem_mat(atom2idx_dict, res2idx_dict).T\n",
    "\n",
    "                x = torch.LongTensor(mem_mat[0, :]).squeeze()\n",
    "                y = torch.LongTensor(mem_mat[1, :]).squeeze()\n",
    "\n",
    "                mem_mat = torch.zeros([n_res, n_atoms]).index_put_((x, y),\n",
    "                                                                   torch.ones(len(x)))\n",
    "\n",
    "                return_dict['mem_mat'] = mem_mat\n",
    "\n",
    "                assert not torch.isnan(return_dict['mem_mat']).any()\n",
    "\n",
    "            if 'idx2atom_dict' in self.return_data:\n",
    "                return_dict['idx2atom_dict'] = idx2atom_dict\n",
    "\n",
    "            if 'idx2res_dict' in self.return_data:\n",
    "                return_dict['idx2res_dict'] = idx2res_dict\n",
    "\n",
    "            self.data[idx] = return_dict\n",
    "\n",
    "            # Return the processed data\n",
    "            return return_dict\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", acc, str(e))\n",
    "            raise e\n",
    "            return np.array([0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yn1eZ_eMbSlj"
   },
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6k6mfHhlbSlk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools as it\n",
    "from torch_scatter import scatter_softmax\n",
    "\n",
    "\n",
    "####################\n",
    "# Embedding layers #\n",
    "####################\n",
    "\n",
    "class AtomEmbed(nn.Module):\n",
    "    \"\"\"\n",
    "    Embed the atoms to fixed-length input vectors.\n",
    "\n",
    "    Args:\n",
    "    - num_features (int) - Size of the returned embedding vectors.\n",
    "    - scale_grad_by_freq (bool) - Scale gradients by the inverse of\n",
    "        frequency (default=True).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_features, scale_grad_by_freq=True):\n",
    "        super(AtomEmbed, self).__init__()\n",
    "        self.embedding = nn.Embedding(118,\n",
    "                                      n_features,\n",
    "                                      scale_grad_by_freq=scale_grad_by_freq)\n",
    "\n",
    "    def forward(self, atomic_numbers):\n",
    "        \"\"\"\n",
    "        Return the embeddings for each atom in the graph.\n",
    "\n",
    "        Args:\n",
    "        - atoms (torch.LongTensor) - Tensor (n_atoms) containing atomic numbers.\n",
    "\n",
    "        Returns:\n",
    "        - torch.FloatTensor of dimension (n_atoms, n_features) containing\n",
    "            the embedding vectors.\n",
    "        \"\"\"\n",
    "\n",
    "        # Get and return the embeddings for each atom\n",
    "        embedded_atoms = self.embedding(atomic_numbers)\n",
    "        return embedded_atoms\n",
    "\n",
    "\n",
    "####################\n",
    "# Attention layers #\n",
    "####################\n",
    "\n",
    "class SpecialSpmmFunction(torch.autograd.Function):\n",
    "    \"\"\"Special function for only sparse region backpropataion layer.\"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, indices, values, shape, b):\n",
    "        assert indices.requires_grad == False\n",
    "        a = torch.sparse_coo_tensor(indices, values, shape)\n",
    "        ctx.save_for_backward(a, b)\n",
    "        ctx.N = shape[0]\n",
    "        return torch.matmul(a, b)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        a, b = ctx.saved_tensors\n",
    "        grad_values = grad_b = None\n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_a_dense = grad_output.matmul(b.t())\n",
    "            edge_idx = a._indices()[0, :] * ctx.N + a._indices()[1, :]\n",
    "            grad_values = grad_a_dense.view(-1)[edge_idx]\n",
    "        if ctx.needs_input_grad[3]:\n",
    "            grad_b = a.t().matmul(grad_output)\n",
    "        return None, grad_values, None, grad_b\n",
    "\n",
    "\n",
    "class SpecialSpmm(nn.Module):\n",
    "    def forward(self, indices, values, shape, b):\n",
    "        return SpecialSpmmFunction.apply(indices, values, shape, b)\n",
    "\n",
    "\n",
    "class GraphAttnLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    Sparse version GAT layer, similar to https://arxiv.org/abs/1710.10903\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
    "        super(GraphAttnLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.alpha = alpha\n",
    "        self.concat = concat\n",
    "\n",
    "        self.W = nn.Parameter(torch.zeros(size=(in_features, out_features)))\n",
    "        nn.init.xavier_normal_(self.W.data, gain=1.414)\n",
    "\n",
    "        self.a = nn.Parameter(torch.zeros(size=(1, 2*out_features)))\n",
    "        nn.init.xavier_normal_(self.a.data, gain=1.414)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "        self.special_spmm = SpecialSpmm()\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        dv = 'cuda' if input.is_cuda else 'cpu'\n",
    "\n",
    "        N = input.size()[0]\n",
    "\n",
    "        if adj.shape[0] == adj.shape[1]:\n",
    "            edge = adj.nonzero().t()\n",
    "        else:\n",
    "            edge = adj\n",
    "\n",
    "#         mask = adj.byte()\n",
    "\n",
    "        h = torch.mm(input, self.W)\n",
    "        # h: N x out\n",
    "        assert not torch.isnan(h).any()\n",
    "\n",
    "        # Self-attention on the nodes - Shared attention mechanism\n",
    "        edge_h = torch.cat((h[edge[0, :], :], h[edge[1, :], :]), dim=1).t()\n",
    "        # edge: 2*D x E\n",
    "\n",
    "        values = self.leakyrelu(self.a.mm(edge_h).squeeze())\n",
    "\n",
    "        edge_e = scatter_softmax(values, edge[0])\n",
    "        assert not torch.isnan(edge_e).any()\n",
    "        # edge_e: E\n",
    "\n",
    "        edge_e = self.dropout(edge_e)\n",
    "        # edge_e: E\n",
    "\n",
    "        h_prime = self.special_spmm(edge, edge_e, torch.Size([N, N]), h)\n",
    "        assert not torch.isnan(h_prime).any()\n",
    "        # h_prime: N x out\n",
    "\n",
    "        if self.concat:\n",
    "            # if this layer is not last layer,\n",
    "            return F.elu(h_prime)\n",
    "        else:\n",
    "            # if this layer is last layer,\n",
    "            return h_prime\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' + str(self.in_features) + ' -> ' + str(self.out_features) + ')'\n",
    "\n",
    "\n",
    "class GraphAttn(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, out_features, dropout, alpha, concat=True):\n",
    "        super(GraphAttn, self).__init__()\n",
    "        self.attn = GraphAttnLayer(in_features, out_features, dropout, alpha, concat)\n",
    "        self.batch_norm = nn.BatchNorm1d(out_features)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "\n",
    "        out = self.attn(input, adj)\n",
    "        out_norm = self.batch_norm(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class MultiHeadGraphAttn(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head graph attention layer.\n",
    "\n",
    "    Args:\n",
    "    - n_head (int) - Number of heads for the attention layer.\n",
    "    - in_features (int) - Number of total input features.\n",
    "    - out_features (int) - Number of output features per head.\n",
    "    - dropout (bool) - P(keep) for dropout.\n",
    "    - alpha (float) - Alpha value for leaky ReLU.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_heads, in_features, out_features, dropout, alpha):\n",
    "        super(MultiHeadGraphAttn, self).__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.dropout = dropout\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # Operations\n",
    "        heads = [GraphAttn(in_features, out_features, dropout, alpha)\n",
    "                 for i in range(n_heads)]\n",
    "        self.attn_heads = nn.ModuleList(heads)\n",
    "\n",
    "    def forward(self, nodes, adj, cat_dim=1):\n",
    "        \"\"\"\n",
    "        Perform forward pass through multi-head graph attention layer.\n",
    "\n",
    "        Args:\n",
    "        - nodes (torch.FloatTensor) - Node feature matrix\n",
    "            (n_nodes, in_features).\n",
    "        - adj (torch.FloatTensor) - Adjacency matrix (n_nodes, n_nodes).\n",
    "\n",
    "        Returns:\n",
    "        - torch.FloatTensor of dimension (n_nodes, n_nodes) of attentional\n",
    "            coefficients where a_ij is the attention value of for node j with\n",
    "            respect to node i.\n",
    "        \"\"\"\n",
    "\n",
    "        if cat_dim == 1:\n",
    "            vals = torch.cat([head(nodes, adj) for head in self.attn_heads],\n",
    "                         dim = 1)\n",
    "\n",
    "        elif cat_dim == -1:\n",
    "            vals = torch.stack([head(nodes, adj) for head in self.attn_heads])\n",
    "\n",
    "        return vals\n",
    "\n",
    "\n",
    "class FCContactPred(nn.Module):\n",
    "    \"\"\"\n",
    "    Fully connected layer to perform contact prediction.\n",
    "\n",
    "    Args:\n",
    "    - node_features (int) - Number of input features.\n",
    "    - out_features (int) - Number of output prediction values.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, node_features, out_preds, layers=3):\n",
    "        super(FCContactPred, self).__init__()\n",
    "\n",
    "        self.linear_first = nn.Linear(node_features, 25, bias=True)\n",
    "\n",
    "        self.int_layers = nn.ModuleList([nn.Linear(25, 25, bias=True)\n",
    "                                         for i in range(layers - 2)])\n",
    "\n",
    "        self.linear_final = nn.Linear(25, out_preds, bias=True)\n",
    "\n",
    "    def forward(self, combined_nodes):\n",
    "        \"\"\"\n",
    "        Predict pointwise multichannel contacts from summarized pairwise\n",
    "        residue features.\n",
    "\n",
    "        Args:\n",
    "        - nodes (torch.FloatTensor) - Tensor of (convolved) node features\n",
    "            (n_pairwise, n_features).\n",
    "\n",
    "        Returns:\n",
    "        - torch.FloatTensor (n_contacts, n_channels) containing the prediction\n",
    "            for every potential contact point and every contact channel.\n",
    "        \"\"\"\n",
    "        # Get the logits from the linear layer\n",
    "        prelogits = self.linear_first(combined_nodes)\n",
    "        prelogits = F.relu(prelogits)\n",
    "\n",
    "        for layer in self.int_layers:\n",
    "            prelogits = layer(prelogits)\n",
    "            prelogits = F.relu(prelogits)\n",
    "\n",
    "        logits = self.linear_final(prelogits)\n",
    "\n",
    "        return logits\n",
    "\n",
    "\n",
    "class AttnLinkPredict(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head graph attention for link prediction.\n",
    "\n",
    "    Args:\n",
    "    - n_layers (int) - Number of layers.\n",
    "    - n_head (int) - Number of heads for the attention layer.\n",
    "    - in_features (int) - Number of total input features.\n",
    "    - out_features (int) - Number of output features per head.\n",
    "    - dropout (bool) - P(keep) for dropout.\n",
    "    - alpha (float) - Alpha value for leaky ReLU.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_layers, n_heads, in_features, out_features, dropout, alpha):\n",
    "        super(AttnLinkPredict, self).__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.dropout = dropout\n",
    "        self.alpha = alpha\n",
    "\n",
    "        layers = [MultiHeadGraphAttn(n_heads, in_features,\n",
    "                                     out_features, dropout,\n",
    "                                     alpha)]\n",
    "\n",
    "        layers.extend([MultiHeadGraphAttn(n_heads, n_heads * out_features,\n",
    "                                     out_features, dropout,\n",
    "                                     alpha)\n",
    "                      for i in range(n_layers - 1)])\n",
    "\n",
    "        self.attn_layers = nn.ModuleList(layers)\n",
    "\n",
    "        self.attn_batch_norm = nn.BatchNorm1d(n_heads * out_features)\n",
    "\n",
    "        self.output_linear = nn.Linear(n_heads * out_features, 8)\n",
    "\n",
    "    def forward(self, nodes, adjacency):\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for target1, target2 in it.combinations_with_replacement(range(len(nodes)), 2):\n",
    "            targets = adjacency[[target1, target2], :]\n",
    "\n",
    "            where = [target1, target2]\n",
    "            where.extend([ind for ind in np.where(targets.cpu() > 0)[1] if ind not in where])\n",
    "\n",
    "            out_adj_size = len(where) + 1\n",
    "            adj = torch.zeros(out_adj_size, out_adj_size)\n",
    "            adj[[0, 0, 1, 2], [1, 2, 0, 0]] = 1\n",
    "\n",
    "            neighbors = adjacency[where][:, where]\n",
    "            adj[1:, 1:] = neighbors\n",
    "\n",
    "            node_feats = nodes[where]\n",
    "\n",
    "            node_feats = torch.cat((torch.sum(node_feats[:2], dim=0, keepdim=True), node_feats), dim=0)\n",
    "\n",
    "            for layer in self.attn_layers:\n",
    "                node_feats = layer(node_feats, adj)\n",
    "\n",
    "            outputs.append(node_feats[0, :].unsqueeze(0))\n",
    "\n",
    "        linear_in = self.attn_batch_norm(torch.cat(outputs, dim=0))\n",
    "\n",
    "        return self.output_linear(linear_in)\n",
    "\n",
    "\n",
    "class LinkPredict(nn.Module):\n",
    "    \"\"\"\n",
    "    Multi-head graph attention for link prediction.\n",
    "\n",
    "    Args:\n",
    "    - n_layers (int) - Number of layers.\n",
    "    - n_head (int) - Number of heads for the attention layer.\n",
    "    - in_features (int) - Number of total input features.\n",
    "    - out_features (int) - Number of output features per head.\n",
    "    - dropout (bool) - P(keep) for dropout.\n",
    "    - alpha (float) - Alpha value for leaky ReLU.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_layers, n_heads, in_features, out_features, dropout, alpha):\n",
    "        super(AttnLinkPredict, self).__init__()\n",
    "\n",
    "        # Parameters\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.dropout = dropout\n",
    "        self.alpha = alpha\n",
    "\n",
    "        layers = [MultiHeadGraphAttn(n_heads, in_features,\n",
    "                                     out_features, dropout,\n",
    "                                     alpha)]\n",
    "\n",
    "        layers.extend([MultiHeadGraphAttn(n_heads, n_heads * out_features,\n",
    "                                     out_features, dropout,\n",
    "                                     alpha)\n",
    "                      for i in range(n_layers - 1)])\n",
    "\n",
    "        self.attn_layers = nn.ModuleList(layers)\n",
    "\n",
    "        self.attn_batch_norm = nn.BatchNorm1d(n_heads * out_features)\n",
    "\n",
    "        self.output_linear = nn.Linear(n_heads * out_features, 8)\n",
    "\n",
    "    def forward(self, nodes, adjacency):\n",
    "\n",
    "        outputs = []\n",
    "\n",
    "        for target1, target2 in it.combinations_with_replacement(range(len(nodes)), 2):\n",
    "            targets = adjacency[[target1, target2], :]\n",
    "\n",
    "            where = [target1, target2]\n",
    "            where.extend([ind for ind in np.where(targets.cpu() > 0)[1] if ind not in where])\n",
    "\n",
    "            out_adj_size = len(where) + 1\n",
    "            adj = torch.zeros(out_adj_size, out_adj_size)\n",
    "            adj[[0, 0, 1, 2], [1, 2, 0, 0]] = 1\n",
    "\n",
    "            neighbors = adjacency[where][:, where]\n",
    "            adj[1:, 1:] = neighbors\n",
    "\n",
    "            node_feats = nodes[where]\n",
    "\n",
    "            node_feats = torch.cat((torch.sum(node_feats[:2], dim=0, keepdim=True), node_feats), dim=0)\n",
    "\n",
    "            for layer in self.attn_layers:\n",
    "                node_feats = layer(node_feats, adj)\n",
    "\n",
    "            outputs.append(node_feats[0, :].unsqueeze(0))\n",
    "\n",
    "        linear_in = self.attn_batch_norm(torch.cat(outputs, dim=0))\n",
    "\n",
    "        return self.output_linear(linear_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HyQx2QqYbSlo"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NvIeIhAcbSlp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "########################################\n",
    "# Pairwise matrix generation functions #\n",
    "########################################\n",
    "\n",
    "def pairwise_mat(nodes, method='mean'):\n",
    "    \"\"\"\n",
    "    Generate matrix for pairwise determination of interactions.\n",
    "\n",
    "    Args:\n",
    "    - nodes (torch.FloatTensor) - Tensor of node (n_nodes, n_features) features.\n",
    "    - method (str) - One of 'sum' or 'mean' for combination startegy for\n",
    "        pairwise combination matrix (default = 'mean').\n",
    "\n",
    "    Returns:\n",
    "    - torch.FloatTensor of shape (n_pairwise, n_nodes) than can be used used to\n",
    "        combine feature vectors. Values are 1 if method == \"sum\" and 0.5 if\n",
    "        method == \"mean\".\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the upper triangle indices\n",
    "    triu = np.vstack(np.triu_indices(nodes.shape[0]))\n",
    "\n",
    "    # Loop through all indices and add to list with\n",
    "    idxs = torch.from_numpy(triu).T\n",
    "\n",
    "    # Convert to tensor\n",
    "    combos = torch.zeros([idxs.shape[0], nodes.shape[0]]).scatter(1, idxs, 1)\n",
    "\n",
    "    # Set to 0.5 if method is 'mean'\n",
    "    if method == 'mean':\n",
    "        combos *= 0.5\n",
    "\n",
    "    return combos.to(nodes.device)\n",
    "\n",
    "\n",
    "####################################\n",
    "# Pairwise concatenation functions #\n",
    "####################################\n",
    "\n",
    "def cat_pairwise(embeddings):\n",
    "\n",
    "    triu = np.vstack(np.triu_indices(embeddings.shape[0])).T\n",
    "\n",
    "    node1 = []\n",
    "    node2 = []\n",
    "\n",
    "    for i, j in triu:\n",
    "        node1.append(embeddings[i])\n",
    "        node2.append(embeddings[j])\n",
    "\n",
    "    node1 = torch.stack(node1, dim=0)\n",
    "    node2 = torch.flip(torch.stack(node2, dim=0), dims=(1,))\n",
    "\n",
    "    return torch.cat((node1, node2), dim=1)\n",
    "\n",
    "\n",
    "############################\n",
    "# Upper triangle functions #\n",
    "############################\n",
    "\n",
    "def triu_condense(input_tensor):\n",
    "    \"\"\"\n",
    "    Condense the upper triangle of a tensor into a 2d dense representation.\n",
    "\n",
    "    Args:\n",
    "    - input_tensor (torch.Tensor) - Tensor of shape (n, n, m).\n",
    "\n",
    "    Returns:\n",
    "    - Tensor of shape (n(n+1)/2, m) where elements along the third dimension in\n",
    "        the original tensor are packed row-wise according to the upper\n",
    "        triangular indices.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get upper triangle index info\n",
    "    row_idx, col_idx = np.triu_indices(input_tensor.shape[0])\n",
    "    row_idx = torch.LongTensor(row_idx)\n",
    "    col_idx = torch.LongTensor(col_idx)\n",
    "\n",
    "    # Return the packed matrix\n",
    "    output = input_tensor[row_idx, col_idx, :]\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def triu_expand(input_matrix):\n",
    "    \"\"\"\n",
    "    Expand a dense representation of the upper triangle of a tensor into\n",
    "    a 3D squareform representation.\n",
    "\n",
    "    Args:\n",
    "    - input_matrix (torch.Tensor) - Tensor of shape (n(n+1)/2, m).\n",
    "\n",
    "    Returns:\n",
    "    - Tensor of shape (n, n, m) where elements along the third dimension in the\n",
    "        original tensor are packed row-wise according to the upper triangular\n",
    "        indices.\n",
    "    \"\"\"\n",
    "    # Get the edge size n of the tensor\n",
    "    n_elements = input_matrix.shape[0]\n",
    "    n_chan = input_matrix.shape[1]\n",
    "    n_res = int((-1 + np.sqrt(1 + 4 * 2 * (n_elements))) / 2)\n",
    "\n",
    "    # Get upper triangle index info\n",
    "    row_idx, col_idx = np.triu_indices(n_res)\n",
    "    row_idx = torch.LongTensor(row_idx)\n",
    "    col_idx = torch.LongTensor(col_idx)\n",
    "\n",
    "    # Generate the output tensor\n",
    "    output = torch.zeros((n_res, n_res, n_chan), device=input_matrix.device)\n",
    "\n",
    "    # Input the triu values\n",
    "    for i in range(n_chan):\n",
    "        i_tens = torch.full((len(row_idx),), i, dtype=torch.long)\n",
    "        output.index_put_((row_idx, col_idx, i_tens), input_matrix[:, i])\n",
    "\n",
    "    # Input the tril values\n",
    "    for i in range(n_chan):\n",
    "        i_tens = torch.full((len(row_idx),), i, dtype=torch.long)\n",
    "        output.index_put_((col_idx, row_idx, i_tens), input_matrix[:, i])\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "#############\n",
    "# Kronecker #\n",
    "#############\n",
    "\n",
    "def kronecker_product(t1, t2, size_t1, size_t2):\n",
    "    fusion_tensor = torch.bmm(t1.unsqueeze(2), t2.unsqueeze(1))\n",
    "    fusion_tensor = fusion_tensor.view(-1, size_t1 * size_t2)\n",
    "    return fusion_tensor\n",
    "\n",
    "##############################\n",
    "# Leak adjacency information #\n",
    "##############################\n",
    "\n",
    "def res_adj_adjust(res_adj, res_contact, p):\n",
    "    res_adj = res_adj.squeeze()\n",
    "    res_contact = res_contact.squeeze()\n",
    "    dev = res_adj.device\n",
    "    keep = torch.full(res_adj.shape, p, device=dev)\n",
    "    out = torch.bernoulli(keep).bool()\n",
    "    mask = (torch.triu(out) + torch.triu(out).T) > 0\n",
    "    adj_out = (((mask.unsqueeze(-1) * res_contact).sum(dim=-1) \n",
    "            + torch.eye(mask.shape[0], device=dev)) > 0).float()\n",
    "    return adj_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mJZARlB3bSlt"
   },
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aZTJ299UbSlv"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch import autograd\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from tqdm import *\n",
    "import wandb\n",
    "\n",
    "import gc\n",
    "\n",
    "\n",
    "def track_mem():\n",
    "    for obj in gc.get_objects():\n",
    "        try:\n",
    "            if (torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data))) and hasattr(obj, '__name__'):\n",
    "                print(obj.__name__, obj.size())\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "class GAT(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, embed_features, atom_out_features, res_out_features,\n",
    "                 n_contact_channels, dropout, alpha, train_data, val_data,\n",
    "                 test_data):\n",
    "        super(GAT, self).__init__()\n",
    "\n",
    "        # Properties\n",
    "        self.embed_features = embed_features\n",
    "        self.atom_out_features = atom_out_features\n",
    "        self.res_out_features = res_out_features\n",
    "        self.n_contact_channels = n_contact_channels\n",
    "        self.dropout = dropout\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # Datasets\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "\n",
    "        # Model components\n",
    "        self.embed = AtomEmbed(embed_features, scale_grad_by_freq=True)\n",
    "\n",
    "        self.embed_batch_norm = nn.BatchNorm1d(embed_features)\n",
    "\n",
    "        # Define number of graph conv layers and heads\n",
    "        n_atom_layers = 5\n",
    "        n_atom_heads = 3\n",
    "\n",
    "        n_res_layers = 3\n",
    "        n_res_heads = 3\n",
    "\n",
    "        # Set up atom attention\n",
    "        self.atom_attns = nn.ModuleList([])\n",
    "        for i in range(n_atom_layers):\n",
    "            if i == 0:\n",
    "                attn_layer = MultiHeadGraphAttn(n_atom_heads, embed_features,\n",
    "                                                atom_out_features,\n",
    "                                                dropout, alpha)\n",
    "            else:\n",
    "                attn_layer = MultiHeadGraphAttn(n_atom_heads,\n",
    "                                                n_atom_heads * atom_out_features,\n",
    "                                                atom_out_features,\n",
    "                                                dropout, alpha)\n",
    "\n",
    "            self.atom_attns.append(attn_layer)\n",
    "\n",
    "\n",
    "        # Set up condensation\n",
    "        self.condense_batch_norm = nn.BatchNorm1d(n_atom_heads * atom_out_features)\n",
    "\n",
    "        # Set up res attention\n",
    "        self.res_attns = nn.ModuleList([])\n",
    "        for i in range(n_res_layers):\n",
    "            if i == 0:\n",
    "                attn_layer = MultiHeadGraphAttn(n_res_heads,\n",
    "                                                n_atom_heads * atom_out_features,\n",
    "                                                res_out_features, dropout,\n",
    "                                                alpha)\n",
    "            else:\n",
    "                attn_layer = MultiHeadGraphAttn(n_res_heads,\n",
    "                                                n_res_heads * res_out_features,\n",
    "                                                res_out_features, dropout,\n",
    "                                                alpha)\n",
    "\n",
    "            self.res_attns.append(attn_layer)\n",
    "\n",
    "        self.final_attn = MultiHeadGraphAttn(n_res_heads,\n",
    "                                             n_res_heads * res_out_features,\n",
    "                                             res_out_features, dropout,\n",
    "                                             alpha)\n",
    "        \n",
    "        self.batch_norm_pairwise = nn.BatchNorm1d(n_res_heads * res_out_features)\n",
    "        \n",
    "        self.conv = nn.Conv2d(30, 10, 3, stride=1, padding=1)\n",
    "        self.conv_batch_norm = nn.BatchNorm2d(10)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(10, 10, 3, stride=1, padding=1)\n",
    "        self.conv_batch_norm2 = nn.BatchNorm2d(10)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(10, 8, 3, stride=1, padding=1)\n",
    "\n",
    "        self.activation = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "        self.pred_contact_batch_norm = nn.BatchNorm1d(n_contact_channels)\n",
    "\n",
    "        self.activations = {}\n",
    "\n",
    "\n",
    "        # Validation information\n",
    "        self.reset_epoch_metrics()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "#         # Put on gpus\n",
    "#         self.embed.cuda(0)\n",
    "#         self.embed_batch_norm.cuda(0)\n",
    "#         [layer.cuda(0) for layer in self.atom_attns]\n",
    "# #         self.condense.cuda(0)\n",
    "#         self.condense_batch_norm.cuda(0)\n",
    "#         [layer.cuda(0) for layer in self.res_attns]\n",
    "#         self.final_attn.cuda(0)\n",
    "#         self.linear1.cuda(1)\n",
    "#         self.linear2.cuda(1)\n",
    "#         self.linear_predict.cuda(1)\n",
    "# #         self.conn_attn.cuda(1)\n",
    "#         self.pred_contact_batch_norm.cuda(1)\n",
    "\n",
    "        # Regular forward pass\n",
    "        atom_embed = self.embed(x['atom_nodes'].squeeze())\n",
    "\n",
    "        atom_embed_update = self.embed_batch_norm(atom_embed)\n",
    "\n",
    "        atom_adj = x['atom_adj'].squeeze()\n",
    "\n",
    "        for layer in self.atom_attns:\n",
    "                atom_embed_update = checkpoint(layer, atom_embed_update, atom_adj)\n",
    "\n",
    "        res_embed = torch.matmul(x['mem_mat'].squeeze(), atom_embed_update)\n",
    "\n",
    "        res_embed_update = self.condense_batch_norm(res_embed)\n",
    "\n",
    "        adj = x['res_adj'].squeeze()\n",
    "\n",
    "        for layer in self.res_attns:\n",
    "            res_embed_update = checkpoint(layer, res_embed_update, adj)\n",
    "\n",
    "        res_embed_update = self.final_attn(res_embed_update, adj)\n",
    "\n",
    "#         preds = torch.matmul(res_embed_update, res_embed_update.T).view(1, 1, res_embed_update.shape[0], -1)\n",
    "        \n",
    "        \n",
    "#         preds = kronecker_product(res_embed_update, res_embed_update.T, res_embed_update.shape, res_embed_update.T.shape)\n",
    "#         preds = res_embed_update.repeat(30, 1, 1).matmul(res_embed_update.T).unsqueeze(0)\n",
    "#         res_embed_update = res_embed_update.unsqueeze(1).repeat(1, res_embed_update.shape[0], 1)\n",
    "#         preds = (res_embed_update + res_embed_update.permute(1, 0, 2)).permute(2, 0, 1).unsqueeze(0)\n",
    "        \n",
    "        pairwise = pairwise_mat(res_embed_update, method='sum').matmul(res_embed_update)\n",
    "        pairwise = triu_expand(self.batch_norm_pairwise(pairwise)).permute(2, 0, 1).unsqueeze(0)\n",
    "        \n",
    "        preds = torch.relu(self.conv(pairwise))\n",
    "        preds = self.conv_batch_norm(preds)\n",
    "        preds = torch.relu(self.conv2(preds))\n",
    "        preds = self.conv_batch_norm2(preds)\n",
    "        preds = self.conv3(preds).squeeze(0).permute(1, 2, 0)\n",
    "        preds = preds + preds.permute(1, 0, 2)\n",
    "\n",
    "        preds = triu_condense(preds)\n",
    "\n",
    "        preds = self.pred_contact_batch_norm(preds)\n",
    "\n",
    "        return preds\n",
    "\n",
    "    def training_step(self, batch, batch_nb):\n",
    "        # REQUIRED\n",
    "        batch['res_adj'] = res_adj_adjust(batch['res_adj'], batch['res_contact'], 0.9)\n",
    "        \n",
    "        y_hat = self.forward(batch).squeeze()\n",
    "        y = triu_condense(batch['res_contact'].squeeze())\n",
    "        weights = triu_condense(batch['res_mask'].squeeze())\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y, weight=weights)\n",
    "\n",
    "        self.train_losses.append(loss.item())\n",
    "\n",
    "        return {'loss': loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_nb):\n",
    "        # OPTIONAL\n",
    "        batch['res_adj'] = res_adj_adjust(batch['res_adj'], batch['res_contact'], 0.9)\n",
    "        \n",
    "        y_hat = self.forward(batch).squeeze()\n",
    "        y = triu_condense(batch['res_contact'].squeeze())\n",
    "        weights = triu_condense(batch['res_mask'].squeeze())\n",
    "\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, y, weight=weights)\n",
    "\n",
    "        self.val_losses.append(loss.item())\n",
    "\n",
    "        _, _, auroc = calc_metric_curve(y_hat.sigmoid().cpu(), y.cpu(), 'ROC', squareform=False)\n",
    "        _, _, auprc = calc_metric_curve(y_hat.sigmoid().cpu(), y.cpu(), 'PRC', squareform=False)\n",
    "\n",
    "        self.auroc['Hydrophobic'].append(auroc[0])\n",
    "        self.auroc['Hydrogen bond'].append(auroc[1])\n",
    "        self.auroc['Van der Waals'].append(auroc[2])\n",
    "        self.auroc['Water bridges'].append(auroc[3])\n",
    "        self.auroc['Salt bridges'].append(auroc[4])\n",
    "        self.auroc['Pi-stacking'].append(auroc[5])\n",
    "        self.auroc['Pi-cation'].append(auroc[6])\n",
    "        self.auroc['T-stacking'].append(auroc[7])\n",
    "\n",
    "        self.auprc['Hydrophobic'].append(auprc[0])\n",
    "        self.auprc['Hydrogen bond'].append(auprc[1])\n",
    "        self.auprc['Van der Waals'].append(auprc[2])\n",
    "        self.auprc['Water bridges'].append(auprc[3])\n",
    "        self.auprc['Salt bridges'].append(auprc[4])\n",
    "        self.auprc['Pi-stacking'].append(auprc[5])\n",
    "        self.auprc['Pi-cation'].append(auprc[6])\n",
    "        self.auprc['T-stacking'].append(auprc[7])\n",
    "\n",
    "        self.pred_example.append(wandb.Image(plot_channels(triu_expand(y_hat.detach().cpu()))))\n",
    "\n",
    "    def on_post_performance_check(self):\n",
    "\n",
    "        epoch_metrics = {}\n",
    "        all_metrics = {}\n",
    "\n",
    "        for key in self.auroc:\n",
    "            values = np.asarray(self.auroc[key])\n",
    "            all_metrics[f'AUROC - {key}'] = values\n",
    "\n",
    "            values = values[~np.isnan(values)]\n",
    "            epoch_metrics[f'AUROC - {key}'] = wandb.Histogram(values)\n",
    "\n",
    "\n",
    "        for key in self.auprc:\n",
    "            values = np.asarray(self.auprc[key])\n",
    "            all_metrics[f'AUPRC - {key}'] = values\n",
    "\n",
    "            values = values[~np.isnan(values)]\n",
    "            epoch_metrics[f'AUPRC - {key}'] = wandb.Histogram(values)\n",
    "\n",
    "        epoch_metrics['Train Losses'] = wandb.Histogram(self.train_losses)\n",
    "\n",
    "        epoch_metrics['Val Losses'] = wandb.Histogram(self.val_losses)\n",
    "        all_metrics['Val Losses'] = np.asarray(self.val_losses)\n",
    "\n",
    "        all_metrics = pd.DataFrame(all_metrics)\n",
    "        cor_mat = all_metrics.corr()\n",
    "\n",
    "        corr_plot = metric_corr_plot(cor_mat)\n",
    "        epoch_metrics['Metric Corr Plot'] = wandb.Image(corr_plot)\n",
    "\n",
    "        epoch_metrics['train_loss'] = np.asarray(self.train_losses).mean()\n",
    "        epoch_metrics['val_loss'] = np.asarray(self.val_losses).mean()\n",
    "\n",
    "        epoch_metrics['Example Prediction'] = self.pred_example\n",
    "        epoch_metrics['Epoch'] = self.current_epoch\n",
    "\n",
    "        self.logger.experiment.log(epoch_metrics)\n",
    "\n",
    "        self.reset_epoch_metrics()\n",
    "\n",
    "    def reset_epoch_metrics(self):\n",
    "\n",
    "        # Validation information\n",
    "        self.auroc = {\n",
    "            'Hydrophobic': [],\n",
    "            'Hydrogen bond': [],\n",
    "            'Van der Waals': [],\n",
    "            'Water bridges': [],\n",
    "            'Salt bridges': [],\n",
    "            'Pi-stacking': [],\n",
    "            'Pi-cation': [],\n",
    "            'T-stacking': []\n",
    "        }\n",
    "\n",
    "        self.auprc = {\n",
    "            'Hydrophobic': [],\n",
    "            'Hydrogen bond': [],\n",
    "            'Van der Waals': [],\n",
    "            'Water bridges': [],\n",
    "            'Salt bridges': [],\n",
    "            'Pi-stacking': [],\n",
    "            'Pi-cation': [],\n",
    "            'T-stacking': []\n",
    "        }\n",
    "\n",
    "        self.val_losses = []\n",
    "        self.train_losses = []\n",
    "        self.pred_example = []\n",
    "\n",
    "\n",
    "#     def validation_end(self, outputs):\n",
    "#         # OPTIONAL\n",
    "# #         avg_loss = torch.stack([x['val_loss'] for x in outputs]).mean()\n",
    "# #         return {'avg_val_loss': avg_loss}\n",
    "#         pass\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # REQUIRED\n",
    "        # can return multiple optimizers and learning_rate schedulers\n",
    "\n",
    "        parameters = filter(lambda p: p.requires_grad, self.parameters())\n",
    "\n",
    "        return torch.optim.SGD(parameters, lr=0.1, momentum=0.9, weight_decay=1e-6)\n",
    "\n",
    "    @pl.data_loader\n",
    "    def train_dataloader(self):\n",
    "        # REQUIRED\n",
    "        return DataLoader(self.train_data, shuffle=True, num_workers=30, pin_memory=True)\n",
    "\n",
    "    @pl.data_loader\n",
    "    def val_dataloader(self):\n",
    "        # OPTIONAL\n",
    "        return DataLoader(self.val_data, shuffle=False, num_workers=20, pin_memory=True)\n",
    "\n",
    "#     def on_batch_end(self):\n",
    "#         wandb.log({key: plt.imshow(self.activations[key][:20]) for key in self.activations})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def plot_channels(values):\n",
    "    fig, ax = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))\n",
    "\n",
    "    ax = ax.flatten()\n",
    "\n",
    "    channel_names = [\n",
    "        'Hydrophobic',\n",
    "        'Hydrogen bond',\n",
    "        'Van der Waals',\n",
    "        'Water bridges',\n",
    "        'Salt bridges',\n",
    "        'Pi-stacking',\n",
    "        'Pi-cation',\n",
    "        'T-stacking'\n",
    "    ]\n",
    "\n",
    "    for channel in range(values.shape[-1]):\n",
    "        ax[channel].imshow(values[:, :, channel].squeeze(), vmin=0, vmax=1)\n",
    "        ax[channel].set(title=channel_names[channel], xlabel='Residue #', ylabel='Residue #')\n",
    "\n",
    "    plt.close()\n",
    "    return fig\n",
    "\n",
    "\n",
    "######################\n",
    "# ROC and PRC curves #\n",
    "######################\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc\n",
    "\n",
    "def calc_metric_curve(preds, target, curve_type, squareform=False):\n",
    "    \"\"\"\n",
    "    Calculate ROC or PRC curves and area for the predicted contact channels.\n",
    "\n",
    "    Args:\n",
    "    - preds (np.ndarray) - Numpy array of model predictions either of form\n",
    "        (n_res, n_res, n_chan) or (n_res * [n_res - 1] / 2, n_chan).\n",
    "    - target (np.ndarray) - Numpy array of target values either of form\n",
    "        (n_res, n_res, n_chan) or (n_res * [n_res - 1] / 2, n_chan),\n",
    "        must match form of preds.\n",
    "    - curve_type (str) - One of 'ROC' or 'PRC' to denote type of curve.\n",
    "    - squareform (bool) - True if tensors are of shape (n_res, n_res, n_chan),\n",
    "        False if they are of shape (n_res * [n_res - 1] / 2, n_chan)\n",
    "        (default = True).\n",
    "\n",
    "    Returns:\n",
    "    - Tuple of x, y, and AUC values to be used for plotting the curves\n",
    "        using plot_curve metric.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get correct curve function\n",
    "    if curve_type.upper() == 'ROC':\n",
    "        curve_func = roc_curve\n",
    "    elif curve_type.upper() == 'PRC':\n",
    "        curve_func = precision_recall_curve\n",
    "\n",
    "    # Generate dicts to hold outputs from curve generation functions\n",
    "    x = dict()\n",
    "    y = dict()\n",
    "    auc_ = dict()\n",
    "\n",
    "    # Handle case of squareform matrix (only get non-redundant triu indices)\n",
    "    if squareform:\n",
    "        indices = np.triu_indices(target.shape[0])\n",
    "\n",
    "    # For each channel\n",
    "    for i in range(target.shape[-1]):\n",
    "\n",
    "        # Handle case of squareform\n",
    "        if squareform:\n",
    "            var1, var2, _ = curve_func(target[:, :, i][indices],\n",
    "                                       preds[:, :, i][indices])\n",
    "\n",
    "        # Handle case of pairwise\n",
    "        else:\n",
    "            var1, var2, _ = curve_func(target[:, i], preds[:, i])\n",
    "\n",
    "        # Assign outputs to correct dict for plotting\n",
    "        if curve_type.upper() == 'ROC':\n",
    "            x[i] = var1\n",
    "            y[i] = var2\n",
    "        elif curve_type.upper() == 'PRC':\n",
    "            x[i] = var2\n",
    "            y[i] = var1\n",
    "\n",
    "        # Calc AUC\n",
    "        auc_[i] = auc(x[i], y[i])\n",
    "\n",
    "    return (x, y, auc_)\n",
    "\n",
    "\n",
    "def plot_curve_metric(x, y, auc, curve_type, title=None, labels=None):\n",
    "    \"\"\"\n",
    "    Plot ROC or PRC curves per output channel.\n",
    "\n",
    "    Args:\n",
    "    - x (dict) - Dict of numpy arrays for values to plot on x axis.\n",
    "    - y (dict) - Dict of numpy arrays for values to plot on x axis.\n",
    "    - auc (dict) - Dict of numpy arrays for areas under each curve.\n",
    "    - curve_type (str) - One of 'ROC' or 'PRC' to denote type of curve.\n",
    "    - title\n",
    "    - labels\n",
    "\n",
    "    Returns:\n",
    "    - pyplot object of curves.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate figure\n",
    "    plt.figure()\n",
    "\n",
    "    # Linetype spec\n",
    "    lw = 2\n",
    "    curve_type = curve_type.upper()\n",
    "\n",
    "    # Get the number of channels being plotted\n",
    "    n_chan = len(x)\n",
    "\n",
    "    # Make labels numeric if not provided\n",
    "    if labels is None:\n",
    "        labels = list(range(n_chan))\n",
    "\n",
    "    # Check to make sure the labels are the right length\n",
    "    if len(labels) != n_chan:\n",
    "        raise ValueError('Number of labels ({}) does not match number of prediction channels ({}).'.format(len(labels), n_chan))\n",
    "\n",
    "    # Get a lit of colors for all the channels\n",
    "    color_list = plt.cm.Set1(np.linspace(0, 1, n_chan))\n",
    "\n",
    "    # Plot each line\n",
    "    for i, color in enumerate(color_list):\n",
    "        plt.plot(x[i], y[i], color=color,\n",
    "                 lw=lw, label='{} (area = {:0.2f})'.format(labels[i], auc[i]))\n",
    "\n",
    "    # Add labels and diagonal line for ROC\n",
    "    if curve_type == 'ROC':\n",
    "        xlab = 'FPR'\n",
    "        ylab = 'TPR'\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.legend(loc=\"lower right\")\n",
    "\n",
    "    # Add labels for PRC\n",
    "    elif curve_type == 'PRC':\n",
    "        xlab = 'Recall'\n",
    "        ylab = 'Precision'\n",
    "        plt.legend(loc=\"lower left\")\n",
    "\n",
    "    # Extend limits, add labels and title\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel(xlab)\n",
    "    plt.ylabel(ylab)\n",
    "\n",
    "    if title is not None:\n",
    "        plt.title('{} for {}'.format(curve_type, title))\n",
    "    else:\n",
    "        plt.title('{}'.format(curve_type))\n",
    "\n",
    "    return plt.axes()\n",
    "\n",
    "def plot_curve(preds, target, curve_type, title=None, labels=None,\n",
    "               squareform=False):\n",
    "    \"\"\"\n",
    "    Wrapper to directly plot curves from model output and target.\n",
    "\n",
    "    Args:\n",
    "    - preds (np array-like) - Array or tensor of predicted values output by\n",
    "        model.\n",
    "    - target (np array-like) - Array or tensor of target values.\n",
    "    - curve_type (str) - One of 'ROC' or 'PRC'.\n",
    "    - title (str) - Title of plot (default = None).\n",
    "    - labels (list) - List of labels for each channel on the plot\n",
    "        (default = None).\n",
    "    - squareform (bool) - Whether the predictions and targets are in square form\n",
    "        (default = False).\n",
    "    \"\"\"\n",
    "    x, y, auc_ = calc_metric_curve(preds, target, curve_type, squareform)\n",
    "    return plot_curve_metric(x, y, auc_, curve_type, title, labels)\n",
    "\n",
    "\n",
    "################################\n",
    "# Correlations between metrics #\n",
    "################################\n",
    "\n",
    "def metric_corr_plot(corr):\n",
    "    mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(11, 9))\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=1.0, vmin = -1.0, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K3QZxiiHbSl1"
   },
   "source": [
    "## Training\n",
    "\n",
    "### Instantiate dataloader and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6gcL3lpbbSl3"
   },
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "data_base = '/home/tshimko/tesselate/'\n",
    "\n",
    "torch.manual_seed(10)\n",
    "\n",
    "data_load = [\n",
    "                'pdb_id',\n",
    "#                 'model',\n",
    "                'atom_nodes',\n",
    "                'atom_adj',\n",
    "#                 'atom_contact',\n",
    "#                 'atom_mask',\n",
    "                'res_adj',\n",
    "                'res_dist',\n",
    "                'chain_mem',\n",
    "                'res_contact',\n",
    "                'conn_adj',\n",
    "                'res_mask',\n",
    "                'mem_mat',\n",
    "#                 'idx2atom_dict',\n",
    "#                 'idx2res_dict'\n",
    "            ]\n",
    "\n",
    "# train_data = TesselateDataset(data_base + 'id_lists/ligand_free_monomers/small_train.txt',\n",
    "#                               graph_dir=data_base + 'data/graphs',\n",
    "#                               contacts_dir=data_base + 'data/contacts',\n",
    "#                               return_data=data_load, in_memory=False)\n",
    "\n",
    "train_data = TesselateDataset(data_base + 'test4.txt',\n",
    "                              graph_dir=data_base + 'data/graphs',\n",
    "                              contacts_dir=data_base + 'data/contacts',\n",
    "                              return_data=data_load, in_memory=True)\n",
    "\n",
    "# train_data = TesselateDataset(data_base + 'test3.txt',\n",
    "#                               graph_dir=data_base + 'data/graphs',\n",
    "#                               contacts_dir=data_base + 'data/contacts',\n",
    "#                               return_data=data_load, in_memory=True)\n",
    "\n",
    "# val_data = TesselateDataset(data_base + 'test3.txt',\n",
    "#                               graph_dir=data_base + 'data/graphs',\n",
    "#                               contacts_dir=data_base + 'data/contacts',\n",
    "#                               return_data=data_load, in_memory=True)\n",
    "\n",
    "val_data = TesselateDataset(data_base + 'id_lists/ligand_free_monomers/small_val.txt',\n",
    "                            graph_dir=data_base + 'data/graphs',\n",
    "                            contacts_dir=data_base + 'data/contacts',\n",
    "                            return_data=data_load, in_memory=True)\n",
    "\n",
    "\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=os.getcwd() + '/checkpoints',\n",
    "    save_top_k=0,\n",
    "    verbose=False,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    prefix=''\n",
    ")\n",
    "\n",
    "model = GAT(embed_features=10, atom_out_features=10, res_out_features=10,\n",
    "             n_contact_channels=8, dropout=0, alpha=0.2, train_data=train_data, val_data=val_data,\n",
    "             test_data=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11611,
     "status": "ok",
     "timestamp": 1574002255203,
     "user": {
      "displayName": "Tyler Carter Shimko",
      "photoUrl": "",
      "userId": "18332645348589660395"
     },
     "user_tz": -60
    },
    "id": "od4NiBExbSl7",
    "outputId": "5fc65a3e-de61-40e7-afdf-eb5de7e1ef4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:  51%|    | 55/107 [00:34<00:28,  1.81batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 1:  52%|    | 56/107 [00:37<01:08,  1.34s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  53%|    | 57/107 [00:40<01:24,  1.69s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  54%|    | 58/107 [00:41<01:15,  1.55s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  55%|    | 59/107 [00:42<01:09,  1.45s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  56%|    | 60/107 [00:43<01:06,  1.42s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  57%|    | 61/107 [00:44<00:58,  1.27s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  58%|    | 62/107 [00:46<01:01,  1.37s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  59%|    | 63/107 [00:47<00:52,  1.20s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  60%|    | 64/107 [00:48<00:48,  1.13s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  61%|    | 65/107 [00:49<00:47,  1.12s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  62%|   | 66/107 [00:50<00:46,  1.14s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  63%|   | 67/107 [00:51<00:45,  1.14s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  64%|   | 68/107 [00:52<00:41,  1.06s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  64%|   | 69/107 [00:53<00:40,  1.05s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  65%|   | 70/107 [00:54<00:38,  1.03s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  66%|   | 71/107 [00:55<00:40,  1.13s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  67%|   | 72/107 [00:57<00:42,  1.21s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  68%|   | 73/107 [00:57<00:36,  1.06s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  69%|   | 74/107 [00:58<00:34,  1.06s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  70%|   | 75/107 [00:59<00:30,  1.03batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  71%|   | 76/107 [01:00<00:28,  1.10batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  72%|  | 77/107 [01:01<00:27,  1.09batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  73%|  | 78/107 [01:02<00:31,  1.08s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  74%|  | 79/107 [01:03<00:27,  1.02batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  75%|  | 80/107 [01:05<00:30,  1.12s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  76%|  | 81/107 [01:05<00:25,  1.02batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  77%|  | 82/107 [01:06<00:23,  1.07batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  78%|  | 83/107 [01:07<00:22,  1.06batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  79%|  | 84/107 [01:08<00:20,  1.12batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  79%|  | 85/107 [01:09<00:18,  1.18batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  80%|  | 86/107 [01:09<00:17,  1.18batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  81%| | 87/107 [01:10<00:16,  1.22batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  82%| | 88/107 [01:11<00:15,  1.23batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  83%| | 89/107 [01:12<00:15,  1.18batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  84%| | 90/107 [01:13<00:15,  1.07batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  85%| | 91/107 [01:14<00:17,  1.09s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  86%| | 92/107 [01:16<00:18,  1.20s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  87%| | 93/107 [01:17<00:15,  1.08s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  88%| | 94/107 [01:18<00:14,  1.14s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  89%| | 95/107 [01:21<00:21,  1.81s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  90%| | 96/107 [01:22<00:17,  1.57s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  91%| | 97/107 [01:24<00:16,  1.62s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  92%|| 98/107 [01:25<00:12,  1.37s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  93%|| 99/107 [01:26<00:09,  1.21s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  93%|| 100/107 [01:27<00:07,  1.08s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  94%|| 101/107 [01:27<00:05,  1.01batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  95%|| 102/107 [01:28<00:05,  1.03s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  96%|| 103/107 [01:29<00:03,  1.01batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  97%|| 104/107 [01:31<00:03,  1.09s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  98%|| 105/107 [01:31<00:02,  1.01s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1:  99%|| 106/107 [01:33<00:01,  1.02s/batch, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 1: 100%|| 107/107 [01:37<00:00,  1.07batch/s, batch_idx=54, gpu=1, loss=0.528, v_num=d5ce3uok]\n",
      "Epoch 2:  51%|    | 55/107 [00:32<00:25,  2.03batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 2:  52%|    | 56/107 [00:36<01:10,  1.38s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  53%|    | 57/107 [00:38<01:22,  1.65s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  54%|    | 58/107 [00:39<01:11,  1.47s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  55%|    | 59/107 [00:40<01:06,  1.39s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  56%|    | 60/107 [00:42<01:02,  1.32s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  57%|    | 61/107 [00:42<00:54,  1.19s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  58%|    | 62/107 [00:44<00:56,  1.26s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  59%|    | 63/107 [00:45<00:50,  1.14s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  60%|    | 64/107 [00:46<00:46,  1.09s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  61%|    | 65/107 [00:47<00:41,  1.00batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  62%|   | 66/107 [00:48<00:42,  1.03s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  63%|   | 67/107 [00:49<00:40,  1.01s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  64%|   | 68/107 [00:50<00:49,  1.27s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  64%|   | 69/107 [00:51<00:45,  1.20s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  65%|   | 70/107 [00:52<00:41,  1.12s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  66%|   | 71/107 [00:54<00:42,  1.19s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  67%|   | 72/107 [00:55<00:40,  1.15s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  68%|   | 73/107 [00:55<00:34,  1.00s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  69%|   | 74/107 [00:57<00:33,  1.01s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  70%|   | 75/107 [00:57<00:29,  1.07batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  71%|   | 76/107 [00:58<00:27,  1.13batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  72%|  | 77/107 [00:59<00:26,  1.14batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  73%|  | 78/107 [01:00<00:30,  1.04s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  74%|  | 79/107 [01:01<00:26,  1.06batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  75%|  | 80/107 [01:02<00:25,  1.05batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  76%|  | 81/107 [01:03<00:22,  1.17batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  77%|  | 82/107 [01:03<00:20,  1.21batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  78%|  | 83/107 [01:04<00:20,  1.16batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  79%|  | 84/107 [01:05<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  79%|  | 85/107 [01:06<00:17,  1.26batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  80%|  | 86/107 [01:07<00:16,  1.25batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  81%| | 87/107 [01:07<00:15,  1.27batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  82%| | 88/107 [01:09<00:19,  1.05s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  83%| | 89/107 [01:10<00:17,  1.00batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  84%| | 90/107 [01:11<00:17,  1.03s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  85%| | 91/107 [01:12<00:15,  1.06batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  86%| | 92/107 [01:13<00:16,  1.11s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  87%| | 93/107 [01:14<00:14,  1.02s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  88%| | 94/107 [01:15<00:14,  1.09s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  89%| | 95/107 [01:19<00:21,  1.76s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  90%| | 96/107 [01:20<00:16,  1.51s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  91%| | 97/107 [01:21<00:15,  1.57s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  92%|| 98/107 [01:22<00:11,  1.33s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  93%|| 99/107 [01:23<00:09,  1.17s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  93%|| 100/107 [01:24<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  94%|| 101/107 [01:24<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  95%|| 102/107 [01:25<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  96%|| 103/107 [01:26<00:03,  1.08batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  97%|| 104/107 [01:27<00:02,  1.17batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  98%|| 105/107 [01:28<00:01,  1.20batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2:  99%|| 106/107 [01:29<00:00,  1.13batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 2: 100%|| 107/107 [01:33<00:00,  1.21batch/s, batch_idx=54, gpu=1, loss=0.468, v_num=d5ce3uok]\n",
      "Epoch 3:  51%|    | 55/107 [00:31<00:22,  2.26batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 3:  52%|    | 56/107 [00:35<01:11,  1.40s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  53%|    | 57/107 [00:37<01:29,  1.79s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  54%|    | 58/107 [00:38<01:16,  1.55s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  55%|    | 59/107 [00:40<01:15,  1.57s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  56%|    | 60/107 [00:42<01:27,  1.85s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  57%|    | 61/107 [00:43<01:12,  1.58s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  58%|    | 62/107 [00:45<01:08,  1.51s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  59%|    | 63/107 [00:46<00:56,  1.29s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  60%|    | 64/107 [00:47<00:51,  1.20s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  61%|    | 65/107 [00:47<00:45,  1.09s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  62%|   | 66/107 [00:49<00:45,  1.11s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  63%|   | 67/107 [00:50<00:42,  1.07s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  64%|   | 68/107 [00:50<00:39,  1.01s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  64%|   | 69/107 [00:51<00:38,  1.01s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  65%|   | 70/107 [00:52<00:36,  1.01batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  66%|   | 71/107 [00:54<00:39,  1.10s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  67%|   | 72/107 [00:55<00:38,  1.09s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  68%|   | 73/107 [00:55<00:32,  1.05batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  69%|   | 74/107 [00:56<00:32,  1.02batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  70%|   | 75/107 [00:57<00:29,  1.09batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  71%|   | 76/107 [00:58<00:27,  1.14batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  72%|  | 77/107 [00:59<00:26,  1.14batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  73%|  | 78/107 [01:00<00:30,  1.06s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  74%|  | 79/107 [01:01<00:26,  1.05batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  75%|  | 80/107 [01:02<00:26,  1.03batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  76%|  | 81/107 [01:03<00:22,  1.16batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  77%|  | 82/107 [01:03<00:21,  1.19batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  78%|  | 83/107 [01:04<00:20,  1.15batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  79%|  | 84/107 [01:05<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  79%|  | 85/107 [01:06<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  80%|  | 86/107 [01:07<00:17,  1.22batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  81%| | 87/107 [01:07<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  82%| | 88/107 [01:08<00:15,  1.26batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  83%| | 89/107 [01:09<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  84%| | 90/107 [01:10<00:15,  1.10batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  85%| | 91/107 [01:13<00:20,  1.31s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  86%| | 92/107 [01:14<00:20,  1.35s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  87%| | 93/107 [01:15<00:16,  1.17s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  88%| | 94/107 [01:16<00:15,  1.20s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  89%| | 95/107 [01:19<00:21,  1.83s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  90%| | 96/107 [01:20<00:17,  1.56s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  91%| | 97/107 [01:22<00:16,  1.61s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  92%|| 98/107 [01:23<00:12,  1.37s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  93%|| 99/107 [01:24<00:09,  1.20s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  93%|| 100/107 [01:24<00:07,  1.06s/batch, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  94%|| 101/107 [01:25<00:05,  1.04batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  95%|| 102/107 [01:26<00:04,  1.00batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  96%|| 103/107 [01:27<00:03,  1.07batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  97%|| 104/107 [01:28<00:02,  1.15batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  98%|| 105/107 [01:28<00:01,  1.19batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3:  99%|| 106/107 [01:29<00:00,  1.12batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 3: 100%|| 107/107 [01:33<00:00,  1.20batch/s, batch_idx=54, gpu=1, loss=0.425, v_num=d5ce3uok]\n",
      "Epoch 4:  51%|    | 55/107 [00:32<00:23,  2.25batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 4:  52%|    | 56/107 [00:36<01:15,  1.48s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  53%|    | 57/107 [00:38<01:27,  1.75s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  54%|    | 58/107 [00:39<01:15,  1.53s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  55%|    | 59/107 [00:41<01:18,  1.63s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  56%|    | 60/107 [00:42<01:07,  1.43s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  57%|    | 61/107 [00:43<00:59,  1.30s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  58%|    | 62/107 [00:45<00:58,  1.30s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  59%|    | 63/107 [00:45<00:49,  1.14s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  60%|    | 64/107 [00:46<00:46,  1.08s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  61%|    | 65/107 [00:47<00:41,  1.02batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  62%|   | 66/107 [00:48<00:41,  1.02s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  63%|   | 67/107 [00:49<00:40,  1.01s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  64%|   | 68/107 [00:50<00:37,  1.03batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  64%|   | 69/107 [00:51<00:38,  1.00s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  65%|   | 70/107 [00:52<00:36,  1.01batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  66%|   | 71/107 [00:53<00:39,  1.10s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  67%|   | 72/107 [00:54<00:37,  1.08s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  68%|   | 73/107 [00:55<00:32,  1.06batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  69%|   | 74/107 [00:56<00:32,  1.02batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  70%|   | 75/107 [00:57<00:29,  1.10batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  71%|   | 76/107 [00:58<00:26,  1.16batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  72%|  | 77/107 [01:01<00:45,  1.53s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  73%|  | 78/107 [01:02<00:43,  1.50s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  74%|  | 79/107 [01:03<00:35,  1.26s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  75%|  | 80/107 [01:04<00:31,  1.18s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  76%|  | 81/107 [01:04<00:26,  1.02s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  77%|  | 82/107 [01:05<00:23,  1.05batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  78%|  | 83/107 [01:06<00:22,  1.05batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  79%|  | 84/107 [01:07<00:20,  1.12batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  79%|  | 85/107 [01:08<00:18,  1.18batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  80%|  | 86/107 [01:09<00:17,  1.18batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  81%| | 87/107 [01:09<00:16,  1.21batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  82%| | 88/107 [01:10<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  83%| | 89/107 [01:11<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  84%| | 90/107 [01:12<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  85%| | 91/107 [01:13<00:13,  1.18batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  86%| | 92/107 [01:14<00:15,  1.03s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  87%| | 93/107 [01:15<00:13,  1.06batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  88%| | 94/107 [01:16<00:13,  1.03s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  89%| | 95/107 [01:19<00:20,  1.72s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  90%| | 96/107 [01:20<00:16,  1.49s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  91%| | 97/107 [01:22<00:15,  1.56s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  92%|| 98/107 [01:23<00:11,  1.32s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  93%|| 99/107 [01:24<00:09,  1.17s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  93%|| 100/107 [01:24<00:07,  1.03s/batch, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  94%|| 101/107 [01:25<00:05,  1.07batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  95%|| 102/107 [01:26<00:04,  1.02batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  96%|| 103/107 [01:27<00:03,  1.10batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  97%|| 104/107 [01:28<00:02,  1.17batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  98%|| 105/107 [01:28<00:01,  1.21batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4:  99%|| 106/107 [01:30<00:00,  1.13batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 4: 100%|| 107/107 [01:33<00:00,  1.20batch/s, batch_idx=54, gpu=1, loss=0.394, v_num=d5ce3uok]\n",
      "Epoch 5:  51%|    | 55/107 [00:32<00:23,  2.18batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 5:  52%|    | 56/107 [00:36<01:17,  1.52s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  53%|    | 57/107 [00:38<01:29,  1.79s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  54%|    | 58/107 [00:39<01:15,  1.55s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  55%|    | 59/107 [00:42<01:31,  1.91s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  56%|    | 60/107 [00:43<01:17,  1.66s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  57%|    | 61/107 [00:44<01:06,  1.45s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  58%|    | 62/107 [00:45<01:02,  1.39s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  59%|    | 63/107 [00:46<00:53,  1.21s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  60%|    | 64/107 [00:47<00:49,  1.16s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  61%|    | 65/107 [00:48<00:44,  1.06s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  62%|   | 66/107 [00:49<00:44,  1.09s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  63%|   | 67/107 [00:50<00:42,  1.05s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  64%|   | 68/107 [00:51<00:38,  1.00batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  64%|   | 69/107 [00:52<00:38,  1.00s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  65%|   | 70/107 [00:53<00:36,  1.01batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  66%|   | 71/107 [00:54<00:39,  1.09s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  67%|   | 72/107 [00:58<01:07,  1.93s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  68%|   | 73/107 [00:59<00:52,  1.56s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  69%|   | 74/107 [01:00<00:46,  1.40s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  70%|   | 75/107 [01:01<00:38,  1.21s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  71%|   | 76/107 [01:01<00:33,  1.08s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  72%|  | 77/107 [01:02<00:30,  1.02s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  73%|  | 78/107 [01:04<00:33,  1.14s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  74%|  | 79/107 [01:05<00:28,  1.01s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  75%|  | 80/107 [01:05<00:27,  1.00s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  76%|  | 81/107 [01:06<00:23,  1.12batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  77%|  | 82/107 [01:07<00:21,  1.17batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  78%|  | 83/107 [01:08<00:21,  1.14batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  79%|  | 84/107 [01:09<00:19,  1.20batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  79%|  | 85/107 [01:09<00:17,  1.25batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  80%|  | 86/107 [01:10<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  81%| | 87/107 [01:11<00:15,  1.28batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  82%| | 88/107 [01:12<00:14,  1.30batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  83%| | 89/107 [01:12<00:14,  1.25batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  84%| | 90/107 [01:14<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  85%| | 91/107 [01:14<00:13,  1.19batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  86%| | 92/107 [01:16<00:15,  1.02s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  87%| | 93/107 [01:16<00:13,  1.06batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  88%| | 94/107 [01:18<00:13,  1.04s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  89%| | 95/107 [01:21<00:21,  1.77s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  90%| | 96/107 [01:22<00:16,  1.55s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  91%| | 97/107 [01:24<00:16,  1.61s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  92%|| 98/107 [01:25<00:12,  1.36s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  93%|| 99/107 [01:26<00:09,  1.19s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  93%|| 100/107 [01:26<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  94%|| 101/107 [01:27<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  95%|| 102/107 [01:28<00:05,  1.00s/batch, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  96%|| 103/107 [01:29<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  97%|| 104/107 [01:30<00:02,  1.15batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  98%|| 105/107 [01:30<00:01,  1.19batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5:  99%|| 106/107 [01:31<00:00,  1.11batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 5: 100%|| 107/107 [01:35<00:00,  1.20batch/s, batch_idx=54, gpu=1, loss=0.368, v_num=d5ce3uok]\n",
      "Epoch 6:  51%|    | 55/107 [00:34<00:24,  2.13batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 6:  52%|    | 56/107 [00:39<01:25,  1.67s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  53%|    | 57/107 [00:41<01:38,  1.98s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  54%|    | 58/107 [00:42<01:22,  1.69s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  55%|    | 59/107 [00:44<01:14,  1.56s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  56%|    | 60/107 [00:45<01:05,  1.40s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  57%|    | 61/107 [00:45<00:57,  1.24s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  58%|    | 62/107 [00:47<00:57,  1.28s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  59%|    | 63/107 [00:48<00:49,  1.13s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  60%|    | 64/107 [00:49<00:46,  1.07s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  61%|    | 65/107 [00:49<00:41,  1.02batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  62%|   | 66/107 [00:50<00:41,  1.00s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  63%|   | 67/107 [00:51<00:40,  1.01s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  64%|   | 68/107 [00:52<00:37,  1.03batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  64%|   | 69/107 [00:53<00:37,  1.01batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  65%|   | 70/107 [00:54<00:36,  1.03batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  66%|   | 71/107 [00:56<00:39,  1.09s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  67%|   | 72/107 [00:57<00:37,  1.07s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  68%|   | 73/107 [00:57<00:31,  1.06batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  69%|   | 74/107 [00:58<00:32,  1.03batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  70%|   | 75/107 [00:59<00:29,  1.10batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  71%|   | 76/107 [01:00<00:26,  1.15batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  72%|  | 77/107 [01:01<00:26,  1.15batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  73%|  | 78/107 [01:06<01:00,  2.09s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  74%|  | 79/107 [01:06<00:46,  1.68s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  75%|  | 80/107 [01:07<00:39,  1.47s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  76%|  | 81/107 [01:08<00:31,  1.22s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  77%|  | 82/107 [01:09<00:27,  1.08s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  78%|  | 83/107 [01:10<00:25,  1.05s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  79%|  | 84/107 [01:11<00:22,  1.04batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  79%|  | 85/107 [01:11<00:19,  1.11batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  80%|  | 86/107 [01:12<00:18,  1.14batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  81%| | 87/107 [01:13<00:16,  1.19batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  82%| | 88/107 [01:14<00:15,  1.24batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  83%| | 89/107 [01:14<00:14,  1.22batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  84%| | 90/107 [01:16<00:15,  1.11batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  85%| | 91/107 [01:16<00:13,  1.16batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  86%| | 92/107 [01:18<00:15,  1.03s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  87%| | 93/107 [01:18<00:13,  1.05batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  88%| | 94/107 [01:20<00:13,  1.04s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  89%| | 95/107 [01:23<00:20,  1.72s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  90%| | 96/107 [01:24<00:16,  1.50s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  91%| | 97/107 [01:26<00:15,  1.56s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  92%|| 98/107 [01:26<00:11,  1.32s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  93%|| 99/107 [01:27<00:09,  1.16s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  93%|| 100/107 [01:28<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  94%|| 101/107 [01:29<00:05,  1.07batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  95%|| 102/107 [01:30<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  96%|| 103/107 [01:31<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  97%|| 104/107 [01:31<00:02,  1.17batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  98%|| 105/107 [01:32<00:01,  1.19batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6:  99%|| 106/107 [01:33<00:00,  1.11batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 6: 100%|| 107/107 [01:37<00:00,  1.18batch/s, batch_idx=54, gpu=1, loss=0.345, v_num=d5ce3uok]\n",
      "Epoch 7:  51%|    | 55/107 [00:32<00:24,  2.13batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 7:  52%|    | 56/107 [00:37<01:28,  1.74s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  53%|    | 57/107 [00:39<01:38,  1.97s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  54%|    | 58/107 [00:40<01:22,  1.68s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  55%|    | 59/107 [00:42<01:14,  1.54s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  56%|    | 60/107 [00:43<01:05,  1.39s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  57%|    | 61/107 [00:43<00:55,  1.22s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  58%|    | 62/107 [00:45<00:57,  1.27s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  59%|    | 63/107 [00:46<00:50,  1.14s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  60%|    | 64/107 [00:47<00:47,  1.09s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  61%|    | 65/107 [00:47<00:42,  1.00s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  62%|   | 66/107 [00:49<00:42,  1.04s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  63%|   | 67/107 [00:50<00:42,  1.05s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  64%|   | 68/107 [00:50<00:38,  1.00batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  64%|   | 69/107 [00:52<00:38,  1.01s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  65%|   | 70/107 [00:52<00:36,  1.01batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  66%|   | 71/107 [00:54<00:39,  1.11s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  67%|   | 72/107 [00:55<00:38,  1.09s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  68%|   | 73/107 [00:56<00:32,  1.04batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  69%|   | 74/107 [00:57<00:32,  1.00batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  70%|   | 75/107 [00:57<00:29,  1.08batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  71%|   | 76/107 [00:58<00:27,  1.14batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  72%|  | 77/107 [00:59<00:26,  1.13batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  73%|  | 78/107 [01:01<00:30,  1.05s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  74%|  | 79/107 [01:01<00:26,  1.05batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  75%|  | 80/107 [01:02<00:25,  1.04batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  76%|  | 81/107 [01:03<00:22,  1.16batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  77%|  | 82/107 [01:04<00:20,  1.20batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  78%|  | 83/107 [01:05<00:20,  1.16batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  79%|  | 84/107 [01:05<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  79%|  | 85/107 [01:06<00:17,  1.25batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  80%|  | 86/107 [01:07<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  81%| | 87/107 [01:08<00:15,  1.27batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  82%| | 88/107 [01:08<00:14,  1.30batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  83%| | 89/107 [01:09<00:14,  1.26batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  84%| | 90/107 [01:10<00:14,  1.14batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  85%| | 91/107 [01:11<00:13,  1.19batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  86%| | 92/107 [01:12<00:15,  1.02s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  87%| | 93/107 [01:13<00:13,  1.05batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  88%| | 94/107 [01:14<00:13,  1.04s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  89%| | 95/107 [01:18<00:20,  1.73s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  90%| | 96/107 [01:19<00:16,  1.50s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  91%| | 97/107 [01:20<00:15,  1.56s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  92%|| 98/107 [01:21<00:11,  1.32s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  93%|| 99/107 [01:26<00:19,  2.47s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  93%|| 100/107 [01:27<00:13,  1.95s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  94%|| 101/107 [01:28<00:09,  1.59s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  95%|| 102/107 [01:29<00:07,  1.45s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  96%|| 103/107 [01:30<00:04,  1.25s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  97%|| 104/107 [01:31<00:03,  1.10s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  98%|| 105/107 [01:31<00:02,  1.00s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7:  99%|| 106/107 [01:32<00:01,  1.01s/batch, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 7: 100%|| 107/107 [01:36<00:00,  1.09batch/s, batch_idx=54, gpu=1, loss=0.325, v_num=d5ce3uok]\n",
      "Epoch 8:  51%|    | 55/107 [00:34<00:23,  2.19batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 8:  52%|    | 56/107 [00:39<01:30,  1.77s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  53%|    | 57/107 [00:41<01:37,  1.95s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  54%|    | 58/107 [00:42<01:22,  1.68s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  55%|    | 59/107 [00:43<01:14,  1.56s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  56%|    | 60/107 [00:44<01:05,  1.40s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  57%|    | 61/107 [00:45<00:57,  1.24s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  58%|    | 62/107 [00:47<00:58,  1.31s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  59%|    | 63/107 [00:47<00:51,  1.16s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  60%|    | 64/107 [00:48<00:48,  1.14s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  61%|    | 65/107 [00:49<00:43,  1.02s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  62%|   | 66/107 [00:50<00:43,  1.06s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  63%|   | 67/107 [00:51<00:41,  1.03s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  64%|   | 68/107 [00:52<00:38,  1.02batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  64%|   | 69/107 [00:53<00:37,  1.01batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  65%|   | 70/107 [00:54<00:35,  1.03batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  66%|   | 71/107 [00:55<00:38,  1.07s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  67%|   | 72/107 [00:56<00:36,  1.05s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  68%|   | 73/107 [00:57<00:31,  1.08batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  69%|   | 74/107 [00:58<00:32,  1.03batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  70%|   | 75/107 [00:59<00:29,  1.10batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  71%|   | 76/107 [01:00<00:26,  1.15batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  72%|  | 77/107 [01:01<00:26,  1.15batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  73%|  | 78/107 [01:02<00:30,  1.04s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  74%|  | 79/107 [01:03<00:26,  1.06batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  75%|  | 80/107 [01:04<00:25,  1.05batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  76%|  | 81/107 [01:04<00:22,  1.18batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  77%|  | 82/107 [01:05<00:20,  1.21batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  78%|  | 83/107 [01:06<00:20,  1.16batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  79%|  | 84/107 [01:07<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  79%|  | 85/107 [01:08<00:17,  1.24batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  80%|  | 86/107 [01:08<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  81%| | 87/107 [01:09<00:15,  1.27batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  82%| | 88/107 [01:10<00:14,  1.30batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  83%| | 89/107 [01:11<00:14,  1.27batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  84%| | 90/107 [01:12<00:14,  1.14batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  85%| | 91/107 [01:12<00:13,  1.20batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  86%| | 92/107 [01:14<00:15,  1.01s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  87%| | 93/107 [01:15<00:13,  1.08batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  88%| | 94/107 [01:16<00:13,  1.02s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  89%| | 95/107 [01:19<00:20,  1.70s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  90%| | 96/107 [01:20<00:16,  1.48s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  91%| | 97/107 [01:22<00:15,  1.55s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  92%|| 98/107 [01:23<00:11,  1.31s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  93%|| 99/107 [01:23<00:09,  1.16s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  93%|| 100/107 [01:24<00:07,  1.03s/batch, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  94%|| 101/107 [01:25<00:05,  1.07batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  95%|| 102/107 [01:26<00:04,  1.02batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  96%|| 103/107 [01:27<00:03,  1.11batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  97%|| 104/107 [01:27<00:02,  1.19batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  98%|| 105/107 [01:28<00:01,  1.21batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8:  99%|| 106/107 [01:29<00:00,  1.13batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 8: 100%|| 107/107 [01:33<00:00,  1.22batch/s, batch_idx=54, gpu=1, loss=0.306, v_num=d5ce3uok]\n",
      "Epoch 9:  51%|    | 55/107 [00:33<00:24,  2.10batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 9:  52%|    | 56/107 [00:38<01:33,  1.84s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  53%|    | 57/107 [00:40<01:35,  1.92s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  54%|    | 58/107 [00:41<01:19,  1.63s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  55%|    | 59/107 [00:42<01:12,  1.52s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  56%|    | 60/107 [00:43<01:04,  1.36s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  57%|    | 61/107 [00:44<00:55,  1.21s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  58%|    | 62/107 [00:45<00:57,  1.29s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  59%|    | 63/107 [00:46<00:50,  1.15s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  60%|    | 64/107 [00:47<00:47,  1.10s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  61%|    | 65/107 [00:48<00:42,  1.01s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  62%|   | 66/107 [00:49<00:41,  1.01s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  63%|   | 67/107 [00:50<00:40,  1.01s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  64%|   | 68/107 [00:51<00:39,  1.00s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  64%|   | 69/107 [00:52<00:38,  1.02s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  65%|   | 70/107 [00:53<00:36,  1.00batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  66%|   | 71/107 [00:54<00:39,  1.10s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  67%|   | 72/107 [00:55<00:38,  1.09s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  68%|   | 73/107 [00:56<00:32,  1.04batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  69%|   | 74/107 [00:57<00:32,  1.02batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  70%|   | 75/107 [00:58<00:29,  1.10batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  71%|   | 76/107 [00:59<00:27,  1.13batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  72%|  | 77/107 [01:00<00:26,  1.12batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  73%|  | 78/107 [01:01<00:30,  1.06s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  74%|  | 79/107 [01:02<00:26,  1.04batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  75%|  | 80/107 [01:03<00:26,  1.04batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  76%|  | 81/107 [01:03<00:22,  1.16batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  77%|  | 82/107 [01:04<00:20,  1.20batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  78%|  | 83/107 [01:05<00:20,  1.15batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  79%|  | 84/107 [01:06<00:19,  1.21batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  79%|  | 85/107 [01:12<00:54,  2.46s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  80%|  | 86/107 [01:13<00:41,  1.98s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  81%| | 87/107 [01:14<00:32,  1.61s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  82%| | 88/107 [01:14<00:25,  1.35s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  83%| | 89/107 [01:15<00:21,  1.20s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  84%| | 90/107 [01:16<00:19,  1.17s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  85%| | 91/107 [01:17<00:16,  1.05s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  86%| | 92/107 [01:19<00:17,  1.18s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  87%| | 93/107 [01:19<00:14,  1.05s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  88%| | 94/107 [01:21<00:14,  1.11s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  89%| | 95/107 [01:24<00:21,  1.78s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  90%| | 96/107 [01:25<00:17,  1.56s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  91%| | 97/107 [01:27<00:16,  1.61s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  92%|| 98/107 [01:28<00:12,  1.35s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  93%|| 99/107 [01:28<00:09,  1.19s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  93%|| 100/107 [01:29<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  94%|| 101/107 [01:30<00:05,  1.05batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  95%|| 102/107 [01:31<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  96%|| 103/107 [01:32<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  97%|| 104/107 [01:32<00:02,  1.16batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  98%|| 105/107 [01:33<00:01,  1.18batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9:  99%|| 106/107 [01:34<00:00,  1.08batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 9: 100%|| 107/107 [01:38<00:00,  1.17batch/s, batch_idx=54, gpu=1, loss=0.291, v_num=d5ce3uok]\n",
      "Epoch 10:  51%|    | 55/107 [00:34<00:24,  2.12batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 10:  52%|    | 56/107 [00:39<01:36,  1.89s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  53%|    | 57/107 [00:42<01:44,  2.10s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  54%|    | 58/107 [00:43<01:26,  1.77s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  55%|    | 59/107 [00:44<01:16,  1.59s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  56%|    | 60/107 [00:45<01:07,  1.44s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  57%|    | 61/107 [00:46<00:58,  1.28s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  58%|    | 62/107 [00:47<00:58,  1.29s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  59%|    | 63/107 [00:48<00:49,  1.13s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  60%|    | 64/107 [00:49<00:46,  1.07s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  61%|    | 65/107 [00:50<00:41,  1.01batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  62%|   | 66/107 [00:51<00:41,  1.02s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  63%|   | 67/107 [00:52<00:42,  1.06s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  64%|   | 68/107 [00:53<00:39,  1.00s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  64%|   | 69/107 [00:54<00:38,  1.02s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  65%|   | 70/107 [00:55<00:37,  1.00s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  66%|   | 71/107 [00:56<00:40,  1.12s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  67%|   | 72/107 [00:57<00:38,  1.10s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  68%|   | 73/107 [00:58<00:32,  1.03batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  69%|   | 74/107 [00:59<00:32,  1.01batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  70%|   | 75/107 [01:00<00:29,  1.09batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  71%|   | 76/107 [01:00<00:28,  1.11batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  72%|  | 77/107 [01:01<00:27,  1.10batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  73%|  | 78/107 [01:03<00:31,  1.07s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  74%|  | 79/107 [01:04<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  75%|  | 80/107 [01:05<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  76%|  | 81/107 [01:05<00:22,  1.15batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  77%|  | 82/107 [01:06<00:21,  1.18batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  78%|  | 83/107 [01:07<00:21,  1.14batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  79%|  | 84/107 [01:08<00:19,  1.20batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  79%|  | 85/107 [01:08<00:17,  1.24batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  80%|  | 86/107 [01:09<00:17,  1.22batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  81%| | 87/107 [01:10<00:16,  1.25batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  82%| | 88/107 [01:11<00:14,  1.28batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  83%| | 89/107 [01:12<00:14,  1.24batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  84%| | 90/107 [01:13<00:15,  1.13batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  85%| | 91/107 [01:13<00:13,  1.17batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  86%| | 92/107 [01:15<00:15,  1.04s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  87%| | 93/107 [01:16<00:13,  1.04batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  88%| | 94/107 [01:17<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  89%| | 95/107 [01:20<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  90%| | 96/107 [01:21<00:16,  1.52s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  91%| | 97/107 [01:23<00:15,  1.59s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  92%|| 98/107 [01:24<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  93%|| 99/107 [01:25<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  93%|| 100/107 [01:25<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  94%|| 101/107 [01:26<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  95%|| 102/107 [01:27<00:04,  1.02batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  96%|| 103/107 [01:28<00:03,  1.10batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  97%|| 104/107 [01:29<00:02,  1.17batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  98%|| 105/107 [01:29<00:01,  1.19batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10:  99%|| 106/107 [01:31<00:00,  1.09batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 10: 100%|| 107/107 [01:35<00:00,  1.18batch/s, batch_idx=54, gpu=1, loss=0.278, v_num=d5ce3uok]\n",
      "Epoch 11:  51%|    | 55/107 [00:34<00:25,  2.08batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 11:  52%|    | 56/107 [00:39<01:36,  1.90s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  53%|    | 57/107 [00:42<01:42,  2.04s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  54%|    | 58/107 [00:43<01:26,  1.76s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  55%|    | 59/107 [00:44<01:18,  1.63s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  56%|    | 60/107 [00:45<01:08,  1.45s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  57%|    | 61/107 [00:46<00:58,  1.28s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  58%|    | 62/107 [00:47<00:59,  1.32s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  59%|    | 63/107 [00:48<00:51,  1.17s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  60%|    | 64/107 [00:49<00:47,  1.11s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  61%|    | 65/107 [00:50<00:42,  1.01s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  62%|   | 66/107 [00:51<00:42,  1.04s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  63%|   | 67/107 [00:52<00:41,  1.04s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  64%|   | 68/107 [00:53<00:40,  1.05s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  64%|   | 69/107 [00:54<00:40,  1.07s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  65%|   | 70/107 [00:55<00:38,  1.04s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  66%|   | 71/107 [00:57<00:40,  1.13s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  67%|   | 72/107 [00:58<00:39,  1.12s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  68%|   | 73/107 [00:59<00:33,  1.01batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  69%|   | 74/107 [01:00<00:34,  1.03s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  70%|   | 75/107 [01:00<00:30,  1.05batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  71%|   | 76/107 [01:01<00:28,  1.09batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  72%|  | 77/107 [01:02<00:27,  1.09batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  73%|  | 78/107 [01:04<00:31,  1.09s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  74%|  | 79/107 [01:04<00:27,  1.02batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  75%|  | 80/107 [01:05<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  76%|  | 81/107 [01:06<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  77%|  | 82/107 [01:07<00:21,  1.18batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  78%|  | 83/107 [01:08<00:20,  1.14batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  79%|  | 84/107 [01:08<00:19,  1.20batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  79%|  | 85/107 [01:09<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  80%|  | 86/107 [01:10<00:17,  1.21batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  81%| | 87/107 [01:11<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  82%| | 88/107 [01:12<00:14,  1.28batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  83%| | 89/107 [01:12<00:14,  1.25batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  84%| | 90/107 [01:13<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  85%| | 91/107 [01:14<00:13,  1.17batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  86%| | 92/107 [01:23<00:47,  3.18s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  87%| | 93/107 [01:24<00:34,  2.46s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  88%| | 94/107 [01:25<00:27,  2.10s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  89%| | 95/107 [01:28<00:29,  2.46s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  90%| | 96/107 [01:29<00:22,  2.03s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  91%| | 97/107 [01:31<00:19,  1.94s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  92%|| 98/107 [01:32<00:14,  1.58s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  93%|| 99/107 [01:33<00:10,  1.35s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  93%|| 100/107 [01:33<00:08,  1.16s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  94%|| 101/107 [01:34<00:06,  1.04s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  95%|| 102/107 [01:35<00:05,  1.06s/batch, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  96%|| 103/107 [01:36<00:03,  1.04batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  97%|| 104/107 [01:37<00:02,  1.13batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  98%|| 105/107 [01:37<00:01,  1.16batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11:  99%|| 106/107 [01:38<00:00,  1.09batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 11: 100%|| 107/107 [01:42<00:00,  1.17batch/s, batch_idx=54, gpu=1, loss=0.266, v_num=d5ce3uok]\n",
      "Epoch 12:  51%|    | 55/107 [00:35<00:26,  2.00batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 12:  52%|    | 56/107 [00:41<01:46,  2.09s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  53%|    | 57/107 [00:45<02:15,  2.70s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  54%|    | 58/107 [00:46<01:46,  2.17s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  55%|    | 59/107 [00:47<01:30,  1.88s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  56%|    | 60/107 [00:48<01:16,  1.62s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  57%|    | 61/107 [00:49<01:02,  1.37s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  58%|    | 62/107 [00:50<01:00,  1.34s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  59%|    | 63/107 [00:51<00:51,  1.16s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  60%|    | 64/107 [00:52<00:48,  1.12s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  61%|    | 65/107 [00:53<00:44,  1.07s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  62%|   | 66/107 [00:54<00:44,  1.09s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  63%|   | 67/107 [00:55<00:42,  1.06s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  64%|   | 68/107 [00:56<00:39,  1.01s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  64%|   | 69/107 [00:57<00:39,  1.03s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  65%|   | 70/107 [00:58<00:37,  1.00s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  66%|   | 71/107 [00:59<00:39,  1.11s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  67%|   | 72/107 [01:00<00:38,  1.10s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  68%|   | 73/107 [01:01<00:32,  1.03batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  69%|   | 74/107 [01:02<00:32,  1.01batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  70%|   | 75/107 [01:03<00:29,  1.08batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  71%|   | 76/107 [01:04<00:28,  1.11batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  72%|  | 77/107 [01:04<00:27,  1.09batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  73%|  | 78/107 [01:06<00:31,  1.09s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  74%|  | 79/107 [01:07<00:27,  1.02batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  75%|  | 80/107 [01:08<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  76%|  | 81/107 [01:08<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  77%|  | 82/107 [01:09<00:21,  1.17batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  78%|  | 83/107 [01:10<00:21,  1.12batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  79%|  | 84/107 [01:11<00:19,  1.18batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  79%|  | 85/107 [01:12<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  80%|  | 86/107 [01:12<00:17,  1.20batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  81%| | 87/107 [01:13<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  82%| | 88/107 [01:14<00:14,  1.27batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  83%| | 89/107 [01:15<00:14,  1.22batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  84%| | 90/107 [01:16<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  85%| | 91/107 [01:17<00:13,  1.16batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  86%| | 92/107 [01:18<00:15,  1.03s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  87%| | 93/107 [01:19<00:13,  1.06batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  88%| | 94/107 [01:20<00:13,  1.03s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  89%| | 95/107 [01:23<00:20,  1.73s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  90%| | 96/107 [01:24<00:16,  1.52s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  91%| | 97/107 [01:26<00:15,  1.59s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  92%|| 98/107 [01:27<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  93%|| 99/107 [01:28<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  93%|| 100/107 [01:29<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  94%|| 101/107 [01:29<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  95%|| 102/107 [01:30<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  96%|| 103/107 [01:31<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  97%|| 104/107 [01:32<00:02,  1.14batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  98%|| 105/107 [01:33<00:01,  1.16batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12:  99%|| 106/107 [01:34<00:00,  1.08batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 12: 100%|| 107/107 [01:38<00:00,  1.15batch/s, batch_idx=54, gpu=1, loss=0.255, v_num=d5ce3uok]\n",
      "Epoch 13:  51%|    | 55/107 [00:34<00:23,  2.23batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 13:  52%|    | 56/107 [00:40<01:45,  2.06s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  53%|    | 57/107 [00:42<01:47,  2.14s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  54%|    | 58/107 [00:43<01:29,  1.83s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  55%|    | 59/107 [00:44<01:19,  1.66s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  56%|    | 60/107 [00:45<01:10,  1.49s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  57%|    | 61/107 [00:46<01:00,  1.31s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  58%|    | 62/107 [00:48<01:00,  1.35s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  59%|    | 63/107 [00:48<00:51,  1.16s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  60%|    | 64/107 [00:49<00:47,  1.11s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  61%|    | 65/107 [00:50<00:43,  1.02s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  62%|   | 66/107 [00:51<00:44,  1.08s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  63%|   | 67/107 [00:53<00:43,  1.08s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  64%|   | 68/107 [00:53<00:40,  1.04s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  64%|   | 69/107 [00:55<00:39,  1.04s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  65%|   | 70/107 [00:55<00:37,  1.01s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  66%|   | 71/107 [00:57<00:39,  1.11s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  67%|   | 72/107 [00:58<00:38,  1.10s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  68%|   | 73/107 [00:59<00:33,  1.03batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  69%|   | 74/107 [01:00<00:32,  1.00batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  70%|   | 75/107 [01:00<00:29,  1.08batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  71%|   | 76/107 [01:01<00:27,  1.11batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  72%|  | 77/107 [01:02<00:27,  1.11batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  73%|  | 78/107 [01:04<00:30,  1.06s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  74%|  | 79/107 [01:04<00:26,  1.04batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  75%|  | 80/107 [01:05<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  76%|  | 81/107 [01:06<00:22,  1.15batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  77%|  | 82/107 [01:07<00:21,  1.19batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  78%|  | 83/107 [01:08<00:20,  1.15batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  79%|  | 84/107 [01:08<00:19,  1.20batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  79%|  | 85/107 [01:09<00:17,  1.24batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  80%|  | 86/107 [01:10<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  81%| | 87/107 [01:11<00:15,  1.26batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  82%| | 88/107 [01:11<00:14,  1.28batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  83%| | 89/107 [01:12<00:14,  1.25batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  84%| | 90/107 [01:13<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  85%| | 91/107 [01:14<00:13,  1.18batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  86%| | 92/107 [01:16<00:15,  1.04s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  87%| | 93/107 [01:16<00:13,  1.04batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  88%| | 94/107 [01:18<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  89%| | 95/107 [01:21<00:20,  1.73s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  90%| | 96/107 [01:22<00:16,  1.52s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  91%| | 97/107 [01:24<00:15,  1.58s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  92%|| 98/107 [01:24<00:11,  1.33s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  93%|| 99/107 [01:25<00:09,  1.17s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  93%|| 100/107 [01:26<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  94%|| 101/107 [01:27<00:05,  1.07batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  95%|| 102/107 [01:28<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  96%|| 103/107 [01:29<00:03,  1.10batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  97%|| 104/107 [01:29<00:02,  1.17batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  98%|| 105/107 [01:30<00:01,  1.19batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13:  99%|| 106/107 [01:31<00:00,  1.10batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 13: 100%|| 107/107 [01:35<00:00,  1.19batch/s, batch_idx=54, gpu=1, loss=0.244, v_num=d5ce3uok]\n",
      "Epoch 14:  51%|    | 55/107 [00:34<00:25,  2.06batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 14:  52%|    | 56/107 [00:39<01:46,  2.09s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  53%|    | 57/107 [00:43<01:59,  2.39s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  54%|    | 58/107 [00:44<01:37,  1.99s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  55%|    | 59/107 [00:45<01:23,  1.73s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  56%|    | 60/107 [00:46<01:11,  1.53s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  57%|    | 61/107 [00:47<01:01,  1.34s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  58%|    | 62/107 [00:48<00:59,  1.32s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  59%|    | 63/107 [00:49<00:51,  1.16s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  60%|    | 64/107 [00:50<00:47,  1.11s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  61%|    | 65/107 [00:50<00:42,  1.01s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  62%|   | 66/107 [00:52<00:42,  1.03s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  63%|   | 67/107 [00:53<00:41,  1.04s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  64%|   | 68/107 [00:54<00:39,  1.00s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  64%|   | 69/107 [00:55<00:39,  1.03s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  65%|   | 70/107 [00:56<00:36,  1.01batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  66%|   | 71/107 [00:57<00:39,  1.09s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  67%|   | 72/107 [00:58<00:37,  1.07s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  68%|   | 73/107 [00:59<00:32,  1.05batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  69%|   | 74/107 [01:08<02:00,  3.64s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  70%|   | 75/107 [01:09<01:28,  2.78s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  71%|   | 76/107 [01:10<01:07,  2.19s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  72%|  | 77/107 [01:11<00:54,  1.81s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  73%|  | 78/107 [01:12<00:49,  1.70s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  74%|  | 79/107 [01:13<00:39,  1.41s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  75%|  | 80/107 [01:14<00:34,  1.28s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  76%|  | 81/107 [01:15<00:28,  1.08s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  77%|  | 82/107 [01:16<00:24,  1.01batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  78%|  | 83/107 [01:16<00:23,  1.02batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  79%|  | 84/107 [01:17<00:20,  1.10batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  79%|  | 85/107 [01:18<00:18,  1.16batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  80%|  | 86/107 [01:19<00:17,  1.17batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  81%| | 87/107 [01:20<00:16,  1.21batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  82%| | 88/107 [01:20<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  83%| | 89/107 [01:21<00:14,  1.22batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  84%| | 90/107 [01:22<00:15,  1.11batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  85%| | 91/107 [01:23<00:13,  1.17batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  86%| | 92/107 [01:24<00:15,  1.04s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  87%| | 93/107 [01:25<00:13,  1.05batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  88%| | 94/107 [01:27<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  89%| | 95/107 [01:30<00:20,  1.73s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  90%| | 96/107 [01:31<00:16,  1.52s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  91%| | 97/107 [01:33<00:15,  1.58s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  92%|| 98/107 [01:33<00:11,  1.33s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  93%|| 99/107 [01:34<00:09,  1.17s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  93%|| 100/107 [01:35<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  94%|| 101/107 [01:36<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  95%|| 102/107 [01:37<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  96%|| 103/107 [01:37<00:03,  1.10batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  97%|| 104/107 [01:38<00:02,  1.17batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  98%|| 105/107 [01:39<00:01,  1.19batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14:  99%|| 106/107 [01:40<00:00,  1.10batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 14: 100%|| 107/107 [01:44<00:00,  1.16batch/s, batch_idx=54, gpu=1, loss=0.235, v_num=d5ce3uok]\n",
      "Epoch 15:  51%|    | 55/107 [00:36<00:26,  1.97batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 15:  52%|    | 56/107 [00:42<01:54,  2.25s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  53%|    | 57/107 [00:45<01:56,  2.32s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  54%|    | 58/107 [00:46<01:35,  1.95s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  55%|    | 59/107 [00:47<01:23,  1.74s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  56%|    | 60/107 [00:48<01:12,  1.54s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  57%|    | 61/107 [00:49<01:03,  1.37s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  58%|    | 62/107 [00:51<01:02,  1.40s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  59%|    | 63/107 [00:51<00:53,  1.21s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  60%|    | 64/107 [00:52<00:49,  1.14s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  61%|    | 65/107 [00:53<00:43,  1.04s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  62%|   | 66/107 [00:54<00:43,  1.07s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  63%|   | 67/107 [00:55<00:42,  1.07s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  64%|   | 68/107 [00:56<00:39,  1.01s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  64%|   | 69/107 [00:57<00:39,  1.03s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  65%|   | 70/107 [00:58<00:37,  1.01s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  66%|   | 71/107 [01:00<00:40,  1.14s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  67%|   | 72/107 [01:01<00:39,  1.13s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  68%|   | 73/107 [01:02<00:33,  1.01batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  69%|   | 74/107 [01:03<00:33,  1.01s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  70%|   | 75/107 [01:03<00:30,  1.06batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  71%|   | 76/107 [01:04<00:28,  1.09batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  72%|  | 77/107 [01:05<00:27,  1.08batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  73%|  | 78/107 [01:07<00:31,  1.09s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  74%|  | 79/107 [01:07<00:27,  1.02batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  75%|  | 80/107 [01:08<00:26,  1.01batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  76%|  | 81/107 [01:09<00:23,  1.12batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  77%|  | 82/107 [01:10<00:21,  1.14batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  78%|  | 83/107 [01:11<00:21,  1.11batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  79%|  | 84/107 [01:12<00:19,  1.16batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  79%|  | 85/107 [01:12<00:18,  1.21batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  80%|  | 86/107 [01:13<00:17,  1.20batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  81%| | 87/107 [01:14<00:16,  1.22batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  82%| | 88/107 [01:15<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  83%| | 89/107 [01:16<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  84%| | 90/107 [01:17<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  85%| | 91/107 [01:17<00:13,  1.17batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  86%| | 92/107 [01:19<00:15,  1.04s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  87%| | 93/107 [01:20<00:13,  1.04batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  88%| | 94/107 [01:21<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  89%| | 95/107 [01:24<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  90%| | 96/107 [01:25<00:16,  1.53s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  91%| | 97/107 [01:27<00:15,  1.60s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  92%|| 98/107 [01:28<00:12,  1.35s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  93%|| 99/107 [01:29<00:09,  1.19s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  93%|| 100/107 [01:29<00:07,  1.06s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  94%|| 101/107 [01:30<00:05,  1.03batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  95%|| 102/107 [01:31<00:05,  1.01s/batch, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  96%|| 103/107 [01:32<00:03,  1.07batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  97%|| 104/107 [01:33<00:02,  1.14batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  98%|| 105/107 [01:34<00:01,  1.17batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15:  99%|| 106/107 [01:35<00:00,  1.07batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 15: 100%|| 107/107 [01:39<00:00,  1.15batch/s, batch_idx=54, gpu=1, loss=0.226, v_num=d5ce3uok]\n",
      "Epoch 16:  51%|    | 55/107 [00:35<00:25,  2.00batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 16:  52%|    | 56/107 [00:42<02:00,  2.36s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  53%|    | 57/107 [00:44<01:57,  2.36s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  54%|    | 58/107 [00:45<01:36,  1.96s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  55%|    | 59/107 [00:46<01:24,  1.76s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  56%|    | 60/107 [00:47<01:12,  1.55s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  57%|    | 61/107 [00:48<01:03,  1.38s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  58%|    | 62/107 [00:50<01:03,  1.41s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  59%|    | 63/107 [00:51<00:53,  1.22s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  60%|    | 64/107 [00:52<00:49,  1.15s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  61%|    | 65/107 [00:52<00:44,  1.05s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  62%|   | 66/107 [00:53<00:43,  1.06s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  63%|   | 67/107 [00:55<00:42,  1.07s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  64%|   | 68/107 [00:55<00:40,  1.03s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  64%|   | 69/107 [00:56<00:39,  1.03s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  65%|   | 70/107 [00:57<00:37,  1.01s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  66%|   | 71/107 [00:59<00:39,  1.11s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  67%|   | 72/107 [01:00<00:38,  1.10s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  68%|   | 73/107 [01:01<00:33,  1.02batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  69%|   | 74/107 [01:02<00:33,  1.00s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  70%|   | 75/107 [01:02<00:29,  1.08batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  71%|   | 76/107 [01:03<00:27,  1.12batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  72%|  | 77/107 [01:04<00:27,  1.09batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  73%|  | 78/107 [01:06<00:31,  1.09s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  74%|  | 79/107 [01:06<00:27,  1.02batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  75%|  | 80/107 [01:07<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  76%|  | 81/107 [01:08<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  77%|  | 82/107 [01:09<00:21,  1.16batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  78%|  | 83/107 [01:10<00:21,  1.12batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  79%|  | 84/107 [01:10<00:19,  1.18batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  79%|  | 85/107 [01:11<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  80%|  | 86/107 [01:12<00:17,  1.19batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  81%| | 87/107 [01:13<00:16,  1.23batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  82%| | 88/107 [01:14<00:15,  1.26batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  83%| | 89/107 [01:15<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  84%| | 90/107 [01:16<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  85%| | 91/107 [01:16<00:13,  1.15batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  86%| | 92/107 [01:18<00:15,  1.04s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  87%| | 93/107 [01:19<00:13,  1.04batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  88%| | 94/107 [01:20<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  89%| | 95/107 [01:23<00:20,  1.73s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  90%| | 96/107 [01:24<00:16,  1.53s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  91%| | 97/107 [01:26<00:15,  1.60s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  92%|| 98/107 [01:27<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  93%|| 99/107 [01:28<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  93%|| 100/107 [01:28<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  94%|| 101/107 [01:29<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  95%|| 102/107 [01:30<00:04,  1.00batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  96%|| 103/107 [01:31<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  97%|| 104/107 [01:32<00:02,  1.15batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  98%|| 105/107 [01:32<00:01,  1.17batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16:  99%|| 106/107 [01:34<00:00,  1.08batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 16: 100%|| 107/107 [01:38<00:00,  1.16batch/s, batch_idx=54, gpu=1, loss=0.218, v_num=d5ce3uok]\n",
      "Epoch 17:  51%|    | 55/107 [00:35<00:24,  2.11batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 17:  52%|    | 56/107 [00:43<02:11,  2.57s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  53%|    | 57/107 [00:44<01:53,  2.26s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  54%|    | 58/107 [00:45<01:33,  1.90s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  55%|    | 59/107 [00:47<01:24,  1.76s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  56%|    | 60/107 [00:48<01:12,  1.54s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  57%|    | 61/107 [00:49<01:03,  1.39s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  58%|    | 62/107 [00:50<01:02,  1.40s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  59%|    | 63/107 [00:51<00:52,  1.20s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  60%|    | 64/107 [00:52<00:48,  1.13s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  61%|    | 65/107 [00:53<00:44,  1.05s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  62%|   | 66/107 [00:54<00:44,  1.07s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  63%|   | 67/107 [00:55<00:43,  1.08s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  64%|   | 68/107 [00:56<00:39,  1.02s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  64%|   | 69/107 [00:57<00:39,  1.03s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  65%|   | 70/107 [00:58<00:37,  1.00s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  66%|   | 71/107 [00:59<00:39,  1.11s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  67%|   | 72/107 [01:00<00:38,  1.09s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  68%|   | 73/107 [01:01<00:32,  1.03batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  69%|   | 74/107 [01:02<00:33,  1.00s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  70%|   | 75/107 [01:03<00:30,  1.06batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  71%|   | 76/107 [01:04<00:27,  1.11batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  72%|  | 77/107 [01:05<00:27,  1.10batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  73%|  | 78/107 [01:06<00:31,  1.09s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  74%|  | 79/107 [01:07<00:27,  1.02batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  75%|  | 80/107 [01:08<00:26,  1.01batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  76%|  | 81/107 [01:09<00:23,  1.13batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  77%|  | 82/107 [01:09<00:21,  1.14batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  78%|  | 83/107 [01:10<00:21,  1.11batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  79%|  | 84/107 [01:11<00:19,  1.18batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  79%|  | 85/107 [01:12<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  80%|  | 86/107 [01:13<00:17,  1.21batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  81%| | 87/107 [01:14<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  82%| | 88/107 [01:14<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  83%| | 89/107 [01:26<01:15,  4.20s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  84%| | 90/107 [01:28<00:55,  3.27s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  85%| | 91/107 [01:28<00:40,  2.54s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  86%| | 92/107 [01:30<00:33,  2.22s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  87%| | 93/107 [01:31<00:25,  1.79s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  88%| | 94/107 [01:32<00:21,  1.63s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  89%| | 95/107 [01:35<00:25,  2.15s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  90%| | 96/107 [01:36<00:19,  1.81s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  91%| | 97/107 [01:38<00:17,  1.79s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  92%|| 98/107 [01:39<00:13,  1.48s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  93%|| 99/107 [01:40<00:10,  1.28s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  93%|| 100/107 [01:40<00:07,  1.11s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  94%|| 101/107 [01:41<00:05,  1.01batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  95%|| 102/107 [01:42<00:05,  1.02s/batch, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  96%|| 103/107 [01:43<00:03,  1.06batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  97%|| 104/107 [01:44<00:02,  1.13batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  98%|| 105/107 [01:44<00:01,  1.15batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17:  99%|| 106/107 [01:45<00:00,  1.08batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 17: 100%|| 107/107 [01:50<00:00,  1.16batch/s, batch_idx=54, gpu=1, loss=0.203, v_num=d5ce3uok]\n",
      "Epoch 18:  51%|    | 55/107 [00:36<00:26,  1.98batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 18:  52%|    | 56/107 [00:43<02:04,  2.45s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  53%|    | 57/107 [00:46<02:01,  2.44s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  54%|    | 58/107 [00:47<01:38,  2.01s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  55%|    | 59/107 [00:48<01:25,  1.78s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  56%|    | 60/107 [00:49<01:12,  1.55s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  57%|    | 61/107 [00:50<01:01,  1.34s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  58%|    | 62/107 [00:51<01:03,  1.42s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  59%|    | 63/107 [00:52<00:53,  1.22s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  60%|    | 64/107 [00:53<00:49,  1.14s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  61%|    | 65/107 [00:54<00:43,  1.05s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  62%|   | 66/107 [00:55<00:43,  1.05s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  63%|   | 67/107 [00:56<00:41,  1.03s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  64%|   | 68/107 [00:57<00:39,  1.00s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  64%|   | 69/107 [00:58<00:38,  1.01s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  65%|   | 70/107 [00:59<00:36,  1.01batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  66%|   | 71/107 [01:00<00:39,  1.09s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  67%|   | 72/107 [01:01<00:37,  1.08s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  68%|   | 73/107 [01:02<00:32,  1.04batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  69%|   | 74/107 [01:03<00:32,  1.01batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  70%|   | 75/107 [01:04<00:30,  1.06batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  71%|   | 76/107 [01:05<00:28,  1.09batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  72%|  | 77/107 [01:06<00:28,  1.07batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  73%|  | 78/107 [01:07<00:32,  1.11s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  74%|  | 79/107 [01:08<00:28,  1.01s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  75%|  | 80/107 [01:09<00:27,  1.02s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  76%|  | 81/107 [01:10<00:23,  1.10batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  77%|  | 82/107 [01:10<00:22,  1.12batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  78%|  | 83/107 [01:11<00:22,  1.09batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  79%|  | 84/107 [01:12<00:20,  1.14batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  79%|  | 85/107 [01:13<00:18,  1.18batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  80%|  | 86/107 [01:14<00:18,  1.16batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  81%| | 87/107 [01:15<00:16,  1.20batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  82%| | 88/107 [01:15<00:15,  1.22batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  83%| | 89/107 [01:16<00:15,  1.19batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  84%| | 90/107 [01:17<00:15,  1.09batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  85%| | 91/107 [01:18<00:14,  1.11batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  86%| | 92/107 [01:20<00:16,  1.08s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  87%| | 93/107 [01:21<00:13,  1.00batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  88%| | 94/107 [01:22<00:14,  1.08s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  89%| | 95/107 [01:25<00:21,  1.78s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  90%| | 96/107 [01:26<00:17,  1.56s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  91%| | 97/107 [01:28<00:16,  1.63s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  92%|| 98/107 [01:29<00:12,  1.38s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  93%|| 99/107 [01:30<00:09,  1.21s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  93%|| 100/107 [01:30<00:07,  1.08s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  94%|| 101/107 [01:31<00:05,  1.02batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  95%|| 102/107 [01:32<00:05,  1.02s/batch, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  96%|| 103/107 [01:33<00:03,  1.06batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  97%|| 104/107 [01:34<00:02,  1.13batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  98%|| 105/107 [01:35<00:01,  1.15batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18:  99%|| 106/107 [01:36<00:00,  1.06batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 18: 100%|| 107/107 [01:40<00:00,  1.13batch/s, batch_idx=54, gpu=1, loss=0.181, v_num=d5ce3uok]\n",
      "Epoch 19:  51%|    | 55/107 [00:36<00:25,  2.06batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 19:  52%|    | 56/107 [00:43<02:10,  2.56s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  53%|    | 57/107 [00:46<02:13,  2.67s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  54%|    | 58/107 [00:47<01:46,  2.18s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  55%|    | 59/107 [00:48<01:30,  1.88s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  56%|    | 60/107 [00:49<01:16,  1.62s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  57%|    | 61/107 [00:50<01:06,  1.44s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  58%|    | 62/107 [00:52<01:04,  1.42s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  59%|    | 63/107 [00:52<00:53,  1.23s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  60%|    | 64/107 [00:53<00:49,  1.15s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  61%|    | 65/107 [00:54<00:44,  1.06s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  62%|   | 66/107 [00:55<00:43,  1.06s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  63%|   | 67/107 [00:56<00:42,  1.06s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  64%|   | 68/107 [00:57<00:39,  1.01s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  64%|   | 69/107 [00:58<00:39,  1.03s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  65%|   | 70/107 [00:59<00:36,  1.01batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  66%|   | 71/107 [01:01<00:39,  1.10s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  67%|   | 72/107 [01:02<00:38,  1.09s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  68%|   | 73/107 [01:02<00:32,  1.03batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  69%|   | 74/107 [01:03<00:32,  1.00batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  70%|   | 75/107 [01:04<00:30,  1.07batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  71%|   | 76/107 [01:05<00:28,  1.11batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  72%|  | 77/107 [01:06<00:27,  1.08batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  73%|  | 78/107 [01:07<00:31,  1.09s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  74%|  | 79/107 [01:08<00:27,  1.02batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  75%|  | 80/107 [01:09<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  76%|  | 81/107 [01:10<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  77%|  | 82/107 [01:11<00:21,  1.16batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  78%|  | 83/107 [01:12<00:21,  1.13batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  79%|  | 84/107 [01:12<00:19,  1.18batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  79%|  | 85/107 [01:13<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  80%|  | 86/107 [01:14<00:17,  1.20batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  81%| | 87/107 [01:15<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  82%| | 88/107 [01:15<00:14,  1.27batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  83%| | 89/107 [01:16<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  84%| | 90/107 [01:17<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  85%| | 91/107 [01:18<00:13,  1.16batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  86%| | 92/107 [01:20<00:15,  1.05s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  87%| | 93/107 [01:20<00:13,  1.04batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  88%| | 94/107 [01:22<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  89%| | 95/107 [01:25<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  90%| | 96/107 [01:26<00:16,  1.53s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  91%| | 97/107 [01:28<00:15,  1.59s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  92%|| 98/107 [01:29<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  93%|| 99/107 [01:29<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  93%|| 100/107 [01:30<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  94%|| 101/107 [01:31<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  95%|| 102/107 [01:32<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  96%|| 103/107 [01:33<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  97%|| 104/107 [01:33<00:02,  1.15batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  98%|| 105/107 [01:34<00:01,  1.17batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19:  99%|| 106/107 [01:35<00:00,  1.09batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 19: 100%|| 107/107 [01:40<00:00,  1.16batch/s, batch_idx=54, gpu=1, loss=0.163, v_num=d5ce3uok]\n",
      "Epoch 20:  51%|    | 55/107 [00:35<00:23,  2.20batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 20:  52%|    | 56/107 [00:43<02:06,  2.48s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  53%|    | 57/107 [00:45<02:03,  2.46s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  54%|    | 58/107 [00:46<01:38,  2.01s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  55%|    | 59/107 [00:47<01:25,  1.78s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  56%|    | 60/107 [00:48<01:12,  1.55s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  57%|    | 61/107 [00:49<01:01,  1.33s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  58%|    | 62/107 [00:51<01:02,  1.40s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  59%|    | 63/107 [00:51<00:53,  1.22s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  60%|    | 64/107 [00:52<00:49,  1.15s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  61%|    | 65/107 [00:53<00:44,  1.05s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  62%|   | 66/107 [00:54<00:42,  1.05s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  63%|   | 67/107 [00:55<00:41,  1.03s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  64%|   | 68/107 [00:56<00:39,  1.01s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  64%|   | 69/107 [00:57<00:39,  1.03s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  65%|   | 70/107 [00:58<00:36,  1.00batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  66%|   | 71/107 [01:00<00:39,  1.11s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  67%|   | 72/107 [01:01<00:38,  1.09s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  68%|   | 73/107 [01:01<00:32,  1.03batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  69%|   | 74/107 [01:02<00:32,  1.00batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  70%|   | 75/107 [01:03<00:30,  1.06batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  71%|   | 76/107 [01:04<00:27,  1.11batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  72%|  | 77/107 [01:05<00:27,  1.09batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  73%|  | 78/107 [01:06<00:31,  1.08s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  74%|  | 79/107 [01:07<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  75%|  | 80/107 [01:08<00:26,  1.01batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  76%|  | 81/107 [01:09<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  77%|  | 82/107 [01:10<00:21,  1.16batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  78%|  | 83/107 [01:11<00:21,  1.13batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  79%|  | 84/107 [01:11<00:19,  1.18batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  79%|  | 85/107 [01:12<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  80%|  | 86/107 [01:13<00:17,  1.20batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  81%| | 87/107 [01:14<00:16,  1.23batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  82%| | 88/107 [01:14<00:15,  1.26batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  83%| | 89/107 [01:15<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  84%| | 90/107 [01:16<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  85%| | 91/107 [01:17<00:13,  1.16batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  86%| | 92/107 [01:19<00:15,  1.04s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  87%| | 93/107 [01:19<00:13,  1.04batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  88%| | 94/107 [01:21<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  89%| | 95/107 [01:24<00:20,  1.75s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  90%| | 96/107 [01:25<00:16,  1.53s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  91%| | 97/107 [01:27<00:16,  1.60s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  92%|| 98/107 [01:28<00:12,  1.35s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  93%|| 99/107 [01:28<00:09,  1.19s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  93%|| 100/107 [01:29<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  94%|| 101/107 [01:30<00:05,  1.05batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  95%|| 102/107 [01:31<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  96%|| 103/107 [01:32<00:03,  1.08batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  97%|| 104/107 [01:32<00:02,  1.15batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  98%|| 105/107 [01:33<00:01,  1.18batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20:  99%|| 106/107 [01:34<00:00,  1.09batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 20: 100%|| 107/107 [01:38<00:00,  1.17batch/s, batch_idx=54, gpu=1, loss=0.147, v_num=d5ce3uok]\n",
      "Epoch 21:  51%|    | 55/107 [00:37<00:24,  2.09batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 21:  52%|    | 56/107 [00:45<02:08,  2.52s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  53%|    | 57/107 [00:47<02:07,  2.56s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  54%|    | 58/107 [00:48<01:41,  2.08s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  55%|    | 59/107 [00:49<01:26,  1.81s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  56%|    | 60/107 [00:50<01:13,  1.57s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  57%|    | 61/107 [00:51<01:02,  1.37s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  58%|    | 62/107 [00:53<01:01,  1.37s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  59%|    | 63/107 [00:53<00:52,  1.19s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  60%|    | 64/107 [00:54<00:48,  1.12s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  61%|    | 65/107 [00:55<00:43,  1.03s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  62%|   | 66/107 [00:56<00:43,  1.05s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  63%|   | 67/107 [00:57<00:41,  1.03s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  64%|   | 68/107 [00:58<00:38,  1.02batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  64%|   | 69/107 [00:59<00:37,  1.01batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  65%|   | 70/107 [01:00<00:36,  1.03batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  66%|   | 71/107 [01:01<00:38,  1.08s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  67%|   | 72/107 [01:02<00:37,  1.07s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  68%|   | 73/107 [01:03<00:31,  1.06batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  69%|   | 74/107 [01:04<00:31,  1.03batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  70%|   | 75/107 [01:05<00:28,  1.11batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  71%|   | 76/107 [01:06<00:26,  1.15batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  72%|  | 77/107 [01:07<00:26,  1.14batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  73%|  | 78/107 [01:08<00:30,  1.05s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  74%|  | 79/107 [01:09<00:26,  1.05batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  75%|  | 80/107 [01:10<00:26,  1.04batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  76%|  | 81/107 [01:10<00:22,  1.16batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  77%|  | 82/107 [01:11<00:21,  1.18batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  78%|  | 83/107 [01:12<00:20,  1.15batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  79%|  | 84/107 [01:13<00:18,  1.21batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  79%|  | 85/107 [01:14<00:17,  1.25batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  80%|  | 86/107 [01:14<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  81%| | 87/107 [01:15<00:15,  1.27batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  82%| | 88/107 [01:16<00:14,  1.29batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  83%| | 89/107 [01:17<00:14,  1.26batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  84%| | 90/107 [01:18<00:14,  1.15batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  85%| | 91/107 [01:19<00:13,  1.19batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  86%| | 92/107 [01:20<00:15,  1.02s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  87%| | 93/107 [01:35<01:12,  5.21s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  88%| | 94/107 [01:36<00:52,  4.01s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  89%| | 95/107 [01:39<00:45,  3.81s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  90%| | 96/107 [01:40<00:32,  2.97s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  91%| | 97/107 [01:42<00:25,  2.59s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  92%|| 98/107 [01:43<00:18,  2.04s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  93%|| 99/107 [01:44<00:13,  1.66s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  93%|| 100/107 [01:44<00:09,  1.38s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  94%|| 101/107 [01:45<00:07,  1.18s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  95%|| 102/107 [01:46<00:05,  1.15s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  96%|| 103/107 [01:47<00:04,  1.03s/batch, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  97%|| 104/107 [01:48<00:02,  1.07batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  98%|| 105/107 [01:49<00:01,  1.11batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21:  99%|| 106/107 [01:50<00:00,  1.06batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 21: 100%|| 107/107 [01:54<00:00,  1.14batch/s, batch_idx=54, gpu=1, loss=0.136, v_num=d5ce3uok]\n",
      "Epoch 22:  51%|    | 55/107 [00:37<00:25,  2.08batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 22:  52%|    | 56/107 [00:45<02:27,  2.89s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  53%|    | 57/107 [00:47<02:09,  2.60s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  54%|    | 58/107 [00:48<01:45,  2.15s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  55%|    | 59/107 [00:50<01:31,  1.91s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  56%|    | 60/107 [00:51<01:17,  1.66s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  57%|    | 61/107 [00:52<01:06,  1.44s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  58%|    | 62/107 [00:53<01:05,  1.45s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  59%|    | 63/107 [00:54<00:54,  1.24s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  60%|    | 64/107 [00:55<00:50,  1.16s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  61%|    | 65/107 [00:56<00:44,  1.06s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  62%|   | 66/107 [00:57<00:44,  1.08s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  63%|   | 67/107 [00:58<00:43,  1.08s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  64%|   | 68/107 [00:59<00:40,  1.05s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  64%|   | 69/107 [01:00<00:40,  1.06s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  65%|   | 70/107 [01:01<00:38,  1.04s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  66%|   | 71/107 [01:02<00:41,  1.16s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  67%|   | 72/107 [01:04<00:39,  1.14s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  68%|   | 73/107 [01:04<00:33,  1.00batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  69%|   | 74/107 [01:05<00:33,  1.02s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  70%|   | 75/107 [01:06<00:30,  1.05batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  71%|   | 76/107 [01:07<00:28,  1.09batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  72%|  | 77/107 [01:08<00:27,  1.07batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  73%|  | 78/107 [01:09<00:32,  1.12s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  74%|  | 79/107 [01:10<00:28,  1.01s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  75%|  | 80/107 [01:11<00:27,  1.01s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  76%|  | 81/107 [01:12<00:23,  1.09batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  77%|  | 82/107 [01:13<00:22,  1.10batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  78%|  | 83/107 [01:14<00:22,  1.07batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  79%|  | 84/107 [01:15<00:20,  1.13batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  79%|  | 85/107 [01:15<00:18,  1.17batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  80%|  | 86/107 [01:16<00:18,  1.16batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  81%| | 87/107 [01:17<00:16,  1.19batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  82%| | 88/107 [01:18<00:15,  1.22batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  83%| | 89/107 [01:19<00:15,  1.19batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  84%| | 90/107 [01:20<00:15,  1.09batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  85%| | 91/107 [01:21<00:14,  1.12batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  86%| | 92/107 [01:22<00:16,  1.08s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  87%| | 93/107 [01:23<00:13,  1.00batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  88%| | 94/107 [01:24<00:14,  1.08s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  89%| | 95/107 [01:28<00:21,  1.77s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  90%| | 96/107 [01:29<00:17,  1.56s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  91%| | 97/107 [01:30<00:16,  1.64s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  92%|| 98/107 [01:31<00:12,  1.37s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  93%|| 99/107 [01:32<00:09,  1.20s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  93%|| 100/107 [01:33<00:07,  1.06s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  94%|| 101/107 [01:34<00:05,  1.04batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  95%|| 102/107 [01:35<00:05,  1.01s/batch, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  96%|| 103/107 [01:35<00:03,  1.06batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  97%|| 104/107 [01:36<00:02,  1.14batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  98%|| 105/107 [01:37<00:01,  1.16batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22:  99%|| 106/107 [01:38<00:00,  1.09batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 22: 100%|| 107/107 [01:42<00:00,  1.16batch/s, batch_idx=54, gpu=1, loss=0.124, v_num=d5ce3uok]\n",
      "Epoch 23:  51%|    | 55/107 [00:38<00:23,  2.25batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 23:  52%|    | 56/107 [00:45<02:17,  2.69s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  53%|    | 57/107 [00:48<02:16,  2.74s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  54%|    | 58/107 [00:49<01:47,  2.20s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  55%|    | 59/107 [00:50<01:32,  1.92s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  56%|    | 60/107 [00:52<01:17,  1.66s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  57%|    | 61/107 [00:52<01:05,  1.42s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  58%|    | 62/107 [00:54<01:04,  1.43s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  59%|    | 63/107 [00:55<00:54,  1.23s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  60%|    | 64/107 [00:56<00:49,  1.16s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  61%|    | 65/107 [00:56<00:44,  1.06s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  62%|   | 66/107 [00:58<00:44,  1.09s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  63%|   | 67/107 [00:59<00:43,  1.08s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  64%|   | 68/107 [01:00<00:40,  1.03s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  64%|   | 69/107 [01:01<00:39,  1.04s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  65%|   | 70/107 [01:02<00:37,  1.00s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  66%|   | 71/107 [01:03<00:39,  1.11s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  67%|   | 72/107 [01:04<00:38,  1.09s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  68%|   | 73/107 [01:05<00:32,  1.04batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  69%|   | 74/107 [01:06<00:32,  1.02batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  70%|   | 75/107 [01:06<00:29,  1.08batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  71%|   | 76/107 [01:07<00:27,  1.13batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  72%|  | 77/107 [01:08<00:27,  1.11batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  73%|  | 78/107 [01:10<00:31,  1.07s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  74%|  | 79/107 [01:10<00:26,  1.04batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  75%|  | 80/107 [01:11<00:26,  1.03batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  76%|  | 81/107 [01:12<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  77%|  | 82/107 [01:13<00:21,  1.15batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  78%|  | 83/107 [01:14<00:21,  1.13batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  79%|  | 84/107 [01:15<00:19,  1.19batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  79%|  | 85/107 [01:15<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  80%|  | 86/107 [01:16<00:17,  1.21batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  81%| | 87/107 [01:17<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  82%| | 88/107 [01:18<00:14,  1.27batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  83%| | 89/107 [01:18<00:14,  1.24batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  84%| | 90/107 [01:20<00:15,  1.13batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  85%| | 91/107 [01:20<00:13,  1.15batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  86%| | 92/107 [01:22<00:15,  1.05s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  87%| | 93/107 [01:23<00:13,  1.04batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  88%| | 94/107 [01:24<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  89%| | 95/107 [01:27<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  90%| | 96/107 [01:28<00:16,  1.54s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  91%| | 97/107 [01:30<00:15,  1.60s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  92%|| 98/107 [01:31<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  93%|| 99/107 [01:32<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  93%|| 100/107 [01:32<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  94%|| 101/107 [01:33<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  95%|| 102/107 [01:34<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  96%|| 103/107 [01:35<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  97%|| 104/107 [01:36<00:02,  1.16batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  98%|| 105/107 [01:36<00:01,  1.18batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23:  99%|| 106/107 [01:38<00:00,  1.08batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 23: 100%|| 107/107 [01:42<00:00,  1.15batch/s, batch_idx=54, gpu=1, loss=0.115, v_num=d5ce3uok]\n",
      "Epoch 24:  51%|    | 55/107 [00:38<00:22,  2.32batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 24:  52%|    | 56/107 [00:46<02:19,  2.74s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  53%|    | 57/107 [00:48<02:09,  2.59s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  54%|    | 58/107 [00:49<01:44,  2.13s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  55%|    | 59/107 [00:50<01:28,  1.85s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  56%|    | 60/107 [00:51<01:15,  1.61s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  57%|    | 61/107 [00:52<01:02,  1.36s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  58%|    | 62/107 [00:54<01:03,  1.40s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  59%|    | 63/107 [00:54<00:55,  1.25s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  60%|    | 64/107 [00:55<00:50,  1.18s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  61%|    | 65/107 [00:56<00:45,  1.08s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  62%|   | 66/107 [00:57<00:44,  1.10s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  63%|   | 67/107 [00:59<00:44,  1.10s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  64%|   | 68/107 [00:59<00:40,  1.05s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  64%|   | 69/107 [01:01<00:40,  1.06s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  65%|   | 70/107 [01:02<00:38,  1.04s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  66%|   | 71/107 [01:03<00:41,  1.16s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  67%|   | 72/107 [01:04<00:39,  1.13s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  68%|   | 73/107 [01:05<00:33,  1.00batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  69%|   | 74/107 [01:06<00:33,  1.02s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  70%|   | 75/107 [01:07<00:30,  1.05batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  71%|   | 76/107 [01:07<00:28,  1.10batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  72%|  | 77/107 [01:08<00:27,  1.08batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  73%|  | 78/107 [01:10<00:31,  1.09s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  74%|  | 79/107 [01:11<00:27,  1.02batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  75%|  | 80/107 [01:12<00:26,  1.01batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  76%|  | 81/107 [01:12<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  77%|  | 82/107 [01:13<00:21,  1.16batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  78%|  | 83/107 [01:14<00:21,  1.12batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  79%|  | 84/107 [01:15<00:19,  1.18batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  79%|  | 85/107 [01:15<00:18,  1.20batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  80%|  | 86/107 [01:16<00:17,  1.18batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  81%| | 87/107 [01:17<00:16,  1.21batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  82%| | 88/107 [01:18<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  83%| | 89/107 [01:19<00:14,  1.21batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  84%| | 90/107 [01:20<00:15,  1.11batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  85%| | 91/107 [01:21<00:14,  1.14batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  86%| | 92/107 [01:22<00:15,  1.06s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  87%| | 93/107 [01:23<00:13,  1.03batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  88%| | 94/107 [01:24<00:13,  1.06s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  89%| | 95/107 [01:28<00:21,  1.75s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  90%| | 96/107 [01:29<00:16,  1.54s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  91%| | 97/107 [01:30<00:16,  1.61s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  92%|| 98/107 [01:31<00:12,  1.35s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  93%|| 99/107 [01:32<00:09,  1.19s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  93%|| 100/107 [01:33<00:07,  1.06s/batch, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  94%|| 101/107 [01:33<00:05,  1.05batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  95%|| 102/107 [01:35<00:04,  1.00batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  96%|| 103/107 [01:35<00:03,  1.08batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  97%|| 104/107 [01:36<00:02,  1.14batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  98%|| 105/107 [01:37<00:01,  1.15batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24:  99%|| 106/107 [01:38<00:00,  1.07batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 24: 100%|| 107/107 [01:42<00:00,  1.14batch/s, batch_idx=54, gpu=1, loss=0.108, v_num=d5ce3uok]\n",
      "Epoch 25:  51%|    | 55/107 [00:38<00:25,  2.02batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 25:  52%|    | 56/107 [00:46<02:19,  2.74s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  53%|    | 57/107 [00:49<02:12,  2.65s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  54%|    | 58/107 [00:50<01:45,  2.15s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  55%|    | 59/107 [00:51<01:28,  1.85s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  56%|    | 60/107 [00:52<01:15,  1.60s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  57%|    | 61/107 [00:53<01:02,  1.37s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  58%|    | 62/107 [00:54<01:04,  1.44s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  59%|    | 63/107 [00:55<00:55,  1.26s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  60%|    | 64/107 [00:56<00:49,  1.16s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  61%|    | 65/107 [00:57<00:43,  1.04s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  62%|   | 66/107 [00:58<00:42,  1.05s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  63%|   | 67/107 [00:59<00:41,  1.03s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  64%|   | 68/107 [01:00<00:38,  1.01batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  64%|   | 69/107 [01:01<00:37,  1.00batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  65%|   | 70/107 [01:02<00:35,  1.03batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  66%|   | 71/107 [01:03<00:38,  1.08s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  67%|   | 72/107 [01:04<00:37,  1.07s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  68%|   | 73/107 [01:05<00:32,  1.06batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  69%|   | 74/107 [01:06<00:31,  1.03batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  70%|   | 75/107 [01:07<00:28,  1.11batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  71%|   | 76/107 [01:07<00:26,  1.16batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  72%|  | 77/107 [01:08<00:26,  1.15batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  73%|  | 78/107 [01:10<00:30,  1.05s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  74%|  | 79/107 [01:10<00:26,  1.06batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  75%|  | 80/107 [01:11<00:25,  1.05batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  76%|  | 81/107 [01:12<00:22,  1.17batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  77%|  | 82/107 [01:13<00:20,  1.20batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  78%|  | 83/107 [01:14<00:20,  1.16batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  79%|  | 84/107 [01:14<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  79%|  | 85/107 [01:15<00:17,  1.26batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  80%|  | 86/107 [01:16<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  81%| | 87/107 [01:17<00:15,  1.26batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  82%| | 88/107 [01:17<00:14,  1.30batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  83%| | 89/107 [01:18<00:14,  1.26batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  84%| | 90/107 [01:19<00:14,  1.14batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  85%| | 91/107 [01:20<00:13,  1.18batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  86%| | 92/107 [01:22<00:15,  1.03s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  87%| | 93/107 [01:22<00:13,  1.07batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  88%| | 94/107 [01:24<00:13,  1.03s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  89%| | 95/107 [01:27<00:20,  1.71s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  90%| | 96/107 [01:28<00:16,  1.49s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  91%| | 97/107 [01:30<00:15,  1.56s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  92%|| 98/107 [01:30<00:11,  1.32s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  93%|| 99/107 [01:31<00:09,  1.16s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  93%|| 100/107 [01:32<00:07,  1.03s/batch, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  94%|| 101/107 [01:33<00:05,  1.08batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  95%|| 102/107 [01:34<00:04,  1.03batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  96%|| 103/107 [01:34<00:03,  1.11batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  97%|| 104/107 [01:35<00:02,  1.18batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  98%|| 105/107 [01:36<00:01,  1.21batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25:  99%|| 106/107 [01:37<00:00,  1.13batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 25: 100%|| 107/107 [01:41<00:00,  1.21batch/s, batch_idx=54, gpu=1, loss=0.101, v_num=d5ce3uok]\n",
      "Epoch 26:  51%|    | 55/107 [00:37<00:24,  2.10batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 26:  52%|    | 56/107 [00:46<02:22,  2.79s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  53%|    | 57/107 [00:48<02:12,  2.65s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  54%|    | 58/107 [00:49<01:45,  2.16s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  55%|    | 59/107 [00:50<01:29,  1.85s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  56%|    | 60/107 [00:51<01:14,  1.60s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  57%|    | 61/107 [00:52<01:02,  1.35s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  58%|    | 62/107 [00:54<01:05,  1.45s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  59%|    | 63/107 [00:54<00:54,  1.25s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  60%|    | 64/107 [00:55<00:49,  1.15s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  61%|    | 65/107 [00:56<00:43,  1.04s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  62%|   | 66/107 [00:57<00:42,  1.03s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  63%|   | 67/107 [00:58<00:40,  1.01s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  64%|   | 68/107 [00:59<00:38,  1.02batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  64%|   | 69/107 [01:00<00:37,  1.01batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  65%|   | 70/107 [01:01<00:35,  1.04batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  66%|   | 71/107 [01:02<00:38,  1.07s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  67%|   | 72/107 [01:03<00:36,  1.06s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  68%|   | 73/107 [01:04<00:31,  1.07batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  69%|   | 74/107 [01:05<00:31,  1.04batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  70%|   | 75/107 [01:06<00:28,  1.11batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  71%|   | 76/107 [01:06<00:26,  1.16batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  72%|  | 77/107 [01:07<00:26,  1.15batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  73%|  | 78/107 [01:09<00:30,  1.04s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  74%|  | 79/107 [01:09<00:26,  1.06batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  75%|  | 80/107 [01:10<00:25,  1.05batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  76%|  | 81/107 [01:11<00:22,  1.18batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  77%|  | 82/107 [01:12<00:20,  1.21batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  78%|  | 83/107 [01:13<00:20,  1.16batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  79%|  | 84/107 [01:13<00:18,  1.21batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  79%|  | 85/107 [01:14<00:17,  1.25batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  80%|  | 86/107 [01:15<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  81%| | 87/107 [01:16<00:16,  1.25batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  82%| | 88/107 [01:17<00:15,  1.27batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  83%| | 89/107 [01:17<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  84%| | 90/107 [01:19<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  85%| | 91/107 [01:19<00:13,  1.16batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  86%| | 92/107 [01:21<00:15,  1.03s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  87%| | 93/107 [01:21<00:13,  1.06batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  88%| | 94/107 [01:23<00:13,  1.04s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  89%| | 95/107 [01:26<00:20,  1.72s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  90%| | 96/107 [01:44<01:13,  6.69s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  91%| | 97/107 [01:46<00:52,  5.20s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  92%|| 98/107 [01:47<00:34,  3.86s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  93%|| 99/107 [01:48<00:23,  2.94s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  93%|| 100/107 [01:48<00:15,  2.27s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  94%|| 101/107 [01:49<00:10,  1.81s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  95%|| 102/107 [01:50<00:07,  1.58s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  96%|| 103/107 [01:51<00:05,  1.33s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  97%|| 104/107 [01:52<00:03,  1.15s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  98%|| 105/107 [01:52<00:02,  1.05s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26:  99%|| 106/107 [01:53<00:01,  1.05s/batch, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 26: 100%|| 107/107 [01:57<00:00,  1.05batch/s, batch_idx=54, gpu=1, loss=0.094, v_num=d5ce3uok]\n",
      "Epoch 27:  51%|    | 55/107 [00:39<00:24,  2.10batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 27:  52%|    | 56/107 [00:48<02:31,  2.97s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  53%|    | 57/107 [00:50<02:18,  2.77s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  54%|    | 58/107 [00:51<01:50,  2.25s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  55%|    | 59/107 [00:53<01:39,  2.07s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  56%|    | 60/107 [00:54<01:23,  1.78s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  57%|    | 61/107 [00:55<01:11,  1.55s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  58%|    | 62/107 [00:56<01:06,  1.48s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  59%|    | 63/107 [00:57<00:55,  1.26s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  60%|    | 64/107 [00:58<00:51,  1.20s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  61%|    | 65/107 [00:59<00:45,  1.09s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  62%|   | 66/107 [01:00<00:44,  1.08s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  63%|   | 67/107 [01:01<00:42,  1.07s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  64%|   | 68/107 [01:02<00:40,  1.03s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  64%|   | 69/107 [01:03<00:39,  1.03s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  65%|   | 70/107 [01:04<00:37,  1.00s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  66%|   | 71/107 [01:05<00:39,  1.11s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  67%|   | 72/107 [01:06<00:38,  1.10s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  68%|   | 73/107 [01:07<00:33,  1.03batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  69%|   | 74/107 [01:08<00:32,  1.00batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  70%|   | 75/107 [01:09<00:29,  1.08batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  71%|   | 76/107 [01:10<00:27,  1.12batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  72%|  | 77/107 [01:11<00:27,  1.10batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  73%|  | 78/107 [01:12<00:31,  1.08s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  74%|  | 79/107 [01:13<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  75%|  | 80/107 [01:14<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  76%|  | 81/107 [01:14<00:22,  1.15batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  77%|  | 82/107 [01:15<00:21,  1.17batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  78%|  | 83/107 [01:16<00:21,  1.13batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  79%|  | 84/107 [01:17<00:19,  1.19batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  79%|  | 85/107 [01:18<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  80%|  | 86/107 [01:19<00:17,  1.20batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  81%| | 87/107 [01:19<00:16,  1.23batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  82%| | 88/107 [01:20<00:15,  1.26batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  83%| | 89/107 [01:21<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  84%| | 90/107 [01:22<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  85%| | 91/107 [01:23<00:13,  1.15batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  86%| | 92/107 [01:24<00:15,  1.05s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  87%| | 93/107 [01:25<00:13,  1.03batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  88%| | 94/107 [01:26<00:13,  1.06s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  89%| | 95/107 [01:30<00:21,  1.75s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  90%| | 96/107 [01:31<00:16,  1.53s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  91%| | 97/107 [01:32<00:15,  1.60s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  92%|| 98/107 [01:33<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  93%|| 99/107 [01:34<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  93%|| 100/107 [01:35<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  94%|| 101/107 [01:36<00:05,  1.05batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  95%|| 102/107 [01:37<00:04,  1.00batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  96%|| 103/107 [01:37<00:03,  1.08batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  97%|| 104/107 [01:38<00:02,  1.15batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  98%|| 105/107 [01:39<00:01,  1.16batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27:  99%|| 106/107 [01:40<00:00,  1.08batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 27: 100%|| 107/107 [01:45<00:00,  1.15batch/s, batch_idx=54, gpu=1, loss=0.089, v_num=d5ce3uok]\n",
      "Epoch 28:  51%|    | 55/107 [00:39<00:25,  2.07batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 28:  52%|    | 56/107 [00:48<02:32,  2.99s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  53%|    | 57/107 [00:51<02:32,  3.04s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  54%|    | 58/107 [00:52<02:00,  2.46s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  55%|    | 59/107 [00:53<01:40,  2.10s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  56%|    | 60/107 [00:54<01:26,  1.84s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  57%|    | 61/107 [00:55<01:10,  1.52s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  58%|    | 62/107 [00:56<01:05,  1.45s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  59%|    | 63/107 [00:57<00:55,  1.26s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  60%|    | 64/107 [00:58<00:51,  1.21s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  61%|    | 65/107 [00:59<00:46,  1.10s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  62%|   | 66/107 [01:00<00:45,  1.11s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  63%|   | 67/107 [01:01<00:44,  1.11s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  64%|   | 68/107 [01:02<00:40,  1.04s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  64%|   | 69/107 [01:03<00:39,  1.05s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  65%|   | 70/107 [01:04<00:37,  1.02s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  66%|   | 71/107 [01:06<00:41,  1.15s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  67%|   | 72/107 [01:07<00:39,  1.13s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  68%|   | 73/107 [01:07<00:34,  1.00s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  69%|   | 74/107 [01:09<00:33,  1.02s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  70%|   | 75/107 [01:09<00:30,  1.04batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  71%|   | 76/107 [01:10<00:29,  1.06batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  72%|  | 77/107 [01:11<00:28,  1.05batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  73%|  | 78/107 [01:13<00:32,  1.12s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  74%|  | 79/107 [01:14<00:28,  1.01s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  75%|  | 80/107 [01:15<00:27,  1.02s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  76%|  | 81/107 [01:15<00:23,  1.09batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  77%|  | 82/107 [01:16<00:22,  1.10batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  78%|  | 83/107 [01:17<00:22,  1.07batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  79%|  | 84/107 [01:18<00:20,  1.13batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  79%|  | 85/107 [01:19<00:18,  1.17batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  80%|  | 86/107 [01:20<00:18,  1.16batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  81%| | 87/107 [01:20<00:16,  1.19batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  82%| | 88/107 [01:21<00:15,  1.21batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  83%| | 89/107 [01:22<00:15,  1.19batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  84%| | 90/107 [01:23<00:15,  1.08batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  85%| | 91/107 [01:24<00:14,  1.13batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  86%| | 92/107 [01:25<00:15,  1.06s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  87%| | 93/107 [01:26<00:13,  1.03batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  88%| | 94/107 [01:27<00:13,  1.06s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  89%| | 95/107 [01:31<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  90%| | 96/107 [01:32<00:16,  1.53s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  91%| | 97/107 [01:34<00:16,  1.61s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  92%|| 98/107 [01:34<00:12,  1.36s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  93%|| 99/107 [01:35<00:09,  1.20s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  93%|| 100/107 [01:36<00:07,  1.07s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  94%|| 101/107 [01:37<00:05,  1.02batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  95%|| 102/107 [01:38<00:05,  1.02s/batch, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  96%|| 103/107 [01:39<00:03,  1.05batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  97%|| 104/107 [01:39<00:02,  1.11batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  98%|| 105/107 [01:40<00:01,  1.14batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28:  99%|| 106/107 [01:41<00:00,  1.07batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 28: 100%|| 107/107 [01:46<00:00,  1.14batch/s, batch_idx=54, gpu=1, loss=0.083, v_num=d5ce3uok]\n",
      "Epoch 29:  51%|    | 55/107 [00:40<00:24,  2.11batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 29:  52%|    | 56/107 [00:49<02:33,  3.02s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  53%|    | 57/107 [00:51<02:20,  2.81s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  54%|    | 58/107 [00:53<01:53,  2.31s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  55%|    | 59/107 [00:54<01:35,  1.99s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  56%|    | 60/107 [00:55<01:20,  1.70s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  57%|    | 61/107 [00:56<01:07,  1.47s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  58%|    | 62/107 [00:57<01:05,  1.45s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  59%|    | 63/107 [00:58<00:54,  1.24s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  60%|    | 64/107 [00:59<00:50,  1.17s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  61%|    | 65/107 [01:00<00:44,  1.06s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  62%|   | 66/107 [01:01<00:43,  1.07s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  63%|   | 67/107 [01:02<00:43,  1.08s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  64%|   | 68/107 [01:03<00:39,  1.02s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  64%|   | 69/107 [01:04<00:38,  1.02s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  65%|   | 70/107 [01:05<00:36,  1.00batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  66%|   | 71/107 [01:06<00:39,  1.11s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  67%|   | 72/107 [01:07<00:39,  1.12s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  68%|   | 73/107 [01:08<00:33,  1.01batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  69%|   | 74/107 [01:09<00:33,  1.00s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  70%|   | 75/107 [01:10<00:29,  1.07batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  71%|   | 76/107 [01:11<00:27,  1.12batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  72%|  | 77/107 [01:12<00:27,  1.11batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  73%|  | 78/107 [01:13<00:31,  1.07s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  74%|  | 79/107 [01:14<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  75%|  | 80/107 [01:15<00:26,  1.00batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  76%|  | 81/107 [01:15<00:23,  1.12batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  77%|  | 82/107 [01:16<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  78%|  | 83/107 [01:17<00:21,  1.12batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  79%|  | 84/107 [01:18<00:19,  1.18batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  79%|  | 85/107 [01:19<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  80%|  | 86/107 [01:20<00:17,  1.22batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  81%| | 87/107 [01:20<00:16,  1.23batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  82%| | 88/107 [01:21<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  83%| | 89/107 [01:22<00:14,  1.22batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  84%| | 90/107 [01:23<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  85%| | 91/107 [01:24<00:13,  1.17batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  86%| | 92/107 [01:25<00:15,  1.04s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  87%| | 93/107 [01:26<00:13,  1.05batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  88%| | 94/107 [01:27<00:13,  1.04s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  89%| | 95/107 [01:31<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  90%| | 96/107 [01:32<00:16,  1.53s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  91%| | 97/107 [01:33<00:15,  1.59s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  92%|| 98/107 [01:34<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  93%|| 99/107 [01:35<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  93%|| 100/107 [01:36<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  94%|| 101/107 [01:36<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  95%|| 102/107 [01:37<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  96%|| 103/107 [01:38<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  97%|| 104/107 [01:39<00:02,  1.14batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  98%|| 105/107 [01:40<00:01,  1.16batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29:  99%|| 106/107 [01:41<00:00,  1.08batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 29: 100%|| 107/107 [01:45<00:00,  1.15batch/s, batch_idx=54, gpu=1, loss=0.080, v_num=d5ce3uok]\n",
      "Epoch 30:  51%|    | 55/107 [00:40<00:24,  2.10batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 30:  52%|    | 56/107 [00:49<02:37,  3.09s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  53%|    | 57/107 [00:51<02:22,  2.85s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  54%|    | 58/107 [00:52<01:54,  2.33s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  55%|    | 59/107 [00:54<01:44,  2.17s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  56%|    | 60/107 [00:55<01:28,  1.87s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  57%|    | 61/107 [00:56<01:14,  1.61s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  58%|    | 62/107 [00:58<01:07,  1.50s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  59%|    | 63/107 [00:58<00:56,  1.28s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  60%|    | 64/107 [00:59<00:50,  1.17s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  61%|    | 65/107 [01:00<00:45,  1.08s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  62%|   | 66/107 [01:01<00:44,  1.10s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  63%|   | 67/107 [01:02<00:43,  1.09s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  64%|   | 68/107 [01:03<00:40,  1.03s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  64%|   | 69/107 [01:04<00:40,  1.05s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  65%|   | 70/107 [01:05<00:37,  1.02s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  66%|   | 71/107 [01:07<00:40,  1.11s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  67%|   | 72/107 [01:08<00:38,  1.11s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  68%|   | 73/107 [01:08<00:33,  1.02batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  69%|   | 74/107 [01:09<00:33,  1.00s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  70%|   | 75/107 [01:10<00:29,  1.08batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  71%|   | 76/107 [01:11<00:27,  1.13batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  72%|  | 77/107 [01:12<00:26,  1.12batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  73%|  | 78/107 [01:13<00:30,  1.06s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  74%|  | 79/107 [01:14<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  75%|  | 80/107 [01:15<00:26,  1.03batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  76%|  | 81/107 [01:16<00:22,  1.15batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  77%|  | 82/107 [01:17<00:21,  1.18batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  78%|  | 83/107 [01:17<00:21,  1.14batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  79%|  | 84/107 [01:18<00:19,  1.20batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  79%|  | 85/107 [01:19<00:17,  1.24batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  80%|  | 86/107 [01:20<00:17,  1.22batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  81%| | 87/107 [01:21<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  82%| | 88/107 [01:21<00:14,  1.28batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  83%| | 89/107 [01:22<00:14,  1.24batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  84%| | 90/107 [01:23<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  85%| | 91/107 [01:24<00:13,  1.17batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  86%| | 92/107 [01:25<00:15,  1.03s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  87%| | 93/107 [01:26<00:13,  1.05batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  88%| | 94/107 [01:27<00:13,  1.04s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  89%| | 95/107 [01:31<00:20,  1.73s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  90%| | 96/107 [01:32<00:16,  1.51s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  91%| | 97/107 [01:34<00:15,  1.58s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  92%|| 98/107 [01:34<00:11,  1.33s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  93%|| 99/107 [01:35<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  93%|| 100/107 [01:36<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  94%|| 101/107 [01:37<00:05,  1.04batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  95%|| 102/107 [01:38<00:04,  1.00batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  96%|| 103/107 [01:38<00:03,  1.08batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  97%|| 104/107 [01:39<00:02,  1.16batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  98%|| 105/107 [01:40<00:01,  1.18batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30:  99%|| 106/107 [01:41<00:00,  1.10batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 30: 100%|| 107/107 [01:45<00:00,  1.17batch/s, batch_idx=54, gpu=1, loss=0.076, v_num=d5ce3uok]\n",
      "Epoch 31:  51%|    | 55/107 [00:40<00:23,  2.18batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 31:  52%|    | 56/107 [00:49<02:37,  3.08s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  53%|    | 57/107 [00:51<02:15,  2.71s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  54%|    | 58/107 [00:52<01:48,  2.20s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  55%|    | 59/107 [00:53<01:31,  1.92s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  56%|    | 60/107 [00:54<01:17,  1.64s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  57%|    | 61/107 [00:55<01:04,  1.41s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  58%|    | 62/107 [00:57<01:09,  1.54s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  59%|    | 63/107 [00:58<00:59,  1.35s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  60%|    | 64/107 [00:59<00:53,  1.25s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  61%|    | 65/107 [01:00<00:47,  1.12s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  62%|   | 66/107 [01:01<00:45,  1.11s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  63%|   | 67/107 [01:02<00:43,  1.08s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  64%|   | 68/107 [01:03<00:39,  1.02s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  64%|   | 69/107 [01:04<00:38,  1.02s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  65%|   | 70/107 [01:05<00:36,  1.01batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  66%|   | 71/107 [01:06<00:39,  1.10s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  67%|   | 72/107 [01:07<00:37,  1.08s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  68%|   | 73/107 [01:08<00:32,  1.05batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  69%|   | 74/107 [01:09<00:32,  1.02batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  70%|   | 75/107 [01:10<00:29,  1.09batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  71%|   | 76/107 [01:10<00:27,  1.14batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  72%|  | 77/107 [01:11<00:26,  1.13batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  73%|  | 78/107 [01:13<00:30,  1.06s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  74%|  | 79/107 [01:13<00:26,  1.05batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  75%|  | 80/107 [01:14<00:25,  1.05batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  76%|  | 81/107 [01:15<00:22,  1.16batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  77%|  | 82/107 [01:16<00:21,  1.17batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  78%|  | 83/107 [01:17<00:20,  1.14batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  79%|  | 84/107 [01:18<00:19,  1.21batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  79%|  | 85/107 [01:18<00:17,  1.24batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  80%|  | 86/107 [01:19<00:17,  1.22batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  81%| | 87/107 [01:20<00:16,  1.23batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  82%| | 88/107 [01:21<00:14,  1.27batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  83%| | 89/107 [01:22<00:14,  1.24batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  84%| | 90/107 [01:23<00:15,  1.13batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  85%| | 91/107 [01:23<00:13,  1.17batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  86%| | 92/107 [01:25<00:15,  1.03s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  87%| | 93/107 [01:26<00:13,  1.05batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  88%| | 94/107 [01:27<00:13,  1.04s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  89%| | 95/107 [01:30<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  90%| | 96/107 [01:31<00:16,  1.52s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  91%| | 97/107 [01:33<00:15,  1.58s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  92%|| 98/107 [01:34<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  93%|| 99/107 [01:35<00:09,  1.19s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  93%|| 100/107 [01:35<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  94%|| 101/107 [01:36<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  95%|| 102/107 [01:37<00:04,  1.02batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  96%|| 103/107 [01:38<00:03,  1.10batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  97%|| 104/107 [01:39<00:02,  1.17batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  98%|| 105/107 [01:39<00:01,  1.19batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31:  99%|| 106/107 [01:40<00:00,  1.12batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 31: 100%|| 107/107 [01:45<00:00,  1.19batch/s, batch_idx=54, gpu=1, loss=0.073, v_num=d5ce3uok]\n",
      "Epoch 32:  51%|    | 55/107 [00:39<00:23,  2.21batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 32:  52%|    | 56/107 [00:50<02:52,  3.39s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  53%|    | 57/107 [00:52<02:26,  2.93s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  54%|    | 58/107 [00:53<01:57,  2.40s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  55%|    | 59/107 [00:54<01:38,  2.06s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  56%|    | 60/107 [00:55<01:22,  1.76s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  57%|    | 61/107 [00:56<01:11,  1.55s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  58%|    | 62/107 [00:57<01:06,  1.48s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  59%|    | 63/107 [00:58<00:56,  1.28s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  60%|    | 64/107 [00:59<00:51,  1.19s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  61%|    | 65/107 [01:00<00:45,  1.08s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  62%|   | 66/107 [01:01<00:44,  1.09s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  63%|   | 67/107 [01:02<00:42,  1.07s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  64%|   | 68/107 [01:03<00:40,  1.03s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  64%|   | 69/107 [01:04<00:39,  1.04s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  65%|   | 70/107 [01:05<00:37,  1.01s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  66%|   | 71/107 [01:06<00:40,  1.12s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  67%|   | 72/107 [01:08<00:38,  1.10s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  68%|   | 73/107 [01:08<00:32,  1.03batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  69%|   | 74/107 [01:09<00:33,  1.00s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  70%|   | 75/107 [01:10<00:29,  1.08batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  71%|   | 76/107 [01:11<00:27,  1.12batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  72%|  | 77/107 [01:12<00:26,  1.11batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  73%|  | 78/107 [01:13<00:31,  1.07s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  74%|  | 79/107 [01:14<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  75%|  | 80/107 [01:15<00:26,  1.03batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  76%|  | 81/107 [01:16<00:22,  1.15batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  77%|  | 82/107 [01:16<00:21,  1.18batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  78%|  | 83/107 [01:17<00:21,  1.14batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  79%|  | 84/107 [01:18<00:19,  1.19batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  79%|  | 85/107 [01:19<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  80%|  | 86/107 [01:20<00:17,  1.21batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  81%| | 87/107 [01:20<00:16,  1.23batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  82%| | 88/107 [01:21<00:15,  1.27batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  83%| | 89/107 [01:22<00:14,  1.24batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  84%| | 90/107 [01:23<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  85%| | 91/107 [01:24<00:13,  1.16batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  86%| | 92/107 [01:25<00:15,  1.06s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  87%| | 93/107 [01:26<00:13,  1.03batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  88%| | 94/107 [01:27<00:13,  1.06s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  89%| | 95/107 [01:31<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  90%| | 96/107 [01:32<00:16,  1.52s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  91%| | 97/107 [01:34<00:15,  1.59s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  92%|| 98/107 [01:34<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  93%|| 99/107 [01:35<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  93%|| 100/107 [01:36<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  94%|| 101/107 [01:37<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  95%|| 102/107 [01:38<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  96%|| 103/107 [01:38<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  97%|| 104/107 [01:39<00:02,  1.16batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  98%|| 105/107 [01:40<00:01,  1.18batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32:  99%|| 106/107 [01:41<00:00,  1.10batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 32: 100%|| 107/107 [01:46<00:00,  1.17batch/s, batch_idx=54, gpu=1, loss=0.069, v_num=d5ce3uok]\n",
      "Epoch 33:  51%|    | 55/107 [00:40<00:26,  1.98batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 33:  52%|    | 56/107 [00:50<02:44,  3.23s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  53%|    | 57/107 [00:53<02:29,  2.99s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  54%|    | 58/107 [01:17<07:36,  9.31s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  55%|    | 59/107 [01:18<05:30,  6.89s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  56%|    | 60/107 [01:19<04:02,  5.15s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  57%|    | 61/107 [01:20<02:56,  3.84s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  58%|    | 62/107 [01:21<02:18,  3.08s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  59%|    | 63/107 [01:22<01:45,  2.39s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  60%|    | 64/107 [01:23<01:24,  1.97s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  61%|    | 65/107 [01:24<01:07,  1.62s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  62%|   | 66/107 [01:25<01:00,  1.49s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  63%|   | 67/107 [01:26<00:53,  1.33s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  64%|   | 68/107 [01:27<00:46,  1.20s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  64%|   | 69/107 [01:28<00:44,  1.17s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  65%|   | 70/107 [01:29<00:41,  1.11s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  66%|   | 71/107 [01:30<00:42,  1.19s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  67%|   | 72/107 [01:31<00:40,  1.16s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  68%|   | 73/107 [01:32<00:34,  1.02s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  69%|   | 74/107 [01:33<00:34,  1.04s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  70%|   | 75/107 [01:34<00:30,  1.03batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  71%|   | 76/107 [01:35<00:28,  1.08batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  72%|  | 77/107 [01:36<00:27,  1.07batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  73%|  | 78/107 [01:37<00:31,  1.10s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  74%|  | 79/107 [01:38<00:28,  1.00s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  75%|  | 80/107 [01:39<00:27,  1.01s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  76%|  | 81/107 [01:39<00:23,  1.10batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  77%|  | 82/107 [01:40<00:22,  1.13batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  78%|  | 83/107 [01:41<00:21,  1.10batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  79%|  | 84/107 [01:42<00:20,  1.15batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  79%|  | 85/107 [01:43<00:18,  1.17batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  80%|  | 86/107 [01:44<00:17,  1.17batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  81%| | 87/107 [01:45<00:16,  1.19batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  82%| | 88/107 [01:45<00:15,  1.21batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  83%| | 89/107 [01:46<00:15,  1.19batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  84%| | 90/107 [01:47<00:15,  1.08batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  85%| | 91/107 [01:48<00:14,  1.14batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  86%| | 92/107 [01:50<00:15,  1.06s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  87%| | 93/107 [01:50<00:13,  1.02batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  88%| | 94/107 [01:52<00:13,  1.07s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  89%| | 95/107 [01:55<00:21,  1.76s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  90%| | 96/107 [01:56<00:16,  1.54s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  91%| | 97/107 [01:58<00:16,  1.61s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  92%|| 98/107 [01:59<00:12,  1.37s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  93%|| 99/107 [01:59<00:09,  1.21s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  93%|| 100/107 [02:00<00:07,  1.07s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  94%|| 101/107 [02:01<00:05,  1.02batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  95%|| 102/107 [02:02<00:05,  1.02s/batch, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  96%|| 103/107 [02:03<00:03,  1.05batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  97%|| 104/107 [02:04<00:02,  1.12batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  98%|| 105/107 [02:04<00:01,  1.15batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33:  99%|| 106/107 [02:06<00:00,  1.08batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 33: 100%|| 107/107 [02:10<00:00,  1.15batch/s, batch_idx=54, gpu=1, loss=0.066, v_num=d5ce3uok]\n",
      "Epoch 34:  51%|    | 55/107 [00:41<00:26,  1.97batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 34:  52%|    | 56/107 [00:51<02:54,  3.42s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  53%|    | 57/107 [00:53<02:36,  3.12s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  54%|    | 58/107 [00:55<02:13,  2.73s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  55%|    | 59/107 [00:56<01:49,  2.27s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  56%|    | 60/107 [00:58<01:30,  1.92s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  57%|    | 61/107 [00:59<01:15,  1.64s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  58%|    | 62/107 [01:00<01:09,  1.55s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  59%|    | 63/107 [01:01<00:58,  1.33s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  60%|    | 64/107 [01:02<00:52,  1.22s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  61%|    | 65/107 [01:03<00:46,  1.11s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  62%|   | 66/107 [01:04<00:45,  1.12s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  63%|   | 67/107 [01:05<00:44,  1.10s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  64%|   | 68/107 [01:06<00:40,  1.03s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  64%|   | 69/107 [01:07<00:39,  1.03s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  65%|   | 70/107 [01:08<00:37,  1.00s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  66%|   | 71/107 [01:09<00:40,  1.12s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  67%|   | 72/107 [01:10<00:38,  1.10s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  68%|   | 73/107 [01:11<00:32,  1.04batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  69%|   | 74/107 [01:12<00:32,  1.01batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  70%|   | 75/107 [01:12<00:29,  1.08batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  71%|   | 76/107 [01:13<00:27,  1.14batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  72%|  | 77/107 [01:14<00:26,  1.12batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  73%|  | 78/107 [01:16<00:30,  1.06s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  74%|  | 79/107 [01:16<00:26,  1.04batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  75%|  | 80/107 [01:17<00:25,  1.04batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  76%|  | 81/107 [01:18<00:22,  1.15batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  77%|  | 82/107 [01:19<00:21,  1.18batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  78%|  | 83/107 [01:20<00:20,  1.15batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  79%|  | 84/107 [01:20<00:19,  1.18batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  79%|  | 85/107 [01:21<00:18,  1.20batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  80%|  | 86/107 [01:22<00:17,  1.19batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  81%| | 87/107 [01:23<00:16,  1.21batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  82%| | 88/107 [01:24<00:15,  1.23batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  83%| | 89/107 [01:25<00:14,  1.22batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  84%| | 90/107 [01:26<00:15,  1.11batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  85%| | 91/107 [01:26<00:13,  1.16batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  86%| | 92/107 [01:28<00:15,  1.05s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  87%| | 93/107 [01:29<00:13,  1.04batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  88%| | 94/107 [01:30<00:13,  1.04s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  89%| | 95/107 [01:33<00:20,  1.73s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  90%| | 96/107 [01:34<00:16,  1.51s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  91%| | 97/107 [01:36<00:15,  1.58s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  92%|| 98/107 [01:37<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  93%|| 99/107 [01:38<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  93%|| 100/107 [01:38<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  94%|| 101/107 [01:39<00:05,  1.07batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  95%|| 102/107 [01:40<00:04,  1.02batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  96%|| 103/107 [01:41<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  97%|| 104/107 [01:42<00:02,  1.16batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  98%|| 105/107 [01:42<00:01,  1.18batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34:  99%|| 106/107 [01:43<00:00,  1.11batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 34: 100%|| 107/107 [01:48<00:00,  1.19batch/s, batch_idx=54, gpu=1, loss=0.064, v_num=d5ce3uok]\n",
      "Epoch 35:  51%|    | 55/107 [00:41<00:25,  2.03batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 35:  52%|    | 56/107 [00:52<02:53,  3.40s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  53%|    | 57/107 [00:54<02:33,  3.07s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  54%|    | 58/107 [00:55<02:00,  2.45s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  55%|    | 59/107 [00:56<01:40,  2.09s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  56%|    | 60/107 [00:57<01:23,  1.78s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  57%|    | 61/107 [00:58<01:09,  1.51s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  58%|    | 62/107 [00:59<01:06,  1.47s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  59%|    | 63/107 [01:00<00:56,  1.28s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  60%|    | 64/107 [01:01<00:50,  1.18s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  61%|    | 65/107 [01:02<00:45,  1.08s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  62%|   | 66/107 [01:03<00:44,  1.09s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  63%|   | 67/107 [01:04<00:43,  1.09s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  64%|   | 68/107 [01:05<00:39,  1.02s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  64%|   | 69/107 [01:06<00:38,  1.02s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  65%|   | 70/107 [01:07<00:37,  1.00s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  66%|   | 71/107 [01:08<00:39,  1.11s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  67%|   | 72/107 [01:10<00:38,  1.09s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  68%|   | 73/107 [01:10<00:32,  1.04batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  69%|   | 74/107 [01:11<00:32,  1.01batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  70%|   | 75/107 [01:12<00:29,  1.08batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  71%|   | 76/107 [01:13<00:27,  1.13batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  72%|  | 77/107 [01:14<00:26,  1.11batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  73%|  | 78/107 [01:15<00:31,  1.07s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  74%|  | 79/107 [01:16<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  75%|  | 80/107 [01:17<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  76%|  | 81/107 [01:18<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  77%|  | 82/107 [01:18<00:21,  1.16batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  78%|  | 83/107 [01:19<00:21,  1.13batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  79%|  | 84/107 [01:20<00:19,  1.20batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  79%|  | 85/107 [01:21<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  80%|  | 86/107 [01:22<00:17,  1.20batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  81%| | 87/107 [01:23<00:16,  1.20batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  82%| | 88/107 [01:23<00:15,  1.24batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  83%| | 89/107 [01:24<00:14,  1.22batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  84%| | 90/107 [01:25<00:15,  1.11batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  85%| | 91/107 [01:26<00:13,  1.15batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  86%| | 92/107 [01:27<00:15,  1.04s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  87%| | 93/107 [01:28<00:13,  1.05batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  88%| | 94/107 [01:29<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  89%| | 95/107 [01:33<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  90%| | 96/107 [01:34<00:16,  1.54s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  91%| | 97/107 [01:36<00:15,  1.59s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  92%|| 98/107 [01:36<00:12,  1.35s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  93%|| 99/107 [01:37<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  93%|| 100/107 [01:38<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  94%|| 101/107 [01:39<00:05,  1.05batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  95%|| 102/107 [01:40<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  96%|| 103/107 [01:40<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  97%|| 104/107 [01:41<00:02,  1.16batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  98%|| 105/107 [01:42<00:01,  1.17batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35:  99%|| 106/107 [01:43<00:00,  1.09batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 35: 100%|| 107/107 [01:48<00:00,  1.17batch/s, batch_idx=54, gpu=1, loss=0.061, v_num=d5ce3uok]\n",
      "Epoch 36:  51%|    | 55/107 [00:40<00:23,  2.26batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 36:  52%|    | 56/107 [00:51<02:55,  3.45s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  53%|    | 57/107 [00:53<02:34,  3.10s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  54%|    | 58/107 [00:54<02:02,  2.50s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  55%|    | 59/107 [00:56<01:41,  2.12s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  56%|    | 60/107 [00:57<01:24,  1.80s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  57%|    | 61/107 [00:57<01:09,  1.50s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  58%|    | 62/107 [00:59<01:10,  1.57s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  59%|    | 63/107 [01:00<00:58,  1.33s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  60%|    | 64/107 [01:01<00:53,  1.25s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  61%|    | 65/107 [01:02<00:47,  1.14s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  62%|   | 66/107 [01:03<00:46,  1.14s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  63%|   | 67/107 [01:04<00:43,  1.10s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  64%|   | 68/107 [01:05<00:40,  1.05s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  64%|   | 69/107 [01:06<00:39,  1.04s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  65%|   | 70/107 [01:07<00:37,  1.03s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  66%|   | 71/107 [01:08<00:40,  1.12s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  67%|   | 72/107 [01:09<00:38,  1.10s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  68%|   | 73/107 [01:10<00:33,  1.03batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  69%|   | 74/107 [01:11<00:33,  1.01s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  70%|   | 75/107 [01:12<00:29,  1.07batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  71%|   | 76/107 [01:13<00:27,  1.12batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  72%|  | 77/107 [01:14<00:26,  1.12batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  73%|  | 78/107 [01:15<00:30,  1.07s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  74%|  | 79/107 [01:16<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  75%|  | 80/107 [01:17<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  76%|  | 81/107 [01:17<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  77%|  | 82/107 [01:18<00:21,  1.18batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  78%|  | 83/107 [01:19<00:20,  1.15batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  79%|  | 84/107 [01:20<00:19,  1.20batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  79%|  | 85/107 [01:21<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  80%|  | 86/107 [01:21<00:17,  1.22batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  81%| | 87/107 [01:22<00:16,  1.25batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  82%| | 88/107 [01:23<00:14,  1.27batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  83%| | 89/107 [01:24<00:14,  1.24batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  84%| | 90/107 [01:25<00:15,  1.11batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  85%| | 91/107 [01:26<00:13,  1.16batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  86%| | 92/107 [01:27<00:15,  1.04s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  87%| | 93/107 [01:28<00:13,  1.05batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  88%| | 94/107 [01:29<00:13,  1.04s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  89%| | 95/107 [01:32<00:20,  1.72s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  90%| | 96/107 [01:33<00:16,  1.50s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  91%| | 97/107 [01:35<00:15,  1.57s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  92%|| 98/107 [01:36<00:11,  1.33s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  93%|| 99/107 [01:37<00:09,  1.17s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  93%|| 100/107 [01:37<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  94%|| 101/107 [01:38<00:05,  1.07batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  95%|| 102/107 [01:39<00:04,  1.02batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  96%|| 103/107 [01:40<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  97%|| 104/107 [01:41<00:02,  1.17batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  98%|| 105/107 [01:42<00:01,  1.19batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36:  99%|| 106/107 [01:43<00:00,  1.11batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 36: 100%|| 107/107 [01:47<00:00,  1.19batch/s, batch_idx=54, gpu=1, loss=0.059, v_num=d5ce3uok]\n",
      "Epoch 37:  51%|    | 55/107 [00:42<00:27,  1.92batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 37:  52%|    | 56/107 [00:52<02:56,  3.47s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  53%|    | 57/107 [00:55<02:41,  3.24s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  54%|    | 58/107 [00:56<02:06,  2.59s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  55%|    | 59/107 [00:57<01:44,  2.17s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  56%|    | 60/107 [00:58<01:25,  1.82s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  57%|    | 61/107 [00:59<01:10,  1.52s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  58%|    | 62/107 [01:01<01:07,  1.50s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  59%|    | 63/107 [01:01<00:56,  1.28s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  60%|    | 64/107 [01:02<00:50,  1.18s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  61%|    | 65/107 [01:03<00:44,  1.06s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  62%|   | 66/107 [01:04<00:43,  1.06s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  63%|   | 67/107 [01:05<00:40,  1.02s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  64%|   | 68/107 [01:06<00:38,  1.02batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  64%|   | 69/107 [01:07<00:38,  1.01s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  65%|   | 70/107 [01:08<00:36,  1.02batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  66%|   | 71/107 [01:09<00:39,  1.09s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  67%|   | 72/107 [01:10<00:37,  1.08s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  68%|   | 73/107 [01:11<00:32,  1.05batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  69%|   | 74/107 [01:12<00:32,  1.03batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  70%|   | 75/107 [01:13<00:29,  1.10batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  71%|   | 76/107 [01:14<00:27,  1.15batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  72%|  | 77/107 [01:14<00:26,  1.13batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  73%|  | 78/107 [01:16<00:31,  1.07s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  74%|  | 79/107 [01:17<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  75%|  | 80/107 [01:18<00:26,  1.03batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  76%|  | 81/107 [01:18<00:22,  1.16batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  77%|  | 82/107 [01:19<00:20,  1.19batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  78%|  | 83/107 [01:20<00:20,  1.16batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  79%|  | 84/107 [01:21<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  79%|  | 85/107 [01:21<00:17,  1.25batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  80%|  | 86/107 [01:22<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  81%| | 87/107 [01:23<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  82%| | 88/107 [01:24<00:14,  1.28batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  83%| | 89/107 [01:25<00:14,  1.24batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  84%| | 90/107 [01:26<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  85%| | 91/107 [01:27<00:13,  1.17batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  86%| | 92/107 [01:28<00:15,  1.03s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  87%| | 93/107 [01:29<00:13,  1.05batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  88%| | 94/107 [01:30<00:13,  1.03s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  89%| | 95/107 [01:33<00:20,  1.72s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  90%| | 96/107 [01:34<00:16,  1.51s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  91%| | 97/107 [01:36<00:15,  1.58s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  92%|| 98/107 [01:37<00:11,  1.33s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  93%|| 99/107 [01:38<00:09,  1.17s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  93%|| 100/107 [01:38<00:07,  1.05s/batch, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  94%|| 101/107 [01:39<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  95%|| 102/107 [01:40<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  96%|| 103/107 [01:41<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  97%|| 104/107 [01:42<00:02,  1.16batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  98%|| 105/107 [01:42<00:01,  1.19batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37:  99%|| 106/107 [01:43<00:00,  1.10batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 37: 100%|| 107/107 [01:48<00:00,  1.18batch/s, batch_idx=54, gpu=1, loss=0.057, v_num=d5ce3uok]\n",
      "Epoch 38:  51%|    | 55/107 [00:41<00:27,  1.90batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 38:  52%|    | 56/107 [00:51<02:59,  3.51s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  53%|    | 57/107 [00:54<02:39,  3.18s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  54%|    | 58/107 [00:55<02:04,  2.54s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  55%|    | 59/107 [00:56<01:41,  2.12s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  56%|    | 60/107 [00:57<01:23,  1.77s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  57%|    | 61/107 [00:58<01:08,  1.48s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  58%|    | 62/107 [00:59<01:09,  1.54s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  59%|    | 63/107 [01:00<00:57,  1.32s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  60%|    | 64/107 [01:01<00:51,  1.20s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  61%|    | 65/107 [01:02<00:44,  1.07s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  62%|   | 66/107 [01:03<00:43,  1.07s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  63%|   | 67/107 [01:04<00:41,  1.03s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  64%|   | 68/107 [01:05<00:38,  1.00batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  64%|   | 69/107 [01:06<00:38,  1.01s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  65%|   | 70/107 [01:07<00:36,  1.01batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  66%|   | 71/107 [01:08<00:39,  1.09s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  67%|   | 72/107 [01:09<00:37,  1.07s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  68%|   | 73/107 [01:10<00:32,  1.05batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  69%|   | 74/107 [01:11<00:32,  1.02batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  70%|   | 75/107 [01:12<00:29,  1.09batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  71%|   | 76/107 [01:12<00:27,  1.14batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  72%|  | 77/107 [01:13<00:26,  1.13batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  73%|  | 78/107 [01:15<00:30,  1.05s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  74%|  | 79/107 [01:16<00:26,  1.05batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  75%|  | 80/107 [01:17<00:25,  1.05batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  76%|  | 81/107 [01:17<00:22,  1.16batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  77%|  | 82/107 [01:18<00:20,  1.19batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  78%|  | 83/107 [01:19<00:20,  1.15batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  79%|  | 84/107 [01:20<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  79%|  | 85/107 [01:20<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  80%|  | 86/107 [01:21<00:17,  1.22batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  81%| | 87/107 [01:22<00:16,  1.23batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  82%| | 88/107 [01:23<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  83%| | 89/107 [01:24<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  84%| | 90/107 [01:25<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  85%| | 91/107 [01:25<00:13,  1.17batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  86%| | 92/107 [01:27<00:15,  1.03s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  87%| | 93/107 [01:28<00:13,  1.05batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  88%| | 94/107 [01:29<00:13,  1.03s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  89%| | 95/107 [01:32<00:20,  1.73s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  90%| | 96/107 [01:33<00:16,  1.51s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  91%| | 97/107 [01:35<00:15,  1.57s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  92%|| 98/107 [01:36<00:11,  1.32s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  93%|| 99/107 [01:37<00:09,  1.17s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  93%|| 100/107 [01:37<00:07,  1.03s/batch, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  94%|| 101/107 [01:38<00:05,  1.07batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  95%|| 102/107 [01:39<00:04,  1.02batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  96%|| 103/107 [01:40<00:03,  1.10batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  97%|| 104/107 [01:40<00:02,  1.17batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  98%|| 105/107 [01:41<00:01,  1.20batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38:  99%|| 106/107 [01:42<00:00,  1.12batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 38: 100%|| 107/107 [01:47<00:00,  1.20batch/s, batch_idx=54, gpu=1, loss=0.056, v_num=d5ce3uok]\n",
      "Epoch 39:  51%|    | 55/107 [00:42<00:27,  1.88batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 39:  52%|    | 56/107 [00:53<03:04,  3.62s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  53%|    | 57/107 [00:56<02:43,  3.27s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  54%|    | 58/107 [00:57<02:09,  2.64s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  55%|    | 59/107 [00:58<01:47,  2.24s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  56%|    | 60/107 [00:59<01:28,  1.89s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  57%|    | 61/107 [01:00<01:15,  1.65s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  58%|    | 62/107 [01:02<01:10,  1.57s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  59%|    | 63/107 [01:02<00:58,  1.33s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  60%|    | 64/107 [01:03<00:52,  1.23s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  61%|    | 65/107 [01:04<00:46,  1.11s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  62%|   | 66/107 [01:05<00:46,  1.13s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  63%|   | 67/107 [01:07<00:44,  1.11s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  64%|   | 68/107 [01:07<00:40,  1.04s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  64%|   | 69/107 [01:08<00:39,  1.04s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  65%|   | 70/107 [01:09<00:37,  1.02s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  66%|   | 71/107 [01:11<00:40,  1.13s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  67%|   | 72/107 [01:12<00:38,  1.11s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  68%|   | 73/107 [01:13<00:33,  1.02batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  69%|   | 74/107 [01:14<00:33,  1.00s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  70%|   | 75/107 [01:14<00:29,  1.08batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  71%|   | 76/107 [01:15<00:27,  1.12batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  72%|  | 77/107 [01:16<00:26,  1.11batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  73%|  | 78/107 [01:18<00:31,  1.07s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  74%|  | 79/107 [01:18<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  75%|  | 80/107 [01:19<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  76%|  | 81/107 [01:20<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  77%|  | 82/107 [01:21<00:21,  1.16batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  78%|  | 83/107 [01:22<00:21,  1.13batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  79%|  | 84/107 [01:22<00:19,  1.19batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  79%|  | 85/107 [01:23<00:18,  1.21batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  80%|  | 86/107 [01:24<00:17,  1.20batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  81%| | 87/107 [01:25<00:16,  1.22batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  82%| | 88/107 [01:26<00:15,  1.26batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  83%| | 89/107 [01:26<00:14,  1.22batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  84%| | 90/107 [01:28<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  85%| | 91/107 [01:28<00:13,  1.15batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  86%| | 92/107 [01:30<00:16,  1.07s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  87%| | 93/107 [01:31<00:13,  1.01batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  88%| | 94/107 [01:32<00:13,  1.07s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  89%| | 95/107 [01:35<00:21,  1.76s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  90%| | 96/107 [01:36<00:16,  1.54s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  91%| | 97/107 [01:38<00:16,  1.61s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  92%|| 98/107 [01:39<00:12,  1.36s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  93%|| 99/107 [01:40<00:09,  1.20s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  93%|| 100/107 [01:40<00:07,  1.07s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  94%|| 101/107 [01:41<00:05,  1.02batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  95%|| 102/107 [01:42<00:05,  1.02s/batch, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  96%|| 103/107 [01:43<00:03,  1.05batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  97%|| 104/107 [01:44<00:02,  1.10batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  98%|| 105/107 [01:45<00:01,  1.12batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39:  99%|| 106/107 [01:46<00:00,  1.04batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 39: 100%|| 107/107 [01:51<00:00,  1.12batch/s, batch_idx=54, gpu=1, loss=0.054, v_num=d5ce3uok]\n",
      "Epoch 40:  51%|    | 55/107 [00:43<00:22,  2.32batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 40:  52%|    | 56/107 [00:54<03:03,  3.60s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  53%|    | 57/107 [00:56<02:31,  3.04s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  54%|    | 58/107 [00:57<01:59,  2.43s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  55%|    | 59/107 [00:58<01:44,  2.17s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  56%|    | 60/107 [00:59<01:26,  1.85s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  57%|    | 61/107 [01:00<01:11,  1.54s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  58%|    | 62/107 [01:02<01:10,  1.57s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  59%|    | 63/107 [01:03<00:59,  1.35s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  60%|    | 64/107 [01:04<00:53,  1.24s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  61%|    | 65/107 [01:04<00:46,  1.11s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  62%|   | 66/107 [01:05<00:45,  1.11s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  63%|   | 67/107 [01:06<00:43,  1.09s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  64%|   | 68/107 [01:07<00:41,  1.06s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  64%|   | 69/107 [01:08<00:40,  1.05s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  65%|   | 70/107 [01:09<00:37,  1.02s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  66%|   | 71/107 [01:11<00:40,  1.12s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  67%|   | 72/107 [01:12<00:38,  1.11s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  68%|   | 73/107 [01:13<00:33,  1.03batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  69%|   | 74/107 [01:14<00:32,  1.00batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  70%|   | 75/107 [01:14<00:30,  1.07batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  71%|   | 76/107 [01:15<00:27,  1.11batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  72%|  | 77/107 [01:16<00:27,  1.10batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  73%|  | 78/107 [01:18<00:31,  1.08s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  74%|  | 79/107 [01:18<00:27,  1.01batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  75%|  | 80/107 [01:19<00:26,  1.01batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  76%|  | 81/107 [01:20<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  77%|  | 82/107 [01:21<00:21,  1.16batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  78%|  | 83/107 [01:22<00:21,  1.13batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  79%|  | 84/107 [01:23<00:19,  1.18batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  79%|  | 85/107 [01:23<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  80%|  | 86/107 [01:24<00:17,  1.21batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  81%| | 87/107 [01:25<00:16,  1.23batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  82%| | 88/107 [01:26<00:15,  1.26batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  83%| | 89/107 [01:27<00:14,  1.22batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  84%| | 90/107 [01:28<00:15,  1.11batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  85%| | 91/107 [01:28<00:13,  1.15batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  86%| | 92/107 [01:30<00:15,  1.05s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  87%| | 93/107 [01:31<00:13,  1.03batch/s, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  88%| | 94/107 [01:32<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  89%| | 95/107 [01:35<00:20,  1.73s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  90%| | 96/107 [01:36<00:16,  1.51s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  91%| | 97/107 [01:38<00:15,  1.58s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  92%|| 98/107 [01:39<00:12,  1.33s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  93%|| 99/107 [02:07<01:15,  9.42s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  93%|| 100/107 [02:08<00:47,  6.82s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  94%|| 101/107 [02:08<00:29,  4.99s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  95%|| 102/107 [02:10<00:19,  3.82s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  96%|| 103/107 [02:10<00:11,  2.91s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  97%|| 104/107 [02:11<00:06,  2.26s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  98%|| 105/107 [02:12<00:03,  1.83s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40:  99%|| 106/107 [02:13<00:01,  1.60s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 40: 100%|| 107/107 [02:18<00:00,  1.34s/batch, batch_idx=54, gpu=1, loss=0.053, v_num=d5ce3uok]\n",
      "Epoch 41:  51%|    | 55/107 [00:42<00:23,  2.26batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 41:  52%|    | 56/107 [00:53<03:04,  3.62s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  53%|    | 57/107 [00:55<02:43,  3.26s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  54%|    | 58/107 [00:56<02:06,  2.59s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  55%|    | 59/107 [00:57<01:45,  2.19s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  56%|    | 60/107 [00:59<01:27,  1.85s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  57%|    | 61/107 [00:59<01:11,  1.55s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  58%|    | 62/107 [01:01<01:09,  1.55s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  59%|    | 63/107 [01:02<00:58,  1.33s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  60%|    | 64/107 [01:03<00:52,  1.23s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  61%|    | 65/107 [01:04<00:47,  1.13s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  62%|   | 66/107 [01:05<00:45,  1.12s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  63%|   | 67/107 [01:06<00:44,  1.12s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  64%|   | 68/107 [01:07<00:40,  1.04s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  64%|   | 69/107 [01:08<00:39,  1.04s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  65%|   | 70/107 [01:09<00:37,  1.01s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  66%|   | 71/107 [01:10<00:40,  1.12s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  67%|   | 72/107 [01:11<00:38,  1.11s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  68%|   | 73/107 [01:12<00:33,  1.02batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  69%|   | 74/107 [01:13<00:33,  1.00s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  70%|   | 75/107 [01:14<00:30,  1.07batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  71%|   | 76/107 [01:14<00:27,  1.12batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  72%|  | 77/107 [01:15<00:27,  1.11batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  73%|  | 78/107 [01:17<00:31,  1.08s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  74%|  | 79/107 [01:18<00:27,  1.02batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  75%|  | 80/107 [01:19<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  76%|  | 81/107 [01:19<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  77%|  | 82/107 [01:20<00:21,  1.16batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  78%|  | 83/107 [01:21<00:21,  1.13batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  79%|  | 84/107 [01:22<00:19,  1.19batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  79%|  | 85/107 [01:23<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  80%|  | 86/107 [01:23<00:17,  1.21batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  81%| | 87/107 [01:24<00:16,  1.23batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  82%| | 88/107 [01:25<00:15,  1.26batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  83%| | 89/107 [01:26<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  84%| | 90/107 [01:27<00:15,  1.09batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  85%| | 91/107 [01:28<00:14,  1.13batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  86%| | 92/107 [01:29<00:15,  1.05s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  87%| | 93/107 [01:30<00:13,  1.04batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  88%| | 94/107 [01:31<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  89%| | 95/107 [01:34<00:20,  1.73s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  90%| | 96/107 [01:35<00:16,  1.51s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  91%| | 97/107 [01:37<00:15,  1.57s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  92%|| 98/107 [01:38<00:11,  1.32s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  93%|| 99/107 [01:39<00:09,  1.17s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  93%|| 100/107 [01:39<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  94%|| 101/107 [01:40<00:05,  1.07batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  95%|| 102/107 [01:41<00:04,  1.02batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  96%|| 103/107 [01:42<00:03,  1.10batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  97%|| 104/107 [01:43<00:02,  1.16batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  98%|| 105/107 [01:44<00:01,  1.16batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41:  99%|| 106/107 [01:45<00:00,  1.08batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 41: 100%|| 107/107 [01:49<00:00,  1.14batch/s, batch_idx=54, gpu=1, loss=0.052, v_num=d5ce3uok]\n",
      "Epoch 42:  51%|    | 55/107 [00:44<00:25,  2.07batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 42:  52%|    | 56/107 [00:55<03:13,  3.79s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  53%|    | 57/107 [00:58<02:48,  3.37s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  54%|    | 58/107 [00:59<02:11,  2.67s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  55%|    | 59/107 [01:00<01:47,  2.25s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  56%|    | 60/107 [01:01<01:29,  1.91s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  57%|    | 61/107 [01:02<01:13,  1.60s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  58%|    | 62/107 [01:03<01:09,  1.55s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  59%|    | 63/107 [01:04<00:58,  1.32s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  60%|    | 64/107 [01:05<00:51,  1.21s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  61%|    | 65/107 [01:06<00:46,  1.10s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  62%|   | 66/107 [01:07<00:45,  1.11s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  63%|   | 67/107 [01:08<00:42,  1.07s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  64%|   | 68/107 [01:09<00:40,  1.05s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  64%|   | 69/107 [01:10<00:39,  1.05s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  65%|   | 70/107 [01:11<00:38,  1.03s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  66%|   | 71/107 [01:13<00:40,  1.13s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  67%|   | 72/107 [01:14<00:38,  1.11s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  68%|   | 73/107 [01:14<00:33,  1.02batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  69%|   | 74/107 [01:15<00:33,  1.01s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  70%|   | 75/107 [01:16<00:30,  1.07batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  71%|   | 76/107 [01:17<00:27,  1.12batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  72%|  | 77/107 [01:18<00:27,  1.10batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  73%|  | 78/107 [01:19<00:31,  1.08s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  74%|  | 79/107 [01:20<00:27,  1.02batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  75%|  | 80/107 [01:21<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  76%|  | 81/107 [01:22<00:22,  1.15batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  77%|  | 82/107 [01:22<00:21,  1.17batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  78%|  | 83/107 [01:23<00:21,  1.13batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  79%|  | 84/107 [01:24<00:19,  1.19batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  79%|  | 85/107 [01:25<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  80%|  | 86/107 [01:26<00:17,  1.21batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  81%| | 87/107 [01:27<00:16,  1.22batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  82%| | 88/107 [01:27<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  83%| | 89/107 [01:28<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  84%| | 90/107 [01:29<00:15,  1.11batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  85%| | 91/107 [01:30<00:13,  1.15batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  86%| | 92/107 [01:32<00:15,  1.06s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  87%| | 93/107 [01:32<00:13,  1.03batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  88%| | 94/107 [01:34<00:13,  1.06s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  89%| | 95/107 [01:37<00:21,  1.75s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  90%| | 96/107 [01:38<00:16,  1.53s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  91%| | 97/107 [01:40<00:15,  1.60s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  92%|| 98/107 [01:41<00:12,  1.36s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  93%|| 99/107 [01:41<00:09,  1.19s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  93%|| 100/107 [01:42<00:07,  1.06s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  94%|| 101/107 [01:43<00:05,  1.05batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  95%|| 102/107 [01:44<00:05,  1.00s/batch, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  96%|| 103/107 [01:45<00:03,  1.08batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  97%|| 104/107 [01:45<00:02,  1.15batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  98%|| 105/107 [01:46<00:01,  1.16batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42:  99%|| 106/107 [01:47<00:00,  1.09batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 42: 100%|| 107/107 [01:52<00:00,  1.16batch/s, batch_idx=54, gpu=1, loss=0.050, v_num=d5ce3uok]\n",
      "Epoch 43:  51%|    | 55/107 [00:43<00:24,  2.12batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 43:  52%|    | 56/107 [00:54<03:16,  3.85s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  53%|    | 57/107 [00:57<02:51,  3.43s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  54%|    | 58/107 [00:58<02:13,  2.72s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  55%|    | 59/107 [00:59<01:48,  2.27s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  56%|    | 60/107 [01:00<01:29,  1.91s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  57%|    | 61/107 [01:01<01:13,  1.59s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  58%|    | 62/107 [01:02<01:10,  1.56s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  59%|    | 63/107 [01:03<00:58,  1.33s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  60%|    | 64/107 [01:04<00:52,  1.22s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  61%|    | 65/107 [01:05<00:46,  1.10s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  62%|   | 66/107 [01:06<00:46,  1.14s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  63%|   | 67/107 [01:07<00:43,  1.09s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  64%|   | 68/107 [01:08<00:40,  1.05s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  64%|   | 69/107 [01:09<00:39,  1.04s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  65%|   | 70/107 [01:10<00:37,  1.01s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  66%|   | 71/107 [01:12<00:40,  1.11s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  67%|   | 72/107 [01:13<00:38,  1.10s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  68%|   | 73/107 [01:13<00:33,  1.02batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  69%|   | 74/107 [01:14<00:33,  1.00s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  70%|   | 75/107 [01:15<00:29,  1.07batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  71%|   | 76/107 [01:16<00:27,  1.12batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  72%|  | 77/107 [01:17<00:27,  1.11batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  73%|  | 78/107 [01:18<00:31,  1.07s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  74%|  | 79/107 [01:19<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  75%|  | 80/107 [01:20<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  76%|  | 81/107 [01:21<00:22,  1.14batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  77%|  | 82/107 [01:22<00:21,  1.16batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  78%|  | 83/107 [01:22<00:21,  1.13batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  79%|  | 84/107 [01:23<00:19,  1.19batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  79%|  | 85/107 [01:24<00:18,  1.22batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  80%|  | 86/107 [01:25<00:17,  1.20batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  81%| | 87/107 [01:26<00:16,  1.22batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  82%| | 88/107 [01:26<00:15,  1.25batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  83%| | 89/107 [01:27<00:14,  1.20batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  84%| | 90/107 [01:28<00:15,  1.10batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  85%| | 91/107 [01:29<00:14,  1.14batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  86%| | 92/107 [01:31<00:15,  1.05s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  87%| | 93/107 [01:31<00:13,  1.03batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  88%| | 94/107 [01:33<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  89%| | 95/107 [01:36<00:21,  1.75s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  90%| | 96/107 [01:37<00:16,  1.53s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  91%| | 97/107 [01:39<00:16,  1.60s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  92%|| 98/107 [01:40<00:12,  1.36s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  93%|| 99/107 [01:40<00:09,  1.20s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  93%|| 100/107 [01:41<00:07,  1.06s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  94%|| 101/107 [01:42<00:05,  1.04batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  95%|| 102/107 [01:43<00:05,  1.00s/batch, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  96%|| 103/107 [01:44<00:03,  1.06batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  97%|| 104/107 [01:45<00:02,  1.13batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  98%|| 105/107 [01:45<00:01,  1.16batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43:  99%|| 106/107 [01:46<00:00,  1.08batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 43: 100%|| 107/107 [01:51<00:00,  1.14batch/s, batch_idx=54, gpu=1, loss=0.049, v_num=d5ce3uok]\n",
      "Epoch 44:  51%|    | 55/107 [00:46<00:26,  1.98batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 44:  52%|    | 56/107 [00:57<03:16,  3.86s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  53%|    | 57/107 [01:00<02:57,  3.54s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  54%|    | 58/107 [01:01<02:19,  2.85s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  55%|    | 59/107 [01:03<01:53,  2.36s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  56%|    | 60/107 [01:04<01:32,  1.97s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  57%|    | 61/107 [01:05<01:16,  1.66s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  58%|    | 62/107 [01:06<01:11,  1.58s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  59%|    | 63/107 [01:07<00:59,  1.35s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  60%|    | 64/107 [01:08<00:53,  1.24s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  61%|    | 65/107 [01:09<00:46,  1.11s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  62%|   | 66/107 [01:10<00:45,  1.10s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  63%|   | 67/107 [01:11<00:43,  1.09s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  64%|   | 68/107 [01:12<00:39,  1.02s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  64%|   | 69/107 [01:13<00:38,  1.02s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  65%|   | 70/107 [01:13<00:36,  1.00batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  66%|   | 71/107 [01:15<00:40,  1.11s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  67%|   | 72/107 [01:16<00:38,  1.11s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  68%|   | 73/107 [01:17<00:33,  1.02batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  69%|   | 74/107 [01:18<00:33,  1.01s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  70%|   | 75/107 [01:18<00:29,  1.07batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  71%|   | 76/107 [01:19<00:27,  1.13batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  72%|  | 77/107 [01:20<00:26,  1.11batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  73%|  | 78/107 [01:22<00:31,  1.07s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  74%|  | 79/107 [01:22<00:27,  1.02batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  75%|  | 80/107 [01:23<00:26,  1.03batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  76%|  | 81/107 [01:24<00:23,  1.13batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  77%|  | 82/107 [01:25<00:22,  1.12batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  78%|  | 83/107 [01:26<00:22,  1.09batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  79%|  | 84/107 [01:27<00:19,  1.16batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  79%|  | 85/107 [01:27<00:18,  1.20batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  80%|  | 86/107 [01:28<00:17,  1.20batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  81%| | 87/107 [01:29<00:16,  1.23batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  82%| | 88/107 [01:30<00:14,  1.27batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  83%| | 89/107 [01:31<00:14,  1.24batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  84%| | 90/107 [01:32<00:15,  1.12batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  85%| | 91/107 [01:32<00:13,  1.17batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  86%| | 92/107 [01:34<00:15,  1.03s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  87%| | 93/107 [01:35<00:13,  1.04batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  88%| | 94/107 [01:36<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  89%| | 95/107 [01:39<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  90%| | 96/107 [01:40<00:16,  1.52s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  91%| | 97/107 [01:42<00:15,  1.58s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  92%|| 98/107 [01:43<00:11,  1.33s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  93%|| 99/107 [01:44<00:09,  1.17s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  93%|| 100/107 [01:44<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  94%|| 101/107 [01:45<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  95%|| 102/107 [01:46<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  96%|| 103/107 [01:47<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  97%|| 104/107 [01:48<00:02,  1.16batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  98%|| 105/107 [01:48<00:01,  1.19batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44:  99%|| 106/107 [01:49<00:00,  1.11batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 44: 100%|| 107/107 [01:54<00:00,  1.16batch/s, batch_idx=54, gpu=1, loss=0.048, v_num=d5ce3uok]\n",
      "Epoch 45:  51%|    | 55/107 [00:44<00:23,  2.18batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 45:  52%|    | 56/107 [00:56<03:17,  3.88s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  53%|    | 57/107 [00:58<02:50,  3.41s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  54%|    | 58/107 [00:59<02:12,  2.70s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  55%|    | 59/107 [01:00<01:47,  2.24s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  56%|    | 60/107 [01:01<01:28,  1.88s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  57%|    | 61/107 [01:02<01:11,  1.56s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  58%|    | 62/107 [01:04<01:10,  1.57s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  59%|    | 63/107 [01:04<00:58,  1.33s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  60%|    | 64/107 [01:05<00:52,  1.21s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  61%|    | 65/107 [01:06<00:45,  1.08s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  62%|   | 66/107 [01:07<00:44,  1.10s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  63%|   | 67/107 [01:08<00:42,  1.06s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  64%|   | 68/107 [01:09<00:39,  1.01s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  64%|   | 69/107 [01:10<00:38,  1.03s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  65%|   | 70/107 [01:11<00:36,  1.00batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  66%|   | 71/107 [01:13<00:39,  1.10s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  67%|   | 72/107 [01:14<00:37,  1.08s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  68%|   | 73/107 [01:14<00:32,  1.05batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  69%|   | 74/107 [01:15<00:32,  1.02batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  70%|   | 75/107 [01:16<00:29,  1.09batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  71%|   | 76/107 [01:17<00:27,  1.14batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  72%|  | 77/107 [01:18<00:26,  1.12batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  73%|  | 78/107 [01:19<00:31,  1.07s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  74%|  | 79/107 [01:20<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  75%|  | 80/107 [01:21<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  76%|  | 81/107 [01:22<00:22,  1.13batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  77%|  | 82/107 [01:22<00:21,  1.17batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  78%|  | 83/107 [01:23<00:21,  1.14batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  79%|  | 84/107 [01:24<00:19,  1.20batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  79%|  | 85/107 [01:25<00:17,  1.24batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  80%|  | 86/107 [01:26<00:17,  1.22batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  81%| | 87/107 [01:26<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  82%| | 88/107 [01:27<00:15,  1.26batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  83%| | 89/107 [01:28<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  84%| | 90/107 [01:29<00:15,  1.11batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  85%| | 91/107 [01:30<00:13,  1.16batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  86%| | 92/107 [01:31<00:15,  1.05s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  87%| | 93/107 [01:32<00:13,  1.03batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  88%| | 94/107 [01:33<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  89%| | 95/107 [01:37<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  90%| | 96/107 [01:38<00:16,  1.52s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  91%| | 97/107 [01:40<00:15,  1.59s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  92%|| 98/107 [01:40<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  93%|| 99/107 [01:41<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  93%|| 100/107 [01:42<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  94%|| 101/107 [01:43<00:05,  1.05batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  95%|| 102/107 [01:44<00:04,  1.01batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  96%|| 103/107 [01:44<00:03,  1.08batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  97%|| 104/107 [01:45<00:02,  1.16batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  98%|| 105/107 [01:46<00:01,  1.18batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45:  99%|| 106/107 [01:47<00:00,  1.10batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 45: 100%|| 107/107 [01:52<00:00,  1.18batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  51%|    | 55/107 [00:44<00:25,  2.05batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 46:  52%|    | 56/107 [00:56<03:26,  4.05s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  53%|    | 57/107 [00:58<02:42,  3.26s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  54%|    | 58/107 [00:59<02:08,  2.63s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  55%|    | 59/107 [01:00<01:51,  2.32s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  56%|    | 60/107 [01:01<01:31,  1.94s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  57%|    | 61/107 [01:02<01:13,  1.60s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  58%|    | 62/107 [01:04<01:13,  1.63s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  59%|    | 63/107 [01:05<01:01,  1.39s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  60%|    | 64/107 [01:06<00:54,  1.26s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  61%|    | 65/107 [01:07<00:47,  1.12s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  62%|   | 66/107 [01:08<00:46,  1.14s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  63%|   | 67/107 [01:09<00:43,  1.09s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  64%|   | 68/107 [01:10<00:41,  1.05s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  64%|   | 69/107 [01:11<00:39,  1.04s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  65%|   | 70/107 [01:12<00:37,  1.01s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  66%|   | 71/107 [01:13<00:40,  1.12s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  67%|   | 72/107 [01:14<00:38,  1.11s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  68%|   | 73/107 [01:15<00:33,  1.03batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  69%|   | 74/107 [01:16<00:32,  1.00batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  70%|   | 75/107 [01:17<00:29,  1.07batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  71%|   | 76/107 [01:17<00:27,  1.12batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  72%|  | 77/107 [01:18<00:26,  1.12batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  73%|  | 78/107 [01:20<00:31,  1.08s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  74%|  | 79/107 [01:21<00:27,  1.03batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  75%|  | 80/107 [01:22<00:26,  1.02batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  76%|  | 81/107 [01:22<00:22,  1.15batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  77%|  | 82/107 [01:23<00:21,  1.17batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  78%|  | 83/107 [01:24<00:21,  1.14batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  79%|  | 84/107 [01:25<00:19,  1.20batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  79%|  | 85/107 [01:25<00:17,  1.23batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  80%|  | 86/107 [01:26<00:17,  1.22batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  81%| | 87/107 [01:27<00:16,  1.24batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  82%| | 88/107 [01:28<00:15,  1.26batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  83%| | 89/107 [01:29<00:14,  1.23batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  84%| | 90/107 [01:30<00:15,  1.11batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  85%| | 91/107 [01:31<00:13,  1.16batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  86%| | 92/107 [01:32<00:15,  1.05s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  87%| | 93/107 [01:33<00:13,  1.03batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  88%| | 94/107 [01:34<00:13,  1.05s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  89%| | 95/107 [01:37<00:20,  1.74s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  90%| | 96/107 [01:38<00:16,  1.52s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  91%| | 97/107 [01:40<00:15,  1.58s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  92%|| 98/107 [01:41<00:12,  1.34s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  93%|| 99/107 [01:42<00:09,  1.18s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  93%|| 100/107 [01:42<00:07,  1.04s/batch, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  94%|| 101/107 [01:43<00:05,  1.06batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  95%|| 102/107 [01:44<00:04,  1.02batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  96%|| 103/107 [01:45<00:03,  1.09batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  97%|| 104/107 [01:46<00:02,  1.16batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  98%|| 105/107 [01:47<00:01,  1.17batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46:  99%|| 106/107 [01:48<00:00,  1.10batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 46: 100%|| 107/107 [01:53<00:00,  1.16batch/s, batch_idx=54, gpu=1, loss=0.047, v_num=d5ce3uok]\n",
      "Epoch 47:  51%|    | 55/107 [00:45<00:25,  2.07batch/s, batch_idx=54, gpu=1, loss=0.046, v_num=d5ce3uok] \n",
      "Validating:   0%|          | 0/52 [00:00<?, ?batch/s]\u001b[A\n",
      "Epoch 47:  52%|    | 56/107 [00:58<03:27,  4.06s/batch, batch_idx=54, gpu=1, loss=0.046, v_num=d5ce3uok]\n",
      "Epoch 47:  53%|    | 57/107 [01:00<02:56,  3.54s/batch, batch_idx=54, gpu=1, loss=0.046, v_num=d5ce3uok]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ab66e5fc0ee8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                   \u001b[0mearly_stop_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccumulate_grad_batches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m                   logger=logger, gpus=[1]) #, gradient_clip_val=0.5) # amp_level='O2', use_amp=True) <-- for half precision\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingle_gpu_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0;31m# ON CPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/pytorch_lightning/trainer/distrib_parts.py\u001b[0m in \u001b[0;36msingle_gpu_train\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pretrain_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdp_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_pretrain_routine\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    828\u001b[0m         \u001b[0;31m# CORE TRAINING LOOP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 829\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# RUN TNG EPOCH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             \u001b[0;31m# -----------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# update LR schedulers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0;31m# fast_dev_run always forces val checking after train batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_dev_run\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mshould_check_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtesting\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m             \u001b[0;31m# when logs should be saved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mrun_evaluation\u001b[0;34m(self, test)\u001b[0m\n\u001b[1;32m    303\u001b[0m                                      \u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m                                      \u001b[0mmax_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m                                      test)\n\u001b[0m\u001b[1;32m    306\u001b[0m         _, prog_bar_metrics, log_metrics, callback_metrics, _ = self.process_output(\n\u001b[1;32m    307\u001b[0m             eval_results)\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, dataloaders, max_batches, test)\u001b[0m\n\u001b[1;32m    232\u001b[0m                                                  \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m                                                  \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                                                  test)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m                 \u001b[0;31m# track outputs for collation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/pytorch_lightning/trainer/evaluation_loop.py\u001b[0m in \u001b[0;36mevaluation_forward\u001b[0;34m(self, model, batch, batch_idx, dataloader_idx, test)\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-40ae9915cc2d>\u001b[0m in \u001b[0;36mvalidation_step\u001b[0;34m(self, batch, batch_nb)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauprc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'T-stacking'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauprc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred_example\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_channels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriu_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_post_performance_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/wandb/data_types.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data_or_path, mode, caption, grouping)\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_matplotlib_typename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_full_typename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_matplotlib_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPILImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPILImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36msavefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   2178\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2180\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     \u001b[0mbbox_inches_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_bbox_inches_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m                     **kwargs)\n\u001b[0m\u001b[1;32m   2092\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mrestore_bbox\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0mFigureCanvasAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m             \u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_cm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdpi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/backends/backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mRendererAgg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m             \u001b[0;31m# A GUI class may be need to update a window using this draw, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;31m# don't forget to call the superclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1707\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1708\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1709\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2647\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2649\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1204\u001b[0m         ticklabelBoxes, ticklabelBoxes2 = self._get_tick_bboxes(ticks_to_draw,\n\u001b[1;32m   1205\u001b[0m                                                                 renderer)\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1077\u001b[0m         \u001b[0mthe\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mticks\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mwill\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mdrawn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m         \"\"\"\n\u001b[0;32m-> 1079\u001b[0;31m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m         \u001b[0mmajor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m         \u001b[0mmajor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_major_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmajor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_majorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_majorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;34m\"\"\"Get the array of major tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1324\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2079\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2080\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2081\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2087\u001b[0m         vmin, vmax = mtransforms.nonsingular(\n\u001b[1;32m   2088\u001b[0m             vmin, vmax, expander=1e-13, tiny=1e-14)\n\u001b[0;32m-> 2089\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2091\u001b[0m         \u001b[0mprune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m_raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nbins\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'auto'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2027\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2028\u001b[0;31m                 nbins = np.clip(self.axis.get_tick_space(),\n\u001b[0m\u001b[1;32m   2029\u001b[0m                                 max(1, self._min_n_ticks - 1), 9)\n\u001b[1;32m   2030\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tick_space\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2181\u001b[0m         \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransAxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m72\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2183\u001b[0;31m         \u001b[0mtick\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2184\u001b[0m         \u001b[0;31m# There is a heuristic here that the aspect ratio of tick text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m         \u001b[0;31m# is no more than 3:1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_tick\u001b[0;34m(self, major)\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m             \u001b[0mtick_kw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_minor_tick_kw\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1933\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mXTick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmajor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtick_kw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1935\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axes, loc, label, size, width, color, tickdir, pad, labelsize, labelcolor, zorder, gridOn, tick1On, tick2On, label1On, label2On, major, labelrotation, grid_color, grid_linestyle, grid_linewidth, grid_alpha, **kw)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick1line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick1line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick2line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tick2line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgridline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gridline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_text2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_get_gridline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m                           \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grid_alpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m                           \u001b[0mmarkersize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 493\u001b[0;31m                           **self._grid_kw)\n\u001b[0m\u001b[1;32m    494\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_xaxis_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'grid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpolation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGRIDLINE_INTERPOLATION_STEPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, xdata, ydata, linewidth, linestyle, color, marker, markersize, markeredgewidth, markeredgecolor, markerfacecolor, markerfacecoloralt, fillstyle, antialiased, dash_capstyle, solid_capstyle, dash_joinstyle, solid_joinstyle, pickradius, drawstyle, markevery, **kwargs)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x_filled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# used in subslicing; only x is needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mydata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"3.1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/tesselate/lib/python3.6/site-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_ydata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    664\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecache_always\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%capture --no-stdout\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.CRITICAL)\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.logging import WandbLogger\n",
    "\n",
    "logger = WandbLogger(project='tesselate')\n",
    "\n",
    "trainer = Trainer(max_nb_epochs=10000, checkpoint_callback=checkpoint_callback,\n",
    "                  early_stop_callback=False, accumulate_grad_batches=8,\n",
    "                  logger=logger, gpus=[1]) #, gradient_clip_val=0.5) # amp_level='O2', use_amp=True) <-- for half precision\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ycs4WmYKrqoE"
   },
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['3cbn']\n",
      "1 ['4mq3']\n",
      "2 ['2w2s']\n",
      "3 ['3zzp']\n",
      "4 ['5daz']\n",
      "5 ['4g29']\n",
      "6 ['4il7']\n",
      "7 ['3piw']\n",
      "8 ['3ey6']\n",
      "9 ['1jyh']\n",
      "10 ['2wwe']\n",
      "11 ['2f3l']\n",
      "12 ['2a90']\n",
      "13 ['2cxa']\n",
      "14 ['3nzl']\n",
      "15 ['1cew']\n",
      "16 ['4jqf']\n",
      "17 ['1jhs']\n",
      "18 ['2nrr']\n",
      "19 ['2vga']\n",
      "20 ['3rle']\n",
      "21 ['3b7x']\n",
      "22 ['3doa']\n",
      "23 ['1uoy']\n",
      "24 ['2nyv']\n",
      "25 ['2f68']\n",
      "26 ['5cwj']\n",
      "27 ['1i60']\n",
      "28 ['2jay']\n",
      "29 ['4hcs']\n",
      "30 ['4pgr']\n",
      "31 ['4pn7']\n",
      "32 ['1bm8']\n",
      "33 ['3u4k']\n",
      "34 ['1mij']\n",
      "35 ['4qft']\n",
      "36 ['3vbc']\n",
      "37 ['1z3x']\n",
      "38 ['2nls']\n",
      "39 ['2x3m']\n",
      "40 ['4glp']\n",
      "41 ['1vk4']\n",
      "42 ['2r4q']\n",
      "43 ['4qwv']\n",
      "44 ['2ymo']\n",
      "45 ['1xkr']\n",
      "46 ['5fd9']\n",
      "47 ['1ipa']\n",
      "48 ['1ops']\n",
      "49 ['3e0h']\n",
      "50 ['5hy6']\n",
      "51 ['1hu3']\n",
      "52 ['1c25']\n",
      "53 ['2ahe']\n",
      "54 ['2vge']\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "data_base = '/home/tshimko/tesselate/'\n",
    "\n",
    "data_load = [\n",
    "                'pdb_id',\n",
    "#                 'model',\n",
    "                'atom_nodes',\n",
    "                'atom_adj',\n",
    "#                 'atom_contact',\n",
    "#                 'atom_mask',\n",
    "                'res_adj',\n",
    "                'res_dist',\n",
    "                'chain_mem',\n",
    "                'res_contact',\n",
    "                'conn_adj',\n",
    "                'res_mask',\n",
    "                'mem_mat',\n",
    "#                 'idx2atom_dict',\n",
    "#                 'idx2res_dict'\n",
    "            ]\n",
    "\n",
    "train_data = TesselateDataset(data_base + 'test4.txt',\n",
    "                              graph_dir=data_base + 'data/graphs',\n",
    "                              contacts_dir=data_base + 'data/contacts',\n",
    "                              return_data=data_load, in_memory=True)\n",
    "\n",
    "\n",
    "for idx, i in enumerate(DataLoader(train_data, shuffle=False, num_workers=30, pin_memory=True)):\n",
    "    print(idx, i['pdb_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5d9740f7fa84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriu_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "preds = triu_expand(out).sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plot_channels(preds.detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels(triu_expand(i['res_contact'].squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions\n",
    "preds = triu_expand(torch.from_numpy(acts['preds'])).sigmoid()\n",
    "plot_channels(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the true values\n",
    "plot_channels(x['res_contact'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_channels(x['res_mask'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(torch.from_numpy(acts['preds']).sigmoid(), triu_condense(x['res_contact'].squeeze()), 'ROC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curve(torch.from_numpy(acts['preds']).sigmoid(), triu_condense(x['res_contact'].squeeze()), 'PRC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.tensor([1., 2., 3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.pow(torch.div(x, 2), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.relu(x - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.randn((5, 5, 3)).sum(dim=-1).sum(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.accessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "p-gnn2D_four_channel_benchmark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
